# 0 课程介绍

> 极客时间 《[趣谈网络协议](https://time.geekbang.org/column/intro/100007101)》

![image-20240429142906892](趣谈网络协议.assets/image-20240429142906892.png)

## 你将获得

- 掌握网络协议的知识框架；
- 应对大厂面试的协议难题；
- 驾驭网络协议的实用场景。

## 课程介绍

网络协议是每个程序员入门的必修课，但是彻底掌握并应用网络协议知识却并非易事，比如常见的 TCP/IP、HTTP。网络协议的内容很基础，但基础知识不等于简单知识，更不等于不重要的知识。在网络协议的学习过程中，如果你也有过这样的感受：

- 协议知识琐碎又枯燥，一看书就头大；
- 协议内容很基础，但面试一问就“崩盘”；
- 工作遇到才去查书，现学却没法现卖；
- 协议知识太底层，不知道如何在热门领域应用。

那么，“趣谈网络协议”专栏就是为你量身定制的。

在本专栏中，刘超老师将结合自己从业 15 年的“泣血”经验，对网络协议的底层概念及其在热门领域的应用进行剖析。

他选取了从底层到上层，最基础、最常用、最重要的网络协议进行一一解析，并将深入分析网络协议在云计算、容器和微服务等领域的应用和实践。帮助入门级程序员深入、直观地理解网络协议基础概念和原理，构建一个完整、精准的协议知识框架；帮助有一定工作经验的程序员填补知识漏洞、打通知识体系。

专栏分为 3 大模块。

- **底层网络协议知识详解：** 将用最通俗的语言，自下而上讲解最重要、最常用以及最陌生的网络协议概念，帮你构建最精准的网络协议知识框架。
- **网络协议在热门领域的应用：** 将讲述网络协议在当下热门领域的应用，比如云计算、容器和微服务，并手把手带你使用新技术，进一步加深对网络协议概念的理解。
- **网络协议知识串联：** 将用“双十一”的故事串起网络协议的核心概念和基础知识；借助虚拟化和容器技术，搭建一个实验环境，持续更新你的知识库。

## 课程目录

<img src="趣谈网络协议.assets/1a17f945f721b4a18a84e540c70f580a.jpg" alt="img" style="zoom:67%;" />

## 开篇词 | 想成为技术牛人？先搞定网络协议！

为什么网络协议这么重要呢？为什么“计算机组成与系统结构”“数据结构与算法”“操作系统”“计算机网络”“编译原理”，会成为大学计算机的核心课程呢？至少看起来，这些内容没有“多少天搞定 MFC、Structs”这样的内容更容易帮你找到工作。我毕业的时候，也感到很困惑。

不过当时我抱着一个理想，也可能是大多数程序员的理想：我要做技术牛人，我要搞定大系统。



工作 15 年，我在 EMC 做过类似 GFS 的分布式存储开发，做过基于 Lucene 的搜索引擎，做过 Hadoop 的运维；在 HP 和华为做过 OpenStack 的开发、实施和解决方案；还创业倒腾过 Mesos 容器平台，后来在网易做 Kubernetes。

随着见过的世面越来越多，我渐渐发现，无论是对于大规模系统的架构，还是对于程序员的个人职业生涯，网络和网络协议都是绕不过去的坎儿。

集群规模一大，我们首先想到的就是网络互通的问题；应用吞吐量压不上去，我们首先想到的也是网络互通的问题。**不客气地讲，很多情况下，只要搞定了网络，一个大型系统也就搞定了一半**。所以，要成为技术牛人，搞定大系统，一定要过网络这一关，而网络协议在网络中占有举足轻重的地位。



相信大部分人都思考过“技术变化太快，容易过时”的问题。毕竟，技术浪潮一浪接一浪，新技术层出不穷。从搜索引擎、大数据、云计算，到人工智能、区块链，简直就是“你方唱罢我登场”。**这里面究竟有没有最本质的东西，使得你掌握了它，就能在新技术的滚滚浪潮中，保持快速学习的能力？**

通过对大量开源技术的代码进行分析，我发现很多技术看起来轰轰烈烈，扒下外衣，本质的东西其实就是基础知识和核心概念。**想要不被滚滚而来的新技术淘汰，就要掌握这些可以长久使用的知识，而网络协议就是值得你学习，而且是到 40 岁之后依然有价值的知识。**

但是，要想真正学习和掌握网络协议，也并非易事。下面这些场景，你是不是也感同身受呢？

- **网络协议知识点太多，学完记不住。**
- **看上去懂了，但是经不住问。**没关系，网上有很多的文章嘛。于是，你会搜索很多文章去看。看的时候，你感觉别人说的很有道理，好像理解了，但是经不住问，一问就发现，你只是了解了大概的流程，很多细节还是不知道。所以说，从能看懂到能给别人讲明白，中间还有很长一段距离。
- **知识学会了，实际应用依旧不会**。细节都摸索得差不多了，但是当你自己去应用和调试的时候，发现还是没有思路。比如，当创建出来的虚拟机不能上网的时候，该怎么办呢？学过的东西，怎么还是不会用？

我把这样的网络协议学习过程总结为：**一看觉得懂，一问就打鼓，一用就糊涂。**

那网络协议究竟该怎么学？基于这个问题，我决定从以下三个角度和你分享我所理解的网络协议。

**第一，我会从身边经常见到的事情出发，用故事来讲解各种网络协议，然后慢慢扩展到不熟悉的领域。**

例如，每个人都会查看 IP 地址，那我们就从这个命令开始，展开一些概念；很多人都在大学宿舍组过简单的网络来打游戏，我就从宿舍里最简单的网络概念开始讲；然后说到办公室，说到日常上网、购物、视频下载等过程涉及的协议；最后说到最陌生的数据中心。



**第二，我会用贴近场景的方式来讲解网络协议，将各个层次的关系串起来，而非孤立地讲解某个概念。**

常见的计算机网络课程往往会按照网络分层，一层一层地讲，却很少讲层与层之间的关系。例如，我们学习路由协议的时候，在真实场景中，这么多的算法和二层是什么关系呢？和四层又是什么关系呢？例如，在真实的网络通信中，我们访问一个网站，做一个支付，在 TCP 进行三次握手的时候，IP 层在干嘛？MAC 层又在干嘛？这些你是不是都清楚？



**第三，我会在讲解完各个层次的网络协议之后，着重剖析如何在当下热门领域使用这些协议，比如云计算、容器和微服务。**

一方面你可以知道网络协议真实应用的地方，另一方面你也可以通过上手使用云计算、容器、微服务来进一步加深对于协议的理解。



# 第一模块 通信协议综述

## 第1讲 | 为什么要学习网络协议？

当"Hello World!"从显示器打印出来的时候，还记得你激动的心情吗？

```java
public class HelloWorld {
  public static void main(String[] args){
    System.out.println("Hello World!");
  }
}
```

如果你是程序员，一定看得懂上面这一段文字。这是每一个程序员向计算机世界说“你好，世界”的方式。

但是，你不一定知道，这段文字也是一种协议，是人类和计算机沟通的协议，**只有通过这种协议，计算机才知道我们想让它做什么。**

### 协议三要素

当然，这种协议还是更接近人类语言，机器不能直接读懂，需要进行翻译，翻译的工作教给编译器，也就是程序员常说的 compile。这个过程比较复杂，其中的编译原理非常复杂，我在这里不进行详述。



<img src="趣谈网络协议.assets/e823209e795faacdbb9b557750e7d37d.jpg" alt="img" style="zoom: 25%;" />

但是可以看得出，计算机语言作为程序员控制一台计算机工作的协议，具备了协议的三要素。



- **语法**，就是这一段内容要符合一定的规则和格式。例如，括号要成对，结束要使用分号等。
- **语义**，就是这一段内容要代表某种意义。例如数字减去数字是有意义的，数字减去文本一般来说就没有意义。
- **顺序**，就是先干啥，后干啥。例如，可以先加上某个数值，然后再减去某个数值。



会了计算机语言，你就能够教给一台计算机完成你的工作了。恭喜你，入门了！



## 第2讲 | 网络分层的真实含义是什么？

当你听到什么二层设备、三层设备、四层 LB 和七层 LB 中层的时候，是否有点一头雾水，不知道这些所谓的层，对应的各种协议具体要做什么“工作”？

### 这四个问题你真的懂了吗？

因为教科书或者老师往往会打一个十分不恰当的比喻：为什么网络要分层呀？因为不同的层次之间有不同的沟通方式，这个叫作协议。例如，一家公司也是分“层次”的，分总经理、经理、组长、员工。总经理之间有他们的沟通方式，经理和经理之间也有沟通方式，同理组长和员工。有没有听过类似的比喻？

1、其他层的协议在做啥

那么**第一个问题**来了。请问经理在握手的时候，员工在干什么？很多人听过 TCP 建立连接的**三次握手协议**，也会把它当知识点背诵。同理问你，TCP 在进行三次握手的时候，IP 层和 MAC 层对应都有什么操作呢？

除了上面这个不恰当的比喻，教科书还会列出每个层次所包含的协议，然后开始逐层地去讲这些协议。但是这些协议之间的关系呢？却很少有教科书会讲。

学习第三层的时候会提到，IP 协议里面包含**目标地址**和**源地址。\**第三层里往往还会学习\**路由协议**。路由就像中转站，我们从原始地址 A 到目标地址 D，中间经过两个中转站 A->B->C->D，是通过路由转发的。



2、协议的生命周期

那么**第二个问题**来了。A 知道自己的下一个中转站是 B，那从 A 发出来的包，应该把 B 的 IP 地址放在哪里呢？B 知道自己的下一个中转站是 C，从 B 发出来的包，应该把 C 的 IP 地址放在哪里呢？如果放在 IP 协议中的目标地址，那包到了中转站，怎么知道最终的目的地址是 D 呢？

教科书不会通过场景化的例子，将网络包的生命周期讲出来，所以你就会很困惑，不知道这些协议实际的应用场景是什么。



3、协议非独立的

我**再问你一个问题**。你一定经常听说二层设备、三层设备。二层设备处理的通常是 MAC 层的东西。那我发送一个 HTTP 的包，是在第七层工作的，那是不是不需要经过二层设备？或者即便经过了，二层设备也不处理呢？或者换一种问法，二层设备处理的包里，有没有 HTTP 层的内容呢？



4、显示场景中的协议链路

最终，我想问你**一个综合的问题**。从你的电脑，通过 SSH 登录到公有云主机里面，都需要经历哪些过程？或者说你打开一个电商网站，都需要经历哪些过程？说得越详细越好。



实际情况可能是，很多人回答不上来。尽管对每一层都很熟悉，但是知识点却串不起来。

上面的这些问题，有的在这一节就会有一个解释，有的则会贯穿我们整个课程。好在后面一节中我会举一个贯穿的例子，将很多层的细节讲过后，你很容易就能把这些知识点串起来。



## 第3讲 | ifconfig：最熟悉又陌生的命令行

上一节结尾给你留的一个思考题是，你知道怎么查看 IP 地址吗？

当面试听到这个问题的时候，面试者常常会觉得走错了房间。我面试的是技术岗位啊，怎么问这么简单的问题？

的确，即便没有专业学过计算机的人，只要倒腾过电脑，重装过系统，大多也会知道这个问题的答案：在 Windows 上是 ipconfig，在 Linux 上是 ifconfig。



那你知道在 Linux 上还有什么其他命令可以查看 IP 地址吗？答案是 **ip addr**。如果回答不上来这个问题，那你可能没怎么用过 Linux。



那你知道 ifconfig 和 ip addr 的区别吗？这是一个有关 **net-tools 和 iproute2** 的“历史”故事，你刚来到第三节，暂时不用了解这么细，但这也是一个常考的知识点。



想象一下，你登录进入一个被裁剪过的非常小的 Linux 系统中，发现既没有 ifconfig 命令，也没有 ip addr 命令，你是不是感觉这个系统压根儿没法用？这个时候，你可以自行安装 net-tools 和 iproute2 这两个工具。当然，大多数时候这两个命令是系统自带的。



安装好后，我们来运行一下 ip addr。不出意外，应该会输出下面的内容。

```bash
root@test:~# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff
    inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::f816:3eff:fec7:7975/64 scope link 
       valid_lft forever preferred_lft forever

```

这个命令显示了这台机器上所有的网卡。大部分的网卡都会有一个 IP 地址，当然，这不是必须的。在后面的分享中，我们会遇到没有 IP 地址的情况。



## 第4讲 | DHCP与PXE：IP是怎么来的，又是怎么没的？

上一节，我们讲了 IP 的一些基本概念。如果需要和其他机器通讯，我们就需要一个通讯地址，我们需要给网卡配置这么一个地址。

> DHCP代表动态主机配置协议（Dynamic Host Configuration Protocol），在一个DHCP网络中，有一个称为DHCP服务器的中央设备，它负责管理和分配IP地址。当设备加入网络时，它可以通过DHCP协议向DHCP服务器发送请求，请求一个可用的IP地址。

### 如何配置 IP 地址？

那如何配置呢？如果有相关的知识和积累，你可以用命令行自己配置一个地址。

可以使用 ifconfig，也可以使用 ip addr。

设置好了以后，用这两个命令，将网卡 up 一下，就可以开始工作了。

**使用 net-tools：**

```shell
$ sudo ifconfig eth1 10.0.0.1/24
$ sudo ifconfig eth1 up
```

**使用 iproute2：**

```shell
$ sudo ip addr add 10.0.0.1/24 dev eth1
$ sudo ip link set up eth1
```

你可能会问了，自己配置这个自由度太大了吧，我是不是配置什么都可以？如果配置一个和谁都不搭边的地址呢？例如，旁边的机器都是 192.168.1.x，我非得配置一个 16.158.23.6，会出现什么现象呢？

不会出现任何现象，就是包发不出去呗。为什么发不出去呢？举例说明:

192.168.1.6 就在你这台机器的旁边，甚至是在同一个交换机上，而你把机器的地址设为了 16.158.23.6。在这台机器上，你企图去 ping192.168.1.6，你觉得只要将包发出去，同一个交换机的另一台机器马上就能收到，对不对？

可是 Linux 系统不是这样的，它没你想的那么智能。你用肉眼看到那台机器就在旁边，它则需要根据自己的逻辑进行处理。

还记得我们在第二节说过的原则吗？**只要是在网络上跑的包，都是完整的，可以有下层没上层，绝对不可能有上层没下层。**

所以，你看着它有自己的源 IP 地址 16.158.23.6，也有目标 IP 地址 192.168.1.6，但是包发不出去，这是**因为 MAC 层还没填**。

自己的 MAC 地址自己知道，这个容易。但是目标 MAC 填什么呢？是不是填 192.168.1.6 这台机器的 MAC 地址呢？

当然不是。Linux 首先会判断，要去的这个地址和我是一个网段的吗，或者和我的一个网卡是同一网段的吗？**只有是一个网段的，它才会发送 ARP 请求，获取 MAC 地址**。如果发现不是呢？



**Linux 默认的逻辑是，如果这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。**



如果你配置了网关的话，Linux 会获取网关的 MAC 地址，然后将包发出去。对于 192.168.1.6 这台机器来讲，虽然路过它家门的这个包，目标 IP 是它，但是无奈 MAC 地址不是它的，所以它的网卡是不会把包收进去的。

如果没有配置网关呢？那包压根就发不出去。

如果将网关配置为 192.168.1.6 呢？不可能，Linux 不会让你配置成功的，因为**网关要和当前的网络至少一个网卡是同一个网段的**，怎么可能 16.158.23.6 的网关是 192.168.1.6 呢？



所以，当你需要手动配置一台机器的网络 IP 时，一定要好好问问你的网络管理员。如果在机房里面，要去网络管理员那里申请，让他给你分配一段正确的 IP 地址。当然，真正配置的时候，一定不是直接用命令配置的，而是放在一个配置文件里面。**不同系统的配置文件格式不同，但是无非就是 CIDR、子网掩码、广播地址和网关地址**。



### 动态主机配置协议（DHCP）

原来配置 IP 有这么多门道儿啊。你可能会问了，配置了 IP 之后一般不能变的，配置一个服务端的机器还可以，但是如果是客户端的机器呢？我抱着一台笔记本电脑在公司里走来走去，或者白天来晚上走，每次使用都要配置 IP 地址，那可怎么办？还有人事、行政等非技术人员，如果公司所有的电脑都需要 IT 人员配置，肯定忙不过来啊。

因此，我们需要有一个自动配置的协议，也就是**动态主机配置协议（Dynamic Host Configuration Protocol）**，简称 **DHCP**。



有了这个协议，网络管理员就轻松多了。他只需要配置一段共享的 IP 地址。每一台新接入的机器都通过 DHCP 协议，来这个共享的 IP 地址里申请，然后自动配置好就可以了。等人走了，或者用完了，还回去，这样其他的机器也能用。

所以说，**如果是数据中心里面的服务器，IP 一旦配置好，基本不会变，这就相当于买房自己装修。DHCP 的方式就相当于租房。你不用装修，都是帮你配置好的。你暂时用一下，用完退租就可以了。**



#### 解析 DHCP 的工作方式

当一台机器新加入一个网络的时候，肯定一脸懵，啥情况都不知道，只知道自己的 MAC 地址。怎么办？先吼一句，我来啦，有人吗？这时候的沟通基本靠“吼”。这一步，我们称为 **DHCP Discover。**



新来的机器**使用 IP 地址 0.0.0.0 发送了一个广播包**，目的 IP 地址为 255.255.255.255。广播包封装了 UDP，UDP 封装了 BOOTP。其实 DHCP 是 BOOTP 的增强版，但是如果你去**抓包**的话，很可能看到的名称还是 BOOTP 协议。

在这个广播包里面，新人大声喊：我是新来的（Boot request），我的 MAC 地址是这个，我还没有 IP，谁能给租给我个 IP 地址！



格式就像这样：

<img src="趣谈网络协议.assets/90b4d41ee38e891031705d987d5d8481-17204203507323.jpg" alt="img" style="zoom:50%;" />

如果一个网络管理员在网络里面配置了 **DHCP Server** 的话，他就相当于这些 IP 的管理员。他立刻能知道来了一个“新人”。这个时候，我们可以体会 MAC 地址唯一的重要性了。当一台机器带着自己的 MAC 地址加入一个网络的时候，MAC 是它唯一的身份，如果连这个都重复了，就没办法配置了。



只有 MAC 唯一，IP 管理员才能知道这是一个新人，需要租给它一个 IP 地址，这个过程我们称为 **DHCP Offer**。同时，DHCP Server 为此客户保留为它提供的 IP 地址，从而不会为其他 DHCP 客户分配此 IP 地址。



DHCP Offer 的格式就像这样，里面有给新人分配的地址。

<img src="趣谈网络协议.assets/a52c8c87b925b52059febe9dfcd6be6b.jpg" alt="img" style="zoom:50%;" />

DHCP Server 仍然使用广播地址作为目的地址，因为，此时请求分配 IP 的新人还没有自己的 IP。DHCP Server 回复说，我分配了一个可用的 IP 给你，你看如何？除此之外，服务器还发送了子网掩码、网关和 IP 地址租用期等信息。

新来的机器很开心，它的“吼”得到了回复，并且有人愿意租给它一个 IP 地址了，这意味着它可以在网络上立足了。当然更令人开心的是，如果有多个 DHCP Server，这台新机器会收到多个 IP 地址，简直受宠若惊。

它会选择其中一个 DHCP Offer，一般是最先到达的那个，并且会向网络发送一个 DHCP Request 广播数据包，包中包含客户端的 MAC 地址、接受的租约中的 IP 地址、提供此租约的 DHCP 服务器地址等，并告诉所有 DHCP Server 它将接受哪一台服务器提供的 IP 地址，告诉其他 DHCP 服务器，谢谢你们的接纳，并请求撤销它们提供的 IP 地址，以便提供给下一个 IP 租用请求者。

<img src="趣谈网络协议.assets/cdbcaad24e1a4d24dd724e38f6f043fa.jpg" alt="img" style="zoom:50%;" />

此时，由于还没有得到 DHCP Server 的最后确认，客户端仍然使用 0.0.0.0 为源 IP 地址、255.255.255.255 为目标地址进行广播。在 BOOTP 里面，接受某个 DHCP Server 的分配的 IP。

当 DHCP Server 接收到客户机的 DHCP request 之后，会广播返回给客户机一个 DHCP ACK 消息包，表明已经接受客户机的选择，并将这一 IP 地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。

<img src="趣谈网络协议.assets/cca8b0baa4749bb359e453b1b482e1a9.jpg" alt="img" style="zoom:50%;" />

最终租约达成的时候，还是需要广播一下，让大家都知道。



#### IP 地址的收回和续租

既然是租房子，就是有租期的。租期到了，管理员就要将 IP 收回。

如果不用的话，收回就收回了。就像你租房子一样，如果还要续租的话，不能到了时间再续租，而是要提前一段时间给房东说。DHCP 也是这样。

客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的 DHCP Server 发送 DHCP request 消息包。客户机接收到该服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新的 TCP/IP 参数，更新自己的配置。这样，IP 租用更新就完成了。

好了，一切看起来完美。DHCP 协议大部分人都知道，但是其实里面隐藏着一个细节，很多人可能不会去注意。接下来，我就讲一个有意思的事情：网络管理员不仅能自动分配 IP 地址，还能帮你自动安装操作系统！



### 预启动执行环境（PXE）

普通的笔记本电脑，一般不会有这种需求。因为你拿到电脑时，就已经有操作系统了，即便你自己重装操作系统，也不是很麻烦的事情。但是，在数据中心里就不一样了。数据中心里面的管理员可能一下子就拿到几百台空的机器，一个个安装操作系统，会累死的。

所以管理员希望的不仅仅是自动分配 IP 地址，还要自动安装系统。装好系统之后自动分配 IP 地址，直接启动就能用了，这样当然最好了！

这事儿其实仔细一想，还是挺有难度的。安装操作系统，应该有个光盘吧。数据中心里不能用光盘吧，想了一个办法就是，可以将光盘里面要安装的操作系统放在一个服务器上，让客户端去下载。但是客户端放在哪里呢？它怎么知道去哪个服务器上下载呢？客户端总得安装在一个操作系统上呀，可是这个客户端本来就是用来安装操作系统的呀？

其实，这个过程和操作系统启动的过程有点儿像。首先，启动 BIOS。这是一个特别小的小系统，只能干特别小的一件事情。其实就是读取硬盘的 MBR 启动扇区，将 GRUB 启动起来；然后将权力交给 GRUB，GRUB 加载内核、加载作为根文件系统的 initramfs 文件；然后将权力交给内核；最后内核启动，初始化整个操作系统。



那我们安装操作系统的过程，只能插在 BIOS 启动之后了。因为没安装系统之前，连启动扇区都没有。因而这个过程叫做**预启动执行环境（Pre-boot Execution Environment）**，简称 **PXE。**



PXE 协议分为客户端和服务器端，由于还没有操作系统，只能先把客户端放在 BIOS 里面。当计算机启动时，BIOS 把 PXE 客户端调入内存里面，就可以连接到服务端做一些操作了。

首先，PXE 客户端自己也需要有个 IP 地址。因为 PXE 的客户端启动起来，就可以发送一个 DHCP 的请求，让 DHCP Server 给它分配一个地址。PXE 客户端有了自己的地址，那它怎么知道 PXE 服务器在哪里呢？对于其他的协议，都好办，要有人告诉他。例如，告诉浏览器要访问的 IP 地址，或者在配置中告诉它；例如，微服务之间的相互调用。

但是 PXE 客户端启动的时候，啥都没有。好在 DHCP Server 除了分配 IP 地址以外，还可以做一些其他的事情。这里有一个 DHCP Server 的一个样例配置：

```
ddns-update-style interim;
ignore client-updates;
allow booting;
allow bootp;
subnet 192.168.1.0 netmask 255.255.255.0
{
option routers 192.168.1.1;
option subnet-mask 255.255.255.0;
option time-offset -18000;
default-lease-time 21600;
max-lease-time 43200;
range dynamic-bootp 192.168.1.240 192.168.1.250;
filename "pxelinux.0";
next-server 192.168.1.180;
}
```

按照上面的原理，默认的 DHCP Server 是需要配置的，无非是我们配置 IP 的时候所需要的 IP 地址段、子网掩码、网关地址、租期等。如果想使用 PXE，则需要配置 next-server，指向 PXE 服务器的地址，另外要配置初始启动文件 filename。

这样 PXE 客户端启动之后，发送 DHCP 请求之后，除了能得到一个 IP 地址，还可以知道 PXE 服务器在哪里，也可以知道如何从 PXE 服务器上下载某个文件，去初始化操作系统。



#### 解析 PXE 的工作过程

接下来我们来详细看一下 PXE 的工作过程。



首先，启动 PXE 客户端。第一步是通过 DHCP 协议告诉 DHCP Server，我刚来，一穷二白，啥都没有。DHCP Server 便租给它一个 IP 地址，同时也给它 PXE 服务器的地址、启动文件 pxelinux.0。

其次，PXE 客户端知道要去 PXE 服务器下载这个文件后，就可以初始化机器。于是便开始下载，下载的时候使用的是 TFTP 协议。所以 PXE 服务器上，往往还需要有一个 TFTP 服务器。PXE 客户端向 TFTP 服务器请求下载这个文件，TFTP 服务器说好啊，于是就将这个文件传给它。

然后，PXE 客户端收到这个文件后，就开始执行这个文件。这个文件会指示 PXE 客户端，向 TFTP 服务器请求计算机的配置信息 pxelinux.cfg。TFTP 服务器会给 PXE 客户端一个配置文件，里面会说内核在哪里、initramfs 在哪里。PXE 客户端会请求这些文件。

最后，启动 Linux 内核。一旦启动了操作系统，以后就啥都好办了。

<img src="趣谈网络协议.assets/bbc2b660bba0ad00b5d1179db158498e.jpg" alt="img" style="zoom: 25%;" />



### 小結

总结一下今天的内容：

- DHCP 协议主要是用来给客户租用 IP 地址，和房产中介很像，要商谈、签约、续租，广播还不能“抢单”；
- DHCP 协议能给客户推荐“装修队”PXE，能够安装操作系统，这个在云计算领域大有用处。

最后，学完了这一节，给你留两个思考题吧。

1. PXE 协议可以用来安装操作系统，但是如果每次重启都安装操作系统，就会很麻烦。你知道如何使得第一次安装操作系统，后面就正常启动吗？
2. 现在上网很简单了，买个家用路由器，连上 WIFI，给 DHCP 分配一个 IP 地址，就可以上网了。那你是否用过更原始的方法自己组过简单的网呢？说来听听。



# 第二模块 底层网络知识详解：从二层到三层



## 第5讲 | 从物理层到MAC层：如何在宿舍里自己组网玩联机游戏？

一旦机器有了 IP，就可以在网络的环境里和其他的机器展开沟通了。

故事就从我的大学宿舍开始讲起吧。作为一个八零后，我要暴露年龄了。

我们宿舍四个人，大一的时候学校不让上网，不给开通网络。但是，宿舍有一个人比较有钱，率先买了一台电脑。那买了电脑干什么呢？

首先，有单机游戏可以打，比如说《拳皇》。两个人用一个键盘，照样打得火热。后来有第二个人买了电脑，那两台电脑能不能连接起来呢？你会说，当然能啊，买个路由器不就行了。

现在一台家用路由器非常便宜，一百多块的事情。那时候路由器绝对是奢侈品。一直到大四，我们宿舍都没有买路由器。可能是因为那时候技术没有现在这么发达，导致我对网络技术的认知是逐渐深入的，而且每一层都是实实在在接触到的。



### 第一层（物理层）

使用路由器，是在第三层上。我们先从第一层物理层开始说。



物理层能折腾啥？现在的同学可能想不到，我们当时去学校配电脑的地方买网线，卖网线的师傅都会问，你的网线是要电脑连电脑啊，还是电脑连网口啊？

我们要的是电脑连电脑。这种方式就是一根网线，有两个头。一头插在一台电脑的网卡上，另一头插在另一台电脑的网卡上。但是在当时，普通的网线这样是通不了的，所以水晶头要做交叉线，用的就是所谓的 **1－3**、**2－6 交叉接法**。



水晶头的第 1、2 和第 3、6 脚，它们分别起着收、发信号的作用。将一端的 1 号和 3 号线、2 号和 6 号线互换一下位置，就能够在物理层实现一端发送的信号，另一端能收到。



当然电脑连电脑，除了网线要交叉，还需要配置这两台电脑的 IP 地址、子网掩码和默认网关。这三个概念上一节详细描述过了。要想两台电脑能够通信，这三项必须配置成为一个网络，可以一个是 192.168.0.1/24，另一个是 192.168.0.2/24，否则是不通的。



这里我想问你一个问题，两台电脑之间的网络包，包含 MAC 层吗？当然包含，要完整。IP 层要封装了 MAC 层才能将包放入物理层。

到此为止，两台电脑已经构成了一个最小的**局域网**，也即 **LAN。**可以玩联机局域网游戏啦！



等到第三个哥们也买了一台电脑，怎么把三台电脑连在一起呢？

先别说交换机，当时交换机也贵。有一个叫做 **Hub** 的东西，也就是**集线器**。这种设备有多个口，可以将宿舍里的多台电脑连接起来。但是，和交换机不同，集线器没有大脑，它完全在物理层工作。它会将自己收到的每一个字节，都复制到其他端口上去。**这是第一层物理层联通的方案**。



### 第二层（数据链路层）

你可能已经发现问题了。Hub 采取的是广播的模式，如果每一台电脑发出的包，宿舍的每个电脑都能收到，那就麻烦了。这就需要解决几个问题：

1. 这个包是发给谁的？谁应该接收？
2. 大家都在发，会不会产生混乱？有没有谁先发、谁后发的规则？
3. 如果发送的时候出现了错误，怎么办？

这几个问题，都是第二层，数据链路层，也即 MAC 层要解决的问题。**MAC** 的全称是 **Medium Access Control**，即**媒体访问控制。\**控制什么呢？其实就是控制在往媒体上发数据的时候，谁先发、谁后发的问题。防止发生混乱。这解决的是第二个问题。这个问题中的规则，学名叫\**多路访问**。有很多算法可以解决这个问题。就像车管所管束马路上跑的车，能想的办法都想过了。



比如接下来这三种方式：

- 方式一：分多个车道。每个车一个车道，你走你的，我走我的。这在计算机网络里叫作**信道划分；**
- 方式二：今天单号出行，明天双号出行，轮着来。这在计算机网络里叫作**轮流协议；**
- 方式三：不管三七二十一，有事儿先出门，发现特堵，就回去。错过高峰再出。我们叫作**随机接入协议。**著名的以太网，用的就是这个方式。



解决了第二个问题，就是解决了媒体接入控制的问题，MAC 的问题也就解决好了。这和 MAC 地址没什么关系。

接下来要解决第一个问题：发给谁，谁接收？这里用到一个物理地址，叫作**链路层地址。\**但是因为第二层主要解决媒体接入控制的问题，所以它常被称为\** MAC 地址**。

解决第一个问题就牵扯到第二层的网络包**格式**。对于以太网，第二层的最开始，就是目标的 MAC 地址和源的 MAC 地址。

<img src="趣谈网络协议.assets/8072e4885b0cbc6cb5384ea84d487e41.jpg" alt="img" style="zoom: 33%;" />



接下来是**类型**，大部分的类型是 IP 数据包，然后 IP 里面包含 TCP、UDP，以及 HTTP 等，这都是里层封装的事情。

有了这个目标 MAC 地址，数据包在链路上广播，MAC 的网卡才能发现，这个包是给它的。MAC 的网卡把包收进来，然后打开 IP 包，发现 IP 地址也是自己的，再打开 TCP 包，发现端口是自己，也就是 80，而 nginx 就是监听 80。

于是将请求提交给 nginx，nginx 返回一个网页。然后将网页需要发回请求的机器。然后层层封装，最后到 MAC 层。因为来的时候有源 MAC 地址，返回的时候，源 MAC 就变成了目标 MAC，再返给请求的机器。

对于以太网，第二层的最后面是 **CRC**，也就是**循环冗余检测**。通过 XOR 异或的算法，来计算整个包是否在发送的过程中出现了错误，主要解决第三个问题。



这里还有一个没有解决的问题，当源机器知道目标机器的时候，可以将目标地址放入包里面，如果不知道呢？一个广播的网络里面接入了 N 台机器，我怎么知道每个 MAC 地址是谁呢？这就是 **ARP 协议**，也就是已知 IP 地址，求 MAC 地址的协议。

<img src="趣谈网络协议.assets/561324a275460a4abbc15e73a476e037.jpg" alt="img" style="zoom:33%;" />

在一个局域网里面，当知道了 IP 地址，不知道 MAC 怎么办呢？靠“吼”（广播）。

<img src="https://static001.geekbang.org/resource/image/48/ad/485b5902066131de547acbcf3579c4ad.jpg?wh=2623*2203" alt="img" style="zoom:33%;" />

广而告之，发送一个广播包，谁是这个 IP 谁来回答。具体询问和回答的报文就像下面这样：

<img src="趣谈网络协议.assets/1f7cfe6046c5df606cfbb6bb6c7f899b.jpg" alt="img" style="zoom:50%;" />

为了避免每次都用 ARP 请求，机器本地也会进行 ARP 缓存。当然机器会不断地上线下线，IP 也可能会变，所以 ARP 的 MAC 地址缓存过一段时间就会过期。



### 局域网

好了，至此我们宿舍四个电脑就组成了一个局域网。用 Hub 连接起来，就可以玩局域网版的《魔兽争霸》了。

<img src="趣谈网络协议.assets/33d180e376439ca10e3f126eb2e36bac.jpg" alt="img" style="zoom: 50%;" />

打开游戏，进入“局域网选项”，选择一张地图，点击“创建游戏”，就可以进入这张地图的房间中。等同一个局域网里的其他小伙伴加入后，游戏就可以开始了。



这种组网的方法，对一个宿舍来说没有问题，但是一旦机器数目增多，问题就出现了。因为 Hub 是广播的，不管某个接口是否需要，所有的 Bit 都会被发送出去，然后让主机来判断是不是需要。这种方式路上的车少就没问题，车一多，产生冲突的概率就提高了。而且把不需要的包转发过去，纯属浪费。看来 Hub 这种不管三七二十一都转发的设备是不行了，需要点儿智能的。因为每个口都只连接一台电脑，这台电脑又不怎么换 IP 和 MAC 地址，只要记住这台电脑的 MAC 地址，如果目标 MAC 地址不是这台电脑的，这个口就不用转发了。

谁能知道目标 MAC 地址是否就是连接某个口的电脑的 MAC 地址呢？这就需要一个能把 MAC 头拿下来，检查一下目标 MAC 地址，然后根据策略转发的设备，按第二节课中讲过的，这个设备显然是个二层设备，我们称为**交换机**。



交换机怎么知道每个口的电脑的 MAC 地址呢？这需要**交换机会学习**。

一台 MAC1 电脑将一个包发送给另一台 MAC2 电脑，当这个包到达交换机的时候，一开始交换机也不知道 MAC2 的电脑在哪个口，所以没办法，它只能将包转发给除了来的那个口之外的其他所有的口。但是，这个时候，交换机会干一件非常聪明的事情，就是交换机会记住，MAC1 是来自一个明确的口。以后有包的目的地址是 MAC1 的，直接发送到这个口就可以了。

当交换机作为一个关卡一样，过了一段时间之后，就有了整个网络的一个结构了，这个时候，基本上不用广播了，全部可以准确转发。当然，每个机器的 IP 地址会变，所在的口也会变，因而交换机上的学习的结果，我们称为**转发表**，是有一个**过期时间**的。



有了交换机，一般来说，你接个几十台、上百台机器打游戏，应该没啥问题。你可以组个战队了。能上网了，就可以玩网游了。



### 小结

好了，今天的内容差不多了，我们来总结一下，有三个重点需要你记住：



第一，MAC 层是用来解决多路访问的堵车问题的；

第二，ARP 是通过吼的方式来寻找目标 MAC 地址的，吼完之后记住一段时间，这个叫作缓存；

第三，交换机是有 MAC 地址学习能力的，学完了它就知道谁在哪儿了，不用广播了。



最后，给你留两个思考题吧。

1. 在二层中我们讲了 ARP 协议，即已知 IP 地址求 MAC；还有一种 RARP 协议，即已知 MAC 求 IP 的，你知道它可以用来干什么吗？
2. 如果一个局域网里面有多个交换机，ARP 广播的模式会出现什么问题呢？

> chatGPT

1、RARP（Reverse Address Resolution Protocol）是一种网络协议，用于根据已知的MAC地址获取对应的IP地址。与ARP协议相反，ARP用于已知IP地址求MAC地址。

RARP协议主要用于早期的计算机网络中，特别是在无盘工作站（diskless workstation）中。无盘工作站是指没有本地存储设备（如硬盘）的计算机，它们依赖网络来获取操作系统和其他必要的软件。

RARP的主要用途是在无盘工作站启动时，通过向网络中的RARP服务器发送请求，获取自己的IP地址。无盘工作站通常只有MAC地址，没有预先配置的IP地址。通过使用RARP协议，无盘工作站可以向RARP服务器发送自己的MAC地址，并请求分配一个IP地址。RARP服务器会根据MAC地址映射表，将对应的IP地址分配给无盘工作站，使其能够在网络中正常通信。

需要注意的是，随着技术的发展，RARP协议已经逐渐被其他更先进的协议所取代，如BOOTP（Bootstrap Protocol）和DHCP（Dynamic Host Configuration Protocol）。这些协议提供了更多的功能和灵活性，不仅可以为无盘工作站分配IP地址，还可以提供其他网络配置参数，如子网掩码、默认网关等。

总之，RARP协议主要用于无盘工作站在启动时获取IP地址，以便能够通过网络进行通信。然而，随着技术的进步，RARP的使用已经相对较少，被更先进的协议所取代。



2、当一个局域网中存在多个交换机时，ARP广播的模式可能会引发以下问题：

1. **广播风暴**：当一个主机发送ARP广播请求时，广播会在整个局域网中传播，包括所有连接的交换机。如果局域网中的交换机数量较多，广播请求会被复制和转发多次，导致网络中的广播风暴。广播风暴会占用大量的网络带宽和交换机处理能力，导致网络性能下降。
2. **ARP表冲突**：每个交换机都会维护一个ARP表，用于记录MAC地址和对应的端口。当一个主机发送ARP广播请求时，所有连接的交换机都会更新自己的ARP表。如果多个主机同时发送ARP广播请求，交换机的ARP表可能会出现冲突，导致通信错误或延迟。
3. **ARP欺骗攻击**：ARP广播的模式容易受到ARP欺骗攻击的影响。恶意用户可以发送伪造的ARP响应，欺骗其他主机将其MAC地址与错误的IP地址进行关联。这可能导致通信中断、数据泄露或中间人攻击等安全问题。

为了解决这些问题，现代的网络设计通常采用VLAN（Virtual Local Area Network）和交换机间的VLAN划分，以减少广播范围。此外，网络管理员还可以使用ARP缓存和静态ARP条目来减少ARP广播的频率，并采取安全措施来防止ARP欺骗攻击。



## 第6讲 | 交换机与VLAN：办公室太复杂，我要回学校

上一次，我们在宿舍里组建了一个本地的局域网 LAN，可以愉快地玩游戏了。这是一个非常简单的场景，因为只有一台交换机，电脑数目很少。今天，让我们切换到一个稍微复杂一点的场景，办公室。

### 拓扑结构是怎么形成的？

我们常见到的办公室大多是一排排的桌子，每个桌子都有网口，一排十几个座位就有十几个网口，一个楼层就会有几十个甚至上百个网口。如果算上所有楼层，这个场景自然比你宿舍里的复杂多了。具体哪里复杂呢？我来给你具体讲解。



首先，这个时候，一个交换机肯定不够用，需要多台交换机，交换机之间连接起来，就形成一个稍微复杂的**拓扑结构**。

我们先来看**两台交换机**的情形。两台交换机连接着三个局域网，每个局域网上都有多台机器。如果机器 1 只知道机器 4 的 IP 地址，当它想要访问机器 4，把包发出去的时候，它必须要知道机器 4 的 MAC 地址。

<img src="趣谈网络协议.assets/0867321c36cc52bd3dd4d7622583fa29.jpg" alt="img" style="zoom: 25%;" />

于是机器 1 发起广播，机器 2 收到这个广播，但是这不是找它的，所以没它什么事。交换机 A 一开始是不知道任何拓扑信息的，在它收到这个广播后，采取的策略是，除了广播包来的方向外，它还要转发给其他所有的网口。于是机器 3 也收到广播信息了，但是这和它也没什么关系。

当然，交换机 B 也是能够收到广播信息的，但是这时候它也是不知道任何拓扑信息的，因而也是进行广播的策略，将包转发到局域网三。这个时候，机器 4 和机器 5 都收到了广播信息。机器 4 主动响应说，这是找我的，这是我的 MAC 地址。于是一个 ARP 请求就成功完成了。



在上面的过程中，交换机 A 和交换机 B 都是能够学习到这样的信息：机器 1 是在左边这个网口的。当了解到这些拓扑信息之后，情况就好转起来。当机器 2 要访问机器 1 的时候，机器 2 并不知道机器 1 的 MAC 地址，所以机器 2 会发起一个 ARP 请求。这个广播消息会到达机器 1，也同时会到达交换机 A。这个时候交换机 A 已经知道机器 1 是不可能在右边的网口的，所以这个广播信息就不会广播到局域网二和局域网三。

当机器 3 要访问机器 1 的时候，也需要发起一个广播的 ARP 请求。这个时候交换机 A 和交换机 B 都能够收到这个广播请求。交换机 A 当然知道主机 A 是在左边这个网口的，所以会把广播消息转发到局域网一。同时，交换机 B 收到这个广播消息之后，由于它知道机器 1 是不在右边这个网口的，所以不会将消息广播到局域网三。



### 如何解决常见的环路问题？

这样看起来，两台交换机工作得非常好。随着办公室越来越大，交换机数目肯定越来越多。当整个拓扑结构复杂了，这么多网线，绕过来绕过去，不可避免地会出现一些意料不到的情况。其中常见的问题就是**环路问题**。

例如这个图，当两个交换机将两个局域网同时连接起来的时候。你可能会觉得，这样反而有了高可用性。但是却不幸地出现了环路。出现了环路会有什么结果呢？



<img src="趣谈网络协议.assets/1f909508a8253d4842ffe962883421ea.jpg" alt="img" style="zoom:33%;" />

但是问题来了，这两个交换机还是都能够收到广播包的。交换机 A 一开始是不知道机器 2 在哪个局域网的，所以它会把广播消息放到局域网二，在局域网二广播的时候，交换机 B 右边这个网口也是能够收到广播消息的。交换机 B 会将这个广播信息发送到局域网一。局域网一的这个广播消息，又会到达交换机 A 左边的这个接口。交换机 A 这个时候还是不知道机器 2 在哪个局域网，于是将广播包又转发到局域网二。左转左转左转，好像是个圈哦。

可能有人会说，当两台交换机都能够逐渐学习到拓扑结构之后，是不是就可以了？



别想了，压根儿学不会的。机器 1 的广播包到达交换机 A 和交换机 B 的时候，本来两个交换机都学会了机器 1 是在局域网一的，但是当交换机 A 将包广播到局域网二之后，交换机 B 右边的网口收到了来自交换机 A 的广播包。根据学习机制，这彻底损坏了交换机 B 的三观，刚才机器 1 还在左边的网口呢，怎么又出现在右边的网口呢？哦，那肯定是机器 1 换位置了，于是就误会了，交换机 B 就学会了，机器 1 是从右边这个网口来的，把刚才学习的那一条清理掉。同理，交换机 A 右边的网口，也能收到交换机 B 转发过来的广播包，同样也误会了，于是也学会了，机器 1 从右边的网口来，不是从左边的网口来。

然而当广播包从左边的局域网一广播的时候，两个交换机再次刷新三观，原来机器 1 是在左边的，过一会儿，又发现不对，是在右边的，过一会，又发现不对，是在左边的。

这还是一个包转来转去，每台机器都会发广播包，交换机转发也会复制广播包，当广播包越来越多的时候，按照上一节讲过一个共享道路的算法，也就是路会越来越堵，最后谁也别想走。所以，必须有一个方法解决环路的问题，怎么破除环路呢？





#### STP 协议中那些难以理解的概念

在数据结构中，有一个方法叫做**最小生成树**。有环的我们常称为**图**。将图中的环破了，就生成了**树**。在计算机网络中，生成树的算法叫作 **STP**，全称 **Spanning Tree Protocol**（生成树协议）。

STP 协议比较复杂，一开始很难看懂，但是其实这是一场血雨腥风的武林比武或者华山论剑，最终决出五岳盟主的方式。

<img src="趣谈网络协议.assets/47baa69073b38357e0ae3f88ff74dd23.jpg" alt="img" style="zoom: 25%;" />

在 STP 协议里面有很多概念，译名就非常拗口，但是我一作比喻，你很容易就明白了。

- **Root Bridge**，也就是**根交换机**。这个比较容易理解，可以比喻为“掌门”交换机，是某棵树的老大，是掌门，最大的大哥。
- **Designated Bridges**，有的翻译为**指定交换机**。这个比较难理解，可以想像成一个“小弟”，对于树来说，就是一棵树的树枝。所谓“指定”的意思是，我拜谁做大哥，其他交换机通过这个交换机到达根交换机，也就相当于拜他做了大哥。这里注意是树枝，不是叶子，因为叶子往往是主机。
- **Bridge Protocol Data Units （BPDU）** ，**网桥协议数据单元**。可以比喻为“相互比较实力”的协议。行走江湖，比的就是武功，拼的就是实力。当两个交换机碰见的时候，也就是相连的时候，就需要互相比一比内力了。BPDU 只有掌门能发，已经隶属于某个掌门的交换机只能传达掌门的指示。
- **Priority Vector**，**优先级向量**。可以比喻为实力 （值越小越牛）。实力是啥？就是一组 ID 数目，[Root Bridge ID, Root Path Cost, Bridge ID, and Port ID]。为什么这样设计呢？这是因为要看怎么来比实力。先看 Root Bridge ID。拿出老大的 ID 看看，发现掌门一样，那就是师兄弟；再比 Root Path Cost，也即我距离我的老大的距离，也就是拿和掌门关系比，看同一个门派内谁和老大关系铁；最后比 Bridge ID，比我自己的 ID，拿自己的本事比。



#### STP 的工作过程是怎样的？

接下来，我们来看 STP 的工作过程。

一开始，江湖纷争，异常混乱。大家都觉得自己是掌门，谁也不服谁。于是，所有的交换机都认为自己是掌门，每个网桥都被分配了一个 ID。这个 ID 里有管理员分配的优先级，当然网络管理员知道哪些交换机贵，哪些交换机好，就会给它们分配高的优先级。这种交换机生下来武功就很高，起步就是乔峰。

<img src="趣谈网络协议.assets/66237be156bea81a801dca8d507c1e2b.jpg" alt="img" style="zoom:33%;" />

既然都是掌门，互相都连着网线，就互相发送 BPDU 来比功夫呗。这一比就发现，有人是岳不群，有人是封不平，赢的接着当掌门，输的就只好做小弟了。当掌门的还会继续发 BPDU，而输的人就没有机会了。它们只有在收到掌门发的 BPDU 的时候，转发一下，表示服从命令。

<img src="趣谈网络协议.assets/5da50b7e328ea3cf8f90430f1deb3f47.jpg" alt="img" style="zoom:33%;" />

数字表示优先级。就像这个图，5 和 6 碰见了，6 的优先级低，所以乖乖做小弟。于是一个小门派形成，5 是掌门，6 是小弟。其他诸如 1-7、2-8、3-4 这样的小门派，也诞生了。于是江湖出现了很多小的门派，小的门派，接着合并。



合并的过程会出现以下四种情形，我分别来介绍。

##### 情形一：掌门遇到掌门

当 5 碰到了 1，掌门碰见掌门，1 觉得自己是掌门，5 也刚刚跟别人 PK 完成为掌门。这俩掌门比较功夫，最终 1 胜出。于是输掉的掌门 5 就会率领所有的小弟归顺。结果就是 1 成为大掌门。

<img src="趣谈网络协议.assets/fb0e19a14e00b5825dac11d359ffe056.jpg" alt="img" style="zoom:25%;" />

##### 情形二：同门相遇

同门相遇可以是掌门与自己的小弟相遇，这说明存在“环”了。这个小弟已经通过其他门路拜在你门下，结果你还不认识，就 PK 了一把。结果掌门发现这个小弟功夫不错，不应该级别这么低，就把它招到门下亲自带，那这个小弟就相当于升职了。

我们再来看，假如 1 和 6 相遇。6 原来就拜在 1 的门下，只不过 6 的上司是 5，5 的上司是 1。1 发现，6 距离我才只有 2，比从 5 这里过来的 5（=4+1）近多了，那 6 就直接汇报给我吧。于是，5 和 6 分别汇报给 1。

<img src="趣谈网络协议.assets/1ef3c9fb5b7d386c519402202233a8d8.jpg" alt="img" style="zoom:25%;" />

同门相遇还可以是小弟相遇。这个时候就要比较谁和掌门的关系近，当然近的当大哥。刚才 5 和 6 同时汇报给 1 了，后来 5 和 6 在比较功夫的时候发现，5 你直接汇报给 1 距离是 4，如果 5 汇报给 6 再汇报给 1，距离只有 2+1=3，所以 5 干脆拜 6 为上司。



##### 情形三：掌门与其他帮派小弟相遇

小弟拿本帮掌门和这个掌门比较，赢了，这个掌门拜入门来。输了，会拜入新掌门，并且逐渐拉拢和自己连接的兄弟，一起弃暗投明。

<img src="趣谈网络协议.assets/8e852604ac81ab453115470edb9e70da.jpg" alt="img" style="zoom:25%;" />

例如，2 和 7 相遇，虽然 7 是小弟，2 是掌门。就个人武功而言，2 比 7 强，但是 7 的掌门是 1，比 2 牛，所以没办法，2 要拜入 7 的门派，并且连同自己的小弟都一起拜入。



##### 情形四：不同门小弟相遇

各自拿掌门比较，输了的拜入赢的门派，并且逐渐将与自己连接的兄弟弃暗投明。

<img src="趣谈网络协议.assets/fdab777fb2f69666e1fd5d838278b1bf.jpg" alt="img" style="zoom:25%;" />

例如，5 和 4 相遇。虽然 4 的武功好于 5，但是 5 的掌门是 1，比 4 牛，于是 4 拜入 5 的门派。后来当 3 和 4 相遇的时候，3 发现 4 已经叛变了，4 说我现在老大是 1，比你牛，要不你也来吧，于是 3 也拜入 1。



最终，生成一棵树，武林一统，天下太平。但是天下大势，分久必合，合久必分，天下统一久了，也会有相应的问题。



### 如何解决广播问题和安全问题？

毕竟机器多了，交换机也多了，就算交换机比 Hub 智能一些，但是还是难免有广播的问题，一大波机器，相关的部门、不相关的部门，广播一大堆，性能就下来了。就像一家公司，创业的时候，一二十个人，坐在一个会议室，有事情大家讨论一下，非常方便。但是如果变成了 50 个人，全在一个会议室里面吵吵，就会乱得不得了。



你们公司有不同的部门，有的部门需要保密的，比如人事部门，肯定要讨论升职加薪的事儿。由于在同一个广播域里面，很多包都会在一个局域网里面飘啊飘，碰到了一个会抓包的程序员，就能抓到这些包，如果没有加密，就能看到这些敏感信息了。还是上面的例子，50 个人在一个会议室里面七嘴八舌地讨论，其中有两个 HR，那他们讨论的问题，肯定被其他人偷偷听走了。

那咋办，分部门，分会议室呗。那我们就来看看怎么分。



有两种分的方法，一个是**物理隔离**。每个部门设一个单独的会议室，对应到网络方面，就是每个部门有单独的交换机，配置单独的子网，这样部门之间的沟通就需要路由器了。路由器咱们还没讲到，以后再说。这样的问题在于，有的部门人多，有的部门人少。人少的部门慢慢人会变多，人多的部门也可能人越变越少。如果每个部门有单独的交换机，口多了浪费，少了又不够用。



另外一种方式是**虚拟隔离**，就是用我们常说的 **VLAN**，或者叫**虚拟局域网**。使用 VLAN，一个交换机上会连属于多个局域网的机器，那交换机怎么区分哪个机器属于哪个局域网呢？

<img src="趣谈网络协议.assets/ba720f6988558f95c381f4deaab11660.jpg" alt="img" style="zoom: 33%;" />

我们只需要在原来的二层的头上加一个 TAG，里面有一个 VLAN ID，一共 12 位。为什么是 12 位呢？因为 12 位可以划分 4096 个 VLAN。这样是不是还不够啊。现在的情况证明，目前云计算厂商里面绝对不止 4096 个用户。当然每个用户需要一个 VLAN 了啊，怎么办呢，这个我们在后面的章节再说。

如果我们买的交换机是支持 VLAN 的，当这个交换机把二层的头取下来的时候，就能够识别这个 VLAN ID。这样只有相同 VLAN 的包，才会互相转发，不同 VLAN 的包，是看不到的。这样广播问题和安全问题就都能够解决了。

<img src="趣谈网络协议.assets/5c207a6e2c1c9881823b04e648f4ba4a.jpg" alt="img" style="zoom:33%;" />

我们可以设置交换机每个口所属的 VLAN。如果某个口坐的是程序员，他们属于 VLAN 10；如果某个口坐的是人事，他们属于 VLAN 20；如果某个口坐的是财务，他们属于 VLAN 30。这样，财务发的包，交换机只会转发到 VLAN 30 的口上。程序员啊，你就监听 VLAN 10 吧，里面除了代码，啥都没有。

而且对于交换机来讲，每个 VLAN 的口都是可以重新设置的。一个财务走了，把他所在座位的口从 VLAN 30 移除掉，来了一个程序员，坐在财务的位置上，就把这个口设置为 VLAN 10，十分灵活。

有人会问交换机之间怎么连接呢？将两个交换机连接起来的口应该设置成什么 VLAN 呢？对于支持 VLAN 的交换机，有一种口叫作 **Trunk 口**。它可以转发属于任何 VLAN 的口。交换机之间可以通过这种口相互连接。



好了，解决这么多交换机连接在一起的问题，办公室的问题似乎搞定了。然而这只是一般复杂的场景，因为你能接触到的网络，到目前为止，不管是你的台式机，还是笔记本所连接的网络，对于带宽、高可用等都要求不高。就算出了问题，一会儿上不了网，也不会有什么大事。

我们在宿舍、学校或者办公室，经常会访问一些网站，这些网站似乎永远不会“挂掉”。那是因为这些网站都生活在一个叫做数据中心的地方，那里的网络世界更加复杂。在后面的章节，我会为你详细讲解。





### 小结

这里来总结一下：

- 当交换机的数目越来越多的时候，会遭遇环路问题，让网络包迷路，这就需要使用 STP 协议，通过华山论剑比武的方式，将有环路的图变成没有环路的树，从而解决环路问题。
- 交换机数目多会面临隔离问题，可以通过 VLAN 形成虚拟局域网，从而解决广播问题和安全问题。

最后，给你留两个思考题。

1. STP 协议能够很好地解决环路问题，但是也有它的缺点，你能举几个例子吗？
2. 在一个比较大的网络中，如果两台机器不通，你知道应该用什么方式调试吗？

> chatGPT

1、STP（Spanning Tree Protocol）是一种用于解决网络中的环路问题的协议。尽管STP在环路消除方面非常有效，但它也存在一些缺点，以下是几个例子：

1. 收敛时间：STP的一个主要缺点是它的收敛时间较长。当网络中发生链路故障或拓扑变化时，STP需要一定的时间来重新计算并建立新的拓扑。在这个过程中，网络中的某些路径可能会被阻塞，导致数据包丢失或延迟。尤其在大型网络中，STP的收敛时间可能会更长，影响网络的可用性和性能。
2. 带宽利用率低：STP的目标是消除环路，确保网络中没有冗余路径。然而，这也意味着某些链路将被阻塞，无法用于数据传输。这导致了带宽利用率的降低，特别是在具有多个冗余路径的网络中。虽然STP的目的是确保网络的稳定性，但它可能会牺牲一些带宽。
3. 单点故障：STP的运行依赖于一个根交换机（Root Switch），它是网络中的主要决策者。如果根交换机发生故障，整个网络可能会受到影响。此外，STP还依赖于BPDU（Bridge Protocol Data Unit）消息的传输，如果BPDU消息无法正常传输或被篡改，可能会导致STP的错误行为或安全问题。
4. 配置复杂性：STP的配置相对复杂，特别是在大型网络中。网络管理员需要正确配置各个交换机的优先级、端口成本等参数，以确保STP的正常运行。此外，当需要进行网络扩展或拓扑变更时，STP的重新配置可能会带来一定的挑战。

尽管STP存在一些缺点，但它仍然是解决环路问题的重要协议。随着技术的发展，出现了一些改进的STP版本，如RSTP（Rapid Spanning Tree Protocol）和MSTP（Multiple Spanning Tree Protocol），它们在一定程度上解决了STP的一些缺点，并提供更快的收敛时间和更好的带宽利用率。



## 第7讲 | ICMP与ping：投石问路的侦察兵

无论是在宿舍，还是在办公室，或者运维一个数据中心，我们常常会遇到网络不通的问题。那台机器明明就在那里，你甚至都可以通过机器的终端连上去看。它看着好好的，可是就是连不上去，究竟是哪里出了问题呢？

### ICMP 协议的格式

一般情况下，你会想到 ping 一下。那你知道 ping 是如何工作的吗？

ping 是基于 ICMP 协议工作的。**ICMP** 全称 **Internet Control Message Protocol**，就是**互联网控制报文协议**。这里面的关键词是“控制”，那具体是怎么控制的呢？



网络包在异常复杂的网络环境中传输时，常常会遇到各种各样的问题。当遇到问题的时候，总不能“死个不明不白”，要传出消息来，报告情况，这样才可以调整传输策略。这就相当于我们经常看到的电视剧里，古代行军的时候，为将为帅者需要通过侦察兵、哨探或传令兵等人肉的方式来掌握情况，控制整个战局。

**ICMP 报文是封装在 IP 包里面的**。因为传输指令的时候，肯定需要源地址和目标地址。它本身非常简单。因为作为侦查兵，要轻装上阵，不能携带大量的包袱。



<img src="趣谈网络协议.assets/201589bb205c5b00ad42e0081aa46fe2.jpg" alt="img" style="zoom:50%;" />

ICMP 报文有很多的类型，不同的类型有不同的代码。**最常用的类型是主动请求为 8，主动请求的应答为 0**。



### 查询报文类型

我们经常在电视剧里听到这样的话：主帅说，来人哪！前方战事如何，快去派人打探，一有情况，立即通报！



这种是主帅发起的，主动查看敌情，对应 ICMP 的**查询报文类型**。例如，常用的 **ping 就是查询报文，是一种主动请求，并且获得主动应答的 ICMP 协议。**所以，ping 发的包也是符合 ICMP 协议格式的，只不过它在后面增加了自己的格式。



对 ping 的主动请求，进行网络抓包，称为 **ICMP ECHO REQUEST。\**同理主动请求的回复，称为\** ICMP ECHO REPLY**。比起原生的 ICMP，这里面多了两个字段，一个是**标识符**。这个很好理解，你派出去两队侦查兵，一队是侦查战况的，一队是去查找水源的，要有个标识才能区分。另一个是**序号**，你派出去的侦查兵，都要编个号。如果派出去 10 个，回来 10 个，就说明前方战况不错；如果派出去 10 个，回来 2 个，说明情况可能不妙。

在选项数据中，ping 还会存放发送请求的时间值，来计算往返时间，说明路程的长短。



### 差错报文类型

当然也有另外一种方式，就是差错报文。

主帅骑马走着走着，突然来了一匹快马，上面的小兵气喘吁吁的：报告主公，不好啦！张将军遭遇埋伏，全军覆没啦！这种是异常情况发起的，来报告发生了不好的事情，对应 ICMP 的**差错报文类型**。

我举几个 ICMP 差错报文的例子：**终点不可达为 3，源抑制为 4，超时为 11，重定向为 5**。这些都是什么意思呢？我给你具体解释一下。



**第一种是终点不可达**。小兵：报告主公，您让把粮草送到张将军那里，结果没有送到。

如果你是主公，你肯定会问，为啥送不到？具体的原因在代码中表示就是，网络不可达代码为 0，主机不可达代码为 1，协议不可达代码为 2，端口不可达代码为 3，需要进行分片但设置了不分片位代码为 4。

具体的场景就像这样：

- 网络不可达：主公，找不到地方呀？
- 主机不可达：主公，找到地方没这个人呀？
- 协议不可达：主公，找到地方，找到人，口号没对上，人家天王盖地虎，我说 12345！
- 端口不可达：主公，找到地方，找到人，对了口号，事儿没对上，我去送粮草，人家说他们在等救兵。
- 需要进行分片但设置了不分片位：主公，走到一半，山路狭窄，想换小车，但是您的将令，严禁换小车，就没办法送到了。



**第二种是源站抑制**，也就是让源站放慢发送速度。小兵：报告主公，您粮草送的太多了吃不完。



**第三种是时间超时**，也就是超过网络包的生存时间还是没到。小兵：报告主公，送粮草的人，自己把粮草吃完了，还没找到地方，已经饿死啦。



**第四种是路由重定向**，也就是让下次发给另一个路由器。小兵：报告主公，上次送粮草的人本来只要走一站地铁，非得从五环绕，下次别这样了啊。



差错报文的结构相对复杂一些。除了前面还是 IP，ICMP 的前 8 字节不变，后面则跟上出错的那个 IP 包的 IP 头和 IP 正文的前 8 个字节。

而且这类侦查兵特别恪尽职守，不但自己返回来报信，还把一部分遗物也带回来。

- 侦察兵：报告主公，张将军已经战死沙场，这是张将军的印信和佩剑。
- 主公：神马？张将军是怎么死的（可以查看 ICMP 的前 8 字节）？没错，这是张将军的剑，是他的剑（IP 数据包的头及正文前 8 字节）。





### ping：查询报文类型的使用

接下来，我们重点来看 ping 的发送和接收过程。

![img](趣谈网络协议.assets/57a77fb89bc4a5653842276c70c0d621.jpg)

假定主机 A 的 IP 地址是 192.168.1.1，主机 B 的 IP 地址是 192.168.1.2，它们都在同一个子网。那当你在主机 A 上运行“ping 192.168.1.2”后，会发生什么呢?



ping 命令执行的时候，源主机首先会构建一个 ICMP 请求数据包，ICMP 数据包内包含多个字段。最重要的是两个，第一个是**类型字段**，对于请求数据包而言该字段为 8；另外一个是**顺序号**，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加 1。为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。



然后，由 ICMP 协议将这个数据包连同地址 192.168.1.2 一起交给 IP 层。IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，加上一些其他控制信息，构建一个 IP 数据包。



接下来，需要加入 MAC 头。如果在本节 ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 ARP 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。



主机 B 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。



主机 B 会构建一个 ICMP 应答包，应答数据包的类型字段为 0，顺序号为接收到的请求数据包中的顺序号，然后再发送出去给主机 A。



在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 应答包，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。



当然这只是最简单的，同一个局域网里面的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等等。但是对于 ICMP 的头来讲，是没什么影响的。会影响的是根据目标 IP 地址，选择路由的下一跳，还有每经过一个路由器到达一个新的局域网，需要换 MAC 头里面的 MAC 地址。这个过程后面几节会详细描述，这里暂时不多说。



如果在自己的可控范围之内，当遇到网络不通的问题的时候，除了直接 ping 目标的 IP 地址之外，还应该有一个清晰的网络拓扑图。并且**从理论上来讲，应该要清楚地知道一个网络包从源地址到目标地址都需要经过哪些设备，然后逐个 ping 中间的这些设备或者机器**。如果可能的话，**在这些关键点，通过 tcpdump -i eth0 icmp，查看包有没有到达某个点，回复的包到达了哪个点，可以更加容易推断出错的位置**。



经常会遇到一个问题，如果不在我们的控制范围内，很多中间设备都是禁止 ping 的，但是 ping 不通不代表网络不通。这个时候就要使用 telnet，通过其他协议来测试网络是否通，这个就不在本篇的讲述范围了。



说了这么多，你应该可以看出 ping 这个程序是使用了 ICMP 里面的 ECHO REQUEST 和 ECHO REPLY 类型的。



### Traceroute：差错报文类型的使用

那其他的类型呢？是不是只有真正遇到错误的时候，才能收到呢？那也不是，有一个程序 Traceroute，是个“大骗子”。它会使用 ICMP 的规则，故意制造一些能够产生错误的场景。

所以，**Traceroute 的第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器**。Traceroute 的参数指向某个目的 IP 地址，它会发送一个 UDP 的数据包。**将 TTL 设置成 1，也就是说一旦遇到一个路由器或者一个关卡，就表示它“牺牲”了**。

如果中间的路由器不止一个，当然碰到第一个就“牺牲”。于是，返回一个 ICMP 包，也就是网络差错包，类型是时间超时。那大军前行就带一顿饭，试一试走多远会被饿死，然后找个哨探回来报告，那我就知道大军只带一顿饭能走多远了。

接下来，将 TTL 设置为 2。第一关过了，第二关就“牺牲”了，那我就知道第二关有多远。如此反复，直到到达目的主机。这样，Traceroute 就拿到了所有的路由器 IP。当然，有的路由器压根不会回这个 ICMP。这也是 Traceroute 一个公网的地址，看不到中间路由的原因。



怎么知道 UDP 有没有到达目的主机呢？Traceroute 程序会发送一份 UDP 数据报给目的主机，但它会选择一个不可能的值作为 UDP 端口号（大于 30000）。当该数据报到达时，将使目的主机的 UDP 模块产生一份“端口不可达”错误 ICMP 报文。如果数据报没有到达，则可能是超时。

这就相当于故意派人去西天如来那里去请一本《道德经》，结果人家信佛不信道，消息就会被打出来。被打的消息传回来，你就知道西天是能够到达的。为什么不去取《心经》呢？因为 UDP 是无连接的。也就是说这人一派出去，你就得不到任何音信。你无法区别到底是半路走丢了，还是真的信佛遁入空门了，只有让人家打出来，你才会得到消息。



**Traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU。**要做的工作首先是发送分组，并设置“不分片”标志。发送的第一个分组的长度正好与出口 MTU 相等。如果中间遇到窄的关口会被卡住，会发送 ICMP 网络差错包，类型为“需要进行分片但设置了不分片位”。其实，这是人家故意的好吧，每次收到 ICMP“不能分片”差错时就减小分组的长度，直到到达目标主机。



### 使用例子

1. 在Windows操作系统上，使用命令提示符（Command Prompt）执行Traceroute指令：

   ```
   tracert google.com
   ```

   这将执行Traceroute来跟踪到达Google服务器的路径，并显示每个路由器的IP地址和延迟时间。

2. 在Linux或Mac操作系统上，使用终端执行Traceroute指令：

   ```bash
   # traceroute google.com
   traceroute to google.com (8.7.198.46), 30 hops max, 60 byte packets
    1  9.135.36.8 (9.135.36.8)  0.227 ms  0.192 ms  0.211 ms
    2  * * *
    3  * * *
    4  * * *
    5  * * *
    6  * * *
   
   ## 注释
   traceroute to google.com (8.7.198.46), 30 hops max, 60 byte packets: 这是目标主机的信息。它显示了要跟踪的目标主机的IP地址（8.7.198.46），最大跳数（30 hops max）和每个数据包的大小（60 byte packets）。
   
   1  9.135.36.8 (9.135.36.8)  0.227 ms  0.192 ms 9.135.36.14 (9.135.36.14)  0.211 ms: 这是第一个跳点的信息。它显示了跳点的序号（1），IP地址（9.135.36.8），以及每个数据包的延迟时间（0.227 ms、0.192 ms和0.211 ms）。这表示第一个跳点的延迟时间非常短。
   
   
   ```

3、在Traceroute指令中，您还可以指定其他选项和参数来自定义跟踪过程。例如，您可以设置报文的TTL值、指定使用的协议（如UDP或ICMP）、设置超时时间等。以下是一些示例：

- 指定最大跳数（最大TTL值）：

  ```
  traceroute -m 30 google.com
  ```

  这将限制Traceroute的跟踪跳数为30，即最多跟踪30个路由器。

- 使用UDP协议而不是默认的ICMP协议：

  ```
  traceroute -U google.com
  ```

  这将使用UDP报文而不是ICMP报文来执行Traceroute。

- 设置超时时间：

  ```
  traceroute -w 2 google.com
  ```

  这将设置每个跳点的超时时间为2秒。



### 小结

总结一下：

- ICMP 相当于网络世界的侦察兵。我讲了两种类型的 ICMP 报文，一种是主动探查的查询报文，一种异常报告的差错报文；
- ping 使用查询报文，Traceroute 使用差错报文。

最后，给你留两个思考题吧。

1. 当发送的报文出问题的时候，会发送一个 ICMP 的差错报文来报告错误，但是如果 ICMP 的差错报文也出问题了呢？
2. 这一节只说了一个局域网互相 ping 的情况。如果跨路由器、跨网关的过程会是什么样的呢？

> chatGPT

1. 当发送的报文出问题时，通常会发送一个ICMP的差错报文来报告错误。但是，如果ICMP的差错报文本身也出现问题，例如在传输过程中被丢弃或被阻止，那么报告错误的能力就会受到影响。这可能导致无法及时获得关于报文问题的详细信息，从而使故障排除变得更加困难。
2. 当进行跨路由器或跨网关的通信时，Traceroute的工作方式会有所不同。在这种情况下，Traceroute会使用IP报文的TTL（Time to Live）字段来探测路径。它会发送一系列的UDP或ICMP报文，每个报文的TTL值递增。当报文到达一个路由器时，该路由器会将TTL减1，并且如果TTL减为0，路由器会发送一个"Time Exceeded"差错报文回到源主机。

在跨路由器或跨网关的过程中，Traceroute会显示每个路由器的IP地址和延迟时间（RTT），以及报文通过的路径。这样可以帮助诊断网络中的延迟和路径问题，并确定数据包在网络中的传输路径。



## 第8讲 | 世界这么大，我想出网关：欧洲十国游与玄奘西行

### 怎么在宿舍上网？

还记得咱们在宿舍的时候买了台交换机，几台机器组了一个局域网打游戏吗？可惜啊，只能打局域网的游戏，不能上网啊！盼啊盼啊，终于盼到大二，允许宿舍开通网络了。学校给每个宿舍的网口分配了一个 IP 地址。这个 IP 是校园网的 IP，完全由网管部门控制。宿舍网的 IP 地址多为 192.168.1.x。校园网的 IP 地址，假设是 10.10.x.x。



这个时候，你要在宿舍上网，有两个办法：

第一个办法，让你们宿舍长再买一个网卡。这个时候，你们宿舍长的电脑里就有两张网卡。一张网卡的线插到你们宿舍的交换机上，另一张网卡的线插到校园网的网口。而且，这张新的网卡的 IP 地址要按照学校网管部门分配的配置，不然上不了网。**这种情况下，如果你们宿舍的人要上网，就需要一直开着宿舍长的电脑。**

第二个办法，你们共同出钱买个家庭路由器（反正当时我们买不起）。家庭路由器会有内网网口和外网网口。把外网网口的线插到校园网的网口上，将这个外网网口配置成和网管部的一样。内网网口连上你们宿舍的所有的电脑。**这种情况下，如果你们宿舍的人要上网，就需要一直开着路由器。**



这两种方法其实是一样的。只不过第一种方式，让你的宿舍长的电脑，变成一个有多个口的路由器而已。而你买的家庭路由器，里面也跑着程序，和你宿舍长电脑里的功能一样，只不过是一个嵌入式的系统。



当你的宿舍长能够上网之后，接下来，就是其他人的电脑怎么上网的问题。这就需要配置你们的**网卡。\**当然 DHCP 是可以默认配置的。在进行网卡配置的时候，除了 IP 地址，还需要配置一个\** Gateway** 的东西，这个就是**网关**。



### 你了解 MAC 头和 IP 头的细节吗？

一旦配置了 IP 地址和网关，往往就能够指定目标地址进行访问了。由于**在跨网关访问的时候，牵扯到 MAC 地址和 IP 地址的变化**，这里有必要详细描述一下 MAC 头和 IP 头的细节。

<img src="趣谈网络协议.assets/825e54560a6de08a32e4cab4e0f59f65.jpg" alt="img" style="zoom: 25%;" />



在 MAC 头里面，先是目标 MAC 地址，然后是源 MAC 地址，然后有一个协议类型，用来说明里面是 IP 协议。

IP 头里面的版本号，目前主流的还是 IPv4，**服务类型 TOS(Type of Service)** 在第三节讲 ip addr 命令的时候讲过，TTL 在第 7 节讲 ICMP 协议的时候讲过。

另外，还有 8 位标识协议。这里到了下一层的协议，也就是，是 TCP 还是 UDP。最重要的就是源 IP 和目标 IP，先是源 IP 地址，然后是目标 IP 地址。

> 补充：TOS字段的8个比特位被分为3个子字段：
>
> 1. 前3位：优先级（Precedence）字段，用于指定数据包的优先级。这些优先级可以是网络控制、优先、立即、闲置等不同级别，用于决定数据包在网络中的处理顺序。
> 2. 下一个4位：TOS子字段，用于指定数据包的服务类型。这些服务类型可以是最小延迟、最大吞吐量、最高可靠性等，以便网络设备根据服务类型对数据包进行适当的处理。
> 3. 最后1位：未使用的保留位，目前没有特定的用途。



在任何一台机器上，当要访问另一个 IP 地址的时候，都会先判断，这个目标 IP 地址，和当前机器的 IP 地址，是否在同一个网段。怎么判断同一个网段呢？需要 CIDR 和子网掩码，这个在第三节的时候也讲过了。



**如果是同一个网段**，例如，你访问你旁边的兄弟的电脑，那就没网关什么事情，直接将源地址和目标地址放入 IP 头中，然后通过 ARP 获得 MAC 地址，将源 MAC 和目的 MAC 放入 MAC 头中，发出去就可以了。

**如果不是同一网段**，例如，你要访问你们校园网里面的 BBS，该怎么办？这就需要**发往默认网关 Gateway**。Gateway 的地址一定是和源 IP 地址是一个网段的。往往不是第一个，就是第二个。例如 192.168.1.0/24 这个网段，Gateway 往往会是 192.168.1.1/24 或者 192.168.1.2/24。



如何发往默认网关呢？网关不是和源 IP 地址是一个网段的么？这个过程就和发往同一个网段的其他机器是一样的：将源地址和目标 IP 地址放入 IP 头中，通过 ARP 获得网关的 MAC 地址，将源 MAC 和网关的 MAC 放入 MAC 头中，发送出去。网关所在的端口，例如 192.168.1.1/24 将网络包收进来，然后接下来怎么做，就完全看网关的了。



**网关往往是一个路由器，是一个三层（IP层）转发的设备。**啥叫三层设备？前面也说过了，就是把 MAC 头和 IP 头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。



在你的宿舍里面，网关就是你宿舍长的电脑。一个路由器往往有多个网口，如果是一台服务器做这个事情，则就有多个网卡，其中一个网卡是和源 IP 同网段的。

很多情况下，人们把网关就叫做路由器。其实不完全准确，而另一种比喻更加恰当：**路由器是一台设备，它有五个网口或者网卡，相当于有五只手，分别连着五个局域网。每只手的 IP 地址都和局域网的 IP 地址相同的网段，每只手都是它握住的那个局域网的网关。**



任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下 MAC 头和 IP 头，看看，根据自己的路由算法，选择另一只手，加上 IP 头和 MAC 头，然后扔出去。



### 静态路由是什么？

这个时候，问题来了，该选择哪一只手？IP 头和 MAC 头加什么内容，哪些变、哪些不变呢？这个问题比较复杂，大致可以分为两类，一个是**静态路由**，一个是**动态路由**。动态路由下一节我们详细地讲。这一节我们先说静态路由。



**静态路由，其实就是在路由器上，配置一条一条规则。**这些规则包括：想访问 BBS 站（它肯定有个网段），从 2 号口出去，下一跳是 IP2；想访问教学视频站（它也有个自己的网段），从 3 号口出去，下一跳是 IP3，然后保存在路由器里。



每当要选择从哪只手抛出去的时候，就一条一条的匹配规则，找到符合的规则，就按规则中设置的那样，从某个口抛出去，找下一跳 IPX。



### IP 头和 MAC 头哪些变、哪些不变？

对于 IP 头和 MAC 头哪些变、哪些不变的问题，可以分两种类型。我把它们称为“**欧洲十国游”型**和“**玄奘西行”型**。



之前我说过，**MAC 地址是一个局域网内才有效的地址。因而，MAC 地址只要过网关，就必定会改变**，因为已经换了局域网。两者主要的区别在于 IP 地址是否改变。不改变 IP 地址的网关，我们称为**转发网关；\**改变 IP 地址的网关，我们称为\** NAT 网关**。



#### “欧洲十国游”型

结合这个图，我们先来看“欧洲十国游”型。

<img src="趣谈网络协议.assets/1d604f88456096a73e40437d8f9e458c.jpg" alt="img" style="zoom:33%;" />



服务器 A 要访问服务器 B。首先，服务器 A 会思考，192.168.4.101 和我不是一个网段的，因而需要先发给网关。那网关是谁呢？已经静态配置好了，网关是 192.168.1.1。网关的 MAC 地址是多少呢？发送 ARP 获取网关的 MAC 地址，然后发送包。包的内容是这样的：

- 源 MAC：服务器 A 的 MAC
- 目标 MAC：192.168.1.1 这个网口的 MAC
- 源 IP：192.168.1.101
- 目标 IP：192.168.4.101

包到达 192.168.1.1 这个网口，发现 MAC 一致，将包收进来，开始思考往哪里转发。

在路由器 A 中配置了静态路由之后，要想访问 192.168.4.0/24，要从 192.168.56.1 这个口出去，下一跳为 192.168.56.2。

于是，路由器 A 思考的时候，匹配上了这条路由，要从 192.168.56.1 这个口发出去，发给 192.168.56.2，那 192.168.56.2 的 MAC 地址是多少呢？路由器 A 发送 ARP 获取 192.168.56.2 的 MAC 地址，然后发送包。包的内容是这样的：

- 源 MAC：192.168.56.1 的 MAC 地址
- 目标 MAC：192.168.56.2 的 MAC 地址
- 源 IP：192.168.1.101
- 目标 IP：192.168.4.101



包到达 192.168.56.2 这个网口，发现 MAC 一致，将包收进来，开始思考往哪里转发。

在路由器 B 中配置了静态路由，要想访问 192.168.4.0/24，要从 192.168.4.1 这个口出去，没有下一跳了。因为我右手这个网卡，就是这个网段的，我是最后一跳了。

于是，路由器 B 思考的时候，匹配上了这条路由，要从 192.168.4.1 这个口发出去，发给 192.168.4.101。那 192.168.4.101 的 MAC 地址是多少呢？路由器 B 发送 ARP 获取 192.168.4.101 的 MAC 地址，然后发送包。包的内容是这样的：

- 源 MAC：192.168.4.1 的 MAC 地址
- 目标 MAC：192.168.4.101 的 MAC 地址
- 源 IP：192.168.1.101
- 目标 IP：192.168.4.101

包到达服务器 B，MAC 地址匹配，将包收进来。



通过这个过程可以看出，每到一个新的局域网，MAC 都是要变的，但是 IP 地址都不变。在 IP 头里面，不会保存任何网关的 IP 地址。**所谓的下一跳是，某个 IP 要将这个 IP 地址转换为 MAC 放入 MAC 头。**

之所以将这种模式比喻称为欧洲十国游，是因为在整个过程中，IP 头里面的地址都是不变的。IP 地址在三个局域网都可见，在三个局域网之间的网段都不会冲突。在三个网段之间传输包，IP 头不改变。这就像在欧洲各国之间旅游，一个签证就能搞定。

<img src="趣谈网络协议.assets/35fb548bbaa7d77012ab46151bfbe63b.jpg" alt="img" style="zoom: 33%;" />



#### “玄奘西行”型

我们再来看“玄奘西行”型。

这里遇见的第一个问题是，局域网之间没有商量过，各定各的网段，因而 IP 段冲突了。最左面大唐的地址是 192.168.1.101，最右面印度的地址也是 192.168.1.101，如果单从 IP 地址上看，简直是自己访问自己，其实是大唐的 192.168.1.101 要访问印度的 192.168.1.101。



怎么解决这个问题呢？既然局域网之间没有商量过，你们各管各的，那到国际上，也即中间的局域网里面，就需要使用另外的地址。就像出国，不能用咱们自己的身份证，而要改用护照一样，玄奘西游也要拿着专门取经的通关文牒，而不能用自己国家的身份证。



首先，目标服务器 B 在国际上要有一个国际的身份，我们给它一个 192.168.56.2。在网关 B 上，我们记下来，国际身份 192.168.56.2 对应国内身份 192.168.1.101。凡是要访问 192.168.56.2，都转成 192.168.1.101。



于是，源服务器 A 要访问目标服务器 B，要指定的目标地址为 192.168.56.2。这是它的国际身份。服务器 A 想，192.168.56.2 和我不是一个网段的，因而需要发给网关，网关是谁？已经静态配置好了，网关是 192.168.1.1，网关的 MAC 地址是多少？发送 ARP 获取网关的 MAC 地址，然后发送包。包的内容是这样的：

- 源 MAC：服务器 A 的 MAC
- 目标 MAC：192.168.1.1 这个网口的 MAC
- 源 IP：192.168.1.101
- 目标 IP：192.168.56.2

包到达 192.168.1.1 这个网口，发现 MAC 一致，将包收进来，开始思考往哪里转发。

在路由器 A 中配置了静态路由：要想访问 192.168.56.2/24，要从 192.168.56.1 这个口出去，没有下一跳了，因为我右手这个网卡，就是这个网段的，我是最后一跳了。



于是，路由器 A 思考的时候，匹配上了这条路由，要从 192.168.56.1 这个口发出去，发给 192.168.56.2。那 192.168.56.2 的 MAC 地址是多少呢？路由器 A 发送 ARP 获取 192.168.56.2 的 MAC 地址。

当网络包发送到中间的局域网的时候，服务器 A 也需要有个国际身份，因而在国际上，源 IP 地址也不能用 192.168.1.101，需要改成 192.168.56.1。发送包的内容是这样的：

- 源 MAC：192.168.56.1 的 MAC 地址
- 目标 MAC：192.168.56.2 的 MAC 地址
- 源 IP：192.168.56.1
- 目标 IP：192.168.56.2

包到达 192.168.56.2 这个网口，发现 MAC 一致，将包收进来，开始思考往哪里转发。

路由器 B 是一个 **NAT 网关**，它上面配置了，要访问国际身份 192.168.56.2 对应国内身份 192.168.1.101，于是改为访问 192.168.1.101。



在路由器 B 中配置了静态路由：要想访问 192.168.1.0/24，要从 192.168.1.1 这个口出去，没有下一跳了，因为我右手这个网卡，就是这个网段的，我是最后一跳了。

于是，路由器 B 思考的时候，匹配上了这条路由，要从 192.168.1.1 这个口发出去，发给 192.168.1.101。

那 192.168.1.101 的 MAC 地址是多少呢？路由器 B 发送 ARP 获取 192.168.1.101 的 MAC 地址，然后发送包。内容是这样的：

- 源 MAC：192.168.1.1 的 MAC 地址
- 目标 MAC：192.168.1.101 的 MAC 地址
- 源 IP：192.168.56.1
- 目标 IP：192.168.1.101

包到达服务器 B，MAC 地址匹配，将包收进来。

从服务器 B 接收的包可以看出，源 IP 为服务器 A 的国际身份，因而发送返回包的时候，也发给这个国际身份，由路由器 A 做 NAT，转换为国内身份。



从这个过程可以看出，IP 地址也会变。这个过程用英文说就是 **Network Address Translation**，简称 **NAT**。

其实这第二种方式我们经常见，现在大家每家都有家用路由器，家里的网段都是 192.168.1.x，所以你肯定访问不了你邻居家的这个私网的 IP 地址的。所以，当我们家里的包发出去的时候，都被家用路由器 NAT 成为了运营商的地址了。

很多办公室访问外网的时候，也是被 NAT 过的，因为不可能办公室里面的 IP 也是公网可见的，公网地址实在是太贵了，所以一般就是整个办公室共用一个到两个出口 IP 地址。你可以通过 https://www.whatismyip.com/ 查看自己的出口 IP 地址。



### 小结

好了，这一节内容差不多了，我来总结一下：

- 如果离开本局域网，就需要经过网关，网关是路由器的一个网口；
- 路由器是一个三层设备，里面有如何寻找下一跳的规则；
- 经过路由器之后 MAC 头要变，如果 IP 不变，相当于不换护照的欧洲旅游，如果 IP 变，相当于换护照的玄奘西行。

最后，给你留两个思考题吧。

1. 当在你家里要访问 163 网站的时候，你的包需要 NAT 成为公网 IP，返回的包又要 NAT 成你的私有 IP，返回包怎么知道这是你的请求呢？它怎么就这么智能的 NAT 成了你的 IP 而非别人的 IP 呢？
2. 对于路由规则，这一节讲述了静态路由，需要手动配置，如果要自动配置，你觉得应该怎么办呢？

> chatGPT

思考题1: 

当你的包需要通过NAT转换成公网IP进行访问163网站时，返回的包需要再次经过NAT转换回你的私有IP。这里涉及到NAT（Network Address Translation）的工作原理。

在NAT转换过程中，NAT设备会在转换表中维护一个映射关系，将你的私有IP和端口映射到公网IP和端口上。当你发送请求时，NAT设备会将源IP和端口替换为公网IP和端口，并在转换表中记录这个映射关系。

当返回的包到达NAT设备时，NAT设备会根据转换表中的映射关系，将目标IP和端口转换回你的私有IP和端口。这样，返回的包就能正确地被路由到你的设备上。

NAT设备之所以能智能地将返回包转换成你的IP而非别人的IP，是因为它在转换表中记录了你的私有IP和端口与公网IP和端口之间的映射关系。当返回包到达时，NAT设备会根据这个映射关系进行转换，确保返回包能正确地被路由到你的设备上。



思考题2:

 对于自动配置路由规则，可以考虑使用动态路由协议来实现。动态路由协议可以自动学习和传播网络中的路由信息，使得路由规则的配置更加灵活和自动化。

一种常见的动态路由协议是OSPF（Open Shortest Path First），它可以根据网络拓扑和链路状态自动计算出最短路径，并将路由信息传播给其他路由器。通过使用OSPF协议，路由器可以自动学习和更新路由规则，以适应网络拓扑的变化。

另一种常见的动态路由协议是BGP（Border Gateway Protocol），它主要用于互联网中的路由器之间的路由信息交换。BGP协议可以自动学习和传播不同自治系统之间的路由信息，实现自治系统之间的自动路由配置。

除了动态路由协议，还可以考虑使用SDN（Software-Defined Networking）技术来实现自动配置路由规则。SDN通过将网络控制平面与数据平面分离，可以实现集中式的网络管理和自动化配置。通过SDN控制器，可以根据网络策略和需求自动配置路由规则，实现自动化的路由管理。

总之，自动配置路由规则可以通过使用动态路由协议、SDN技术或其他自动化的网络管理工具来实现。这样可以减少手动配置的工作量，提高网络的灵活性和可扩展性。



## 第9讲 | 路由协议：西出网关无故人，敢问路在何方

网络世界复杂得多，一旦出了网关，会面临着很多路由器，有很多条道路可以选。如何选择一个更快速的道路求取真经呢？这里面还有很多门道可以讲。



### 如何配置路由？

通过上一节的内容，你应该已经知道，路由器就是一台网络设备，它有多张网卡。当一个入口的网络包送到路由器时，它会根据一个本地的转发信息库，来决定如何正确地转发流量。这个转发信息库通常被称为**路由表**。



一张路由表中会有多条路由规则。每一条规则至少包含这三项信息。

- 目的网络：这个包想去哪儿？
- 出口设备：将包从哪个口扔出去？
- 下一跳网关：下一个路由器的地址。



通过 route 命令和 ip route 命令都可以进行查询或者配置。

例如，我们设置 ip route add 10.176.48.0/20 via 10.173.32.1 dev eth0，就说明要去 10.176.48.0/20 这个目标网络，要从 eth0 端口出去，经过 10.173.32.1。



上一节的例子中，网关上的路由策略就是按照这三项配置信息进行配置的。这种配置方式的一个核心思想是：**根据目的 IP 地址来配置路由**。



### 如何配置策略路由？



当然，在真实的复杂的网络环境中，除了可以根据目的 ip 地址配置路由外，还可以根据多个参数来配置路由，这就称为**策略路由**。

可以配置多个路由表，可以根据源 IP 地址、入口设备、TOS 等选择路由表，然后在路由表中查找路由。这样可以使得来自不同来源的包走不同的路由。



例如，我们设置：

```
ip rule add from 192.168.1.0/24 table 10 
ip rule add from 192.168.2.0/24 table 20
```

表示从 192.168.1.10/24 这个网段来的，使用 table 10 中的路由表，而从 192.168.2.0/24 网段来的，使用 table20 的路由表。

在一条路由规则中，也可以走多条路径。例如，在下面的路由规则中：

```
ip route add default scope global nexthop via 100.100.100.1 weight 1 \
nexthop via 200.200.200.1 weight 2
```

下一跳有两个地方，分别是 100.100.100.1 和 200.200.200.1，权重分别为 1 比 2。

在什么情况下会用到如此复杂的配置呢？举一个现实中的例子。



我是房东，家里从运营商那儿拉了两根网线。这两根网线分别属于两个运行商。一个带宽大一些，一个带宽小一些。这个时候，我就不能买普通的家用路由器了，得买个高级点的，可以接两个外网的。

家里的网络呢，就是普通的家用网段 192.168.1.x/24。家里有两个租户，分别把线连到路由器上。IP 地址为 192.168.1.101/24 和 192.168.1.102/24，网关都是 192.168.1.1/24，网关在路由器上。

就像上一节说的一样，家里的网段是私有网段，出去的包需要 NAT 成公网的 IP 地址，因而路由器是一个 NAT 路由器。

两个运营商都要为这个网关配置一个公网的 IP 地址。如果你去查看你们家路由器里的网段，基本就是我图中画的样子。

<img src="趣谈网络协议.assets/c3f476eb7ce8f185befb6c7a2b1752db.jpg" alt="img" style="zoom: 33%;" />



运行商里面也有一个 IP 地址，在运营商网络里面的网关。不同的运营商方法不一样，有的是 /32 的，也即一个一对一连接。

例如，运营商 1 给路由器分配的地址是 183.134.189.34/32，而运营商网络里面的网关是 183.134.188.1/32。有的是 /30 的，也就是分了一个特别小的网段。运营商 2 给路由器分配的地址是 60.190.27.190/30，运营商网络里面的网关是 60.190.27.189/30。

根据这个网络拓扑图，可以将路由配置成这样：

```bash
$ ip route list table main 
60.190.27.189/30 dev eth3  proto kernel  scope link  src 60.190.27.190
183.134.188.1 dev eth2  proto kernel  scope link  src 183.134.189.34
192.168.1.0/24 dev eth1  proto kernel  scope link  src 192.168.1.1
127.0.0.0/8 dev lo  scope link
default via 183.134.188.1 dev eth2
# 目标地址 通过哪个device出去
```

当路由这样配置的时候，就告诉这个路由器如下的规则：

- 如果去运营商二，就走 eth3；
- 如果去运营商一呢，就走 eth2；
- 如果访问内网，就走 eth1；
- 如果所有的规则都匹配不上，默认走运营商一，也即走快的网络。

但是问题来了，租户 A 不想多付钱，他说我就上上网页，从不看电影，凭什么收我同样贵的网费啊？没关系，咱有技术可以解决。

下面我添加一个 Table，名字叫 **chao**。

```
# echo 200 chao >> /etc/iproute2/rt_tables
```

添加一条规则：

```
# ip rule add from 192.168.1.101 table chao
# ip rule ls
0:  from all lookup local 
32765:  from 10.0.0.10 lookup chao
32766:  from all lookup main 
32767:  from all lookup default
```

设定规则为：从 192.168.1.101 来的包都查看个 chao 这个新的路由表。

在 chao 路由表中添加规则：

```
# ip route add default via 60.190.27.189 dev eth3 table chao
# ip route flush cache
```

默认的路由走慢的，谁让你不付钱。



上面说的都是静态的路由，一般来说网络环境简单的时候，在自己的可控范围之内，自己捣鼓还是可以的。但是有时候网络环境复杂并且多变，如果总是用静态路由，一旦网络结构发生变化，让网络管理员手工修改路由太复杂了，因而需要动态路由算法。

### 动态路由算法

使用动态路由路由器，可以根据路由协议算法生成动态路由表，随网络运行状况的变化而变化。那路由算法是什么样的呢？

我们可以想象唐僧西天取经，需要解决两大问题，一个是在每个国家如何找到正确的路，去换通关文牒、吃饭、休息；一个是在国家之间，野外行走的时候，如何找到正确的路、水源的问题。

<img src="趣谈网络协议.assets/85b3314e56cb5870a5cf9a0597ffa965.jpg" alt="img" style="zoom:25%;" />

无论是一个国家内部，还是国家之间，我们都可以将复杂的路径，抽象为一种叫作图的数据结构。至于唐僧西行取经，肯定想走的路越少越好，道路越短越好，因而这就转化成为**如何在途中找到最短路径**的问题。

咱们在大学里面学习计算机网络与数据结构的时候，知道求最短路径常用的有两种方法，一种是 Bellman-Ford 算法，一种是 Dijkstra 算法。在计算机网络中基本也是用这两种方法计算的。



#### 1. 距离矢量路由算法

第一大类的算法称为**距离矢量路由**（**distance vector routing**）。它是基于 Bellman-Ford 算法的。

这种算法的基本思路是，每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到目标路由器，从那条线出去，另一个是到目标路由器的距离。



由此可以看出，每个路由器都是知道全局信息的。那这个信息如何更新呢？每个路由器都知道自己和邻居之间的距离，每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。

每个路由器根据新收集的信息，计算和其他路由器的距离，比如自己的一个邻居距离目标路由器的距离是 M，而自己距离邻居是 x，则自己距离目标路由器是 x+M。

这个算法比较简单，但是还是有问题。



**第一个问题就是好消息传得快，坏消息传得慢。** 如果有个路由器加入了这个网络，它的邻居就能很快发现它，然后将消息广播出去。要不了多久，整个网络就都知道了。但是一旦一个路由器挂了，挂的消息是没有广播的。当每个路由器发现原来的道路到不了这个路由器的时候，感觉不到它已经挂了，而是试图通过其他的路径访问，直到试过了所有的路径，才发现这个路由器是真的挂了。

再举个例子。

<img src="趣谈网络协议.assets/e9642f901c1d9c470c539ccc395e7879.jpg" alt="img" style="zoom:33%;" />

原来的网络包括两个节点，B 和 C。A 加入了网络，它的邻居 B 很快就发现 A 启动起来了。于是它将自己和 A 的距离设为 1，同样 C 也发现 A 起来了，将自己和 A 的距离设置为 2。但是如果 A 挂掉，情况就不妙了。B 本来和 A 是邻居，发现连不上 A 了，但是 C 还是能够连上，只不过距离远了点，是 2，于是将自己的距离设置为 3。殊不知 C 的距离 2 其实是基于原来自己的距离为 1 计算出来的。C 发现自己也连不上 A，并且发现 B 设置为 3，于是自己改成距离 4。**依次类推，数越来越大，直到超过一个阈值，我们才能判定 A 真的挂了**。



这个道理有点像有人走丢了。当你突然发现找不到这个人了。于是你去学校问，是不是在他姨家呀？找到他姨家，他姨说，是不是在他舅舅家呀？他舅舅说，是不是在他姥姥家呀？他姥姥说，是不是在学校呀？总归要问一圈，或者是超过一定的时间，大家才会认为这个人的确走丢了。如果这个人其实只是去见了一个谁都不认识的网友去了，当这个人回来的时候，只要他随便见到其中的一个亲戚，这个亲戚就会拉着他到他的家长那里，说你赶紧回家，你妈都找你一天了。



**这种算法的第二个问题是，每次发送的时候，要发送整个全局路由表。**网络大了，谁也受不了，所以最早的路由协议 RIP 就是这个算法。它适用于小型网络（小于 15 跳）。当网络规模都小的时候，没有问题。现在一个数据中心内部路由器数目就很多，因而不适用了。

所以上面的两个问题，限制了距离矢量路由的网络规模。



#### 2. 链路状态路由算法

第二大类算法是**链路状态路由**（**link state routing**），基于 Dijkstra 算法。



这种算法的基本思路是：当一个路由器启动的时候，首先是发现邻居，向邻居 say hello，邻居都回复。然后计算和邻居的距离，发送一个 echo，要求马上返回，除以二就是距离。然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。这样每个路由器都能够收到它和邻居之间的关系的信息。因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用 Dijkstra 算法，找到两点之间的最短路径。

不像距离距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和 CPU 利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。





### 动态路由协议

#### 1. 基于链路状态路由算法的 OSPF

**OSPF**（**Open Shortest Path First**，**开放式最短路径优先**）就是这样一个基于链路状态路由协议，广泛应用在数据中心中的协议。由于主要用在数据中心内部，用于路由决策，因而称为**内部网关协议**（**Interior Gateway Protocol**，简称 **IGP**）。

内部网关协议的重点就是找到最短的路径。在一个组织内部，路径最短往往最优。当然有时候 OSPF 可以发现多个最短的路径，可以在这多个路径中进行负载均衡，这常常被称为**等价路由**。

<img src="趣谈网络协议.assets/2eb5f4722689adf9926fded5005e02db.jpg" alt="img" style="zoom: 25%;" />



这一点非常重要。有了等价路由，到一个地方去可以有相同的两个路线，可以分摊流量，还可以当一条路不通的时候，走另外一条路。这个在后面我们讲数据中心的网络的时候，一般应用的接入层会有负载均衡 LVS（Linux Virtual Server（LVS），它是一个开源的负载均衡器）。它可以和 OSPF 一起，实现高吞吐量的接入层设计。



#### 2. 基于距离矢量路由算法的 BGP

但是外网的路由协议，也即国家之间的，又有所不同。我们称为**外网路由协议**（**Border Gateway Protocol**，简称 **BGP**）。

在一个国家内部，有路当然选近的走。但是国家之间，不光远近的问题，还有政策的问题。例如，唐僧去西天取经，有的路近。但是路过的国家看不惯僧人，见了僧人就抓。例如灭法国，连光头都要抓。这样的情况即便路近，也最好绕远点走。

对于网络包同样，每个数据中心都设置自己的 Policy。例如，哪些外部的 IP 可以让内部知晓，哪些内部的 IP 可以让外部知晓，哪些可以通过，哪些不能通过。这就好比，虽然从我家里到目的地最近，但是不能谁都能从我家走啊！



在网络世界，这一个个国家成为自治系统 **AS**（Autonomous System）。自治系统分几种类型。

- Stub AS：对外只有一个连接。这类 AS 不会传输其他 AS 的包。例如，个人或者小公司的网络。
- Multihomed AS：可能有多个连接连到其他的 AS，但是大多拒绝帮其他的 AS 传输包。例如一些大公司的网络。
- Transit AS：有多个连接连到其他的 AS，并且可以帮助其他的 AS 传输包。例如主干网。

每个自治系统都有**边界路由器**，通过它和外面的世界建立联系。

<img src="趣谈网络协议.assets/698e368848fdbf1eb8e270983e18143d.jpg" alt="img" style="zoom: 25%;" />



**BGP 又分为两类，eBGP 和 iBGP。**自治系统间，边界路由器之间使用 eBGP 广播路由。内部网络也需要访问其他的自治系统。边界路由器如何将 BGP 学习到的路由导入到内部网络呢？就是通过运行 iBGP，使得内部的路由器能够找到到达外网目的地的最好的边界路由器。



BGP 协议使用的算法是**路径矢量路由协议**（path-vector protocol）。它是距离矢量路由协议的升级版。



前面说了距离矢量路由协议的缺点。其中一个是收敛慢。**在 BGP 里面，除了下一跳 hop 之外，还包括了自治系统 AS 的路径，从而可以避免坏消息传得慢的问题**，也即上面所描述的，B 知道 C 原来能够到达 A，是因为通过自己，一旦自己都到达不了 A 了，就不用假设 C 还能到达 A 了。



另外，在路径中将一个自治系统看成一个整体，不区分自治系统内部的路由器，这样自治系统的数目是非常有限的。就像大家都能记住出去玩，从中国出发先到韩国然后到日本，只要不计算细到具体哪一站，就算是发送全局信息，也是没有问题的。



### 小结

总结：

- 路由分静态路由和动态路由，静态路由可以配置复杂的策略路由，控制转发策略；
- 动态路由主流算法有两种，距离矢量算法和链路状态算法。基于两种算法产生两种协议，BGP 协议和 OSPF 协议。

最后，再给你留两个思考题：

1. 路由协议要在路由器之间交换信息，这些信息的交换还需要走路由吗？不是死锁了吗？
2. 路由器之间信息的交换使用什么协议呢？报文格式是什么样呢？



> chatGPT

1. 路由协议在路由器之间交换信息时，确实需要通过路由器进行传递。这可能会引发一个问题：如果路由器之间的信息交换也需要通过路由器，那么是否会导致死锁？

实际上，路由器之间的信息交换并不会导致死锁。这是因为路由器之间的信息交换是基于一些特定的路由协议进行的，这些协议具有一些机制来避免死锁的发生。例如，常见的路由协议如 OSPF（Open Shortest Path First）和 BGP（Border Gateway Protocol）使用了分布式算法和路由选择策略，以确保信息在网络中能够正确地传递，并避免死锁的发生。

1. 路由器之间的信息交换使用的是路由协议。常见的路由协议有 OSPF、BGP、RIP（Routing Information Protocol）等。这些协议定义了路由器之间交换的报文格式和交换规则。

报文格式通常包括以下信息：

- 路由器的标识和地址信息
- 路由器之间的邻居关系和连接状态
- 路由表信息，包括网络地址、下一跳路由器、距离等
- 路由器之间的协议参数和选项

具体的报文格式和交换规则会根据不同的路由协议而有所不同。每个协议都有自己的报文格式和交换机制，以确保路由器之间能够正确地交换信息，并根据网络的变化进行动态的路由更新。这样可以实现网络的动态路由选择和适应性调整。



# 第二模块 底层网络知识详解：最常用的应用层



## 第10讲 | UDP协议：因性善而简单，难免碰到“城会玩”



讲完了 IP 层以后，接下来我们开始讲传输层。传输层里比较重要的两个协议，一个是 TCP，一个是 UDP。对于不从事底层开发的人员来讲，或者对于开发应用的人来讲，最常用的就是这两个协议。由于面试的时候，这两个协议经常会被放在一起问，因而我在讲的时候，也会结合着来讲。

### TCP 和 UDP 有哪些区别？

一般面试的时候我问这两个协议的区别，大部分人会回答，TCP 是面向连接的，UDP 是面向无连接的。



什么叫面向连接，什么叫无连接呢？在互通之前，面向连接的协议会先建立连接。例如，TCP 会三次握手，而 UDP 不会。为什么要建立连接呢？你 TCP 三次握手，我 UDP 也可以发三个包玩玩，有什么区别吗？



**所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。**

1、例如，**TCP 提供可靠交付**。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。我们都知道 IP 包是没有任何可靠性保证的，一旦发出去，就像西天取经，走丢了、被妖怪吃了，都只能随它去。但是 TCP 号称能做到那个连接维护的程序做的事情，这个下两节我会详细描述。而 **UDP 继承了 IP 包的特性，不保证不丢失，不保证按顺序到达。**



2、再如，**TCP 是面向字节流的**。发送的时候发的是一个流，没头没尾。IP 包可不是一个流，而是一个个的 IP 包。之所以变成了流，这也是 TCP 自己的状态维护做的事情。而 **UDP 继承了 IP 的特性，基于数据报（data message）的，一个一个地发，一个一个地收。**



3、还有 **TCP 是可以有拥塞控制的**。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。**UDP 就不会，应用让我发，我就发，管它洪水滔天。**



因而 **TCP 其实是一个有状态服务**，通俗地讲就是有脑子的，里面精确地记着发送了没有，接收到没有，发送到哪个了，应该接收哪个了，错一点儿都不行。而 **UDP 则是无状态服务**。通俗地说是没脑子的，天真无邪的，发出去就发出去了。



我们可以这样比喻，如果 MAC 层定义了本地局域网的传输行为，IP 层定义了整个网络端到端的传输行为，这两层基本定义了这样的基因：网络传输是以包为单位的，二层叫帧，网络层叫包，传输层叫段。我们笼统地称为包。包单独传输，自行选路，在不同的设备封装解封装，不保证到达。基于这个基因，生下来的孩子 UDP 完全继承了这些特性，几乎没有自己的思想。

![img](趣谈网络协议.assets/20170822222325781.png)





### UDP 包头是什么样的？

我们来看一下 UDP 包头。



前面章节我已经讲过包的传输过程，这里不再赘述。当我发送的 UDP 包到达目标机器后，发现 MAC 地址匹配，于是就取下来，将剩下的包传给处理 IP 层的代码。把 IP 头取下来，发现目标 IP 匹配，接下来呢？这里面的数据包是给谁呢？



发送的时候，我知道我发的是一个 UDP 的包，收到的那台机器咋知道的呢？所以在 **IP 头里面有个 8 位协议，这里会存放，数据里面到底是 TCP 还是 UDP**，当然这里是 UDP。于是，如果我们知道 UDP 头的格式，就能从数据里面，将它解析出来。解析出来以后呢？数据给谁处理呢？



处理完传输层的事情，内核的事情基本就干完了，里面的数据应该交给应用程序自己去处理，可是一台机器上跑着这么多的应用程序，应该给谁呢？



无论应用程序写的使用 TCP 传数据，还是 UDP 传数据，都要**监听一个端口。正是这个端口，用来区分应用程序**，要不说端口不能冲突呢。两个应用监听一个端口，到时候包给谁呀？所以，按理说，无论是 TCP 还是 UDP 包头里面应该有端口号，根据端口号，将数据交给相应的应用程序。

<img src="趣谈网络协议.assets/2c9a109f3be308dea901004a5a3b4c84.jpg" alt="img" style="zoom:33%;" />

当我们看到 UDP 包头的时候，发现的确有端口号，有源端口号和目标端口号。因为是两端通信嘛，这很好理解。但是你还会发现，UDP 除了端口号，再没有其他的了。和下两节要讲的 TCP 头比起来，这个简直简单得一塌糊涂啊！



### UDP 的三大特点

UDP 就像小孩子一样，有以下这些特点：



第一，**沟通简单**，不需要一肚子花花肠子（大量的数据结构、处理逻辑、包头字段）。前提是它相信网络世界是美好的，秉承性善论，相信网络通路默认就是很容易送达的，不容易被丢弃的。



第二，**轻信他人**。它不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，他也可以传给任何人数据，甚至可以同时传给多个人数据。



第三，**愣头青，做事不懂权变**。不知道什么时候该坚持，什么时候该退让。它不会根据网络的情况进行发包的拥塞控制，无论网络丢包丢成啥样了，它该怎么发还怎么发。



### UDP 的三大使用场景

基于 UDP 这种“小孩子”的特点，我们可以考虑在以下的场景中使用。



第一，**需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用**。这很好理解，就像如果你是领导，你会让你们组刚毕业的小朋友去做一些没有那么难的项目，打一些没有那么难的客户，或者做一些失败了也能忍受的实验性项目。



我们在第四节讲的 **DHCP 就是基于 UDP 协议的**。一般的获取 IP 地址都是内网请求，而且一次获取不到 IP 又没事，过一会儿还有机会。我们讲过 PXE 可以在启动的时候自动安装操作系统，操作系统镜像的下载使用的 TFTP，这个也是基于 UDP 协议的。在还没有操作系统的时候，客户端拥有的资源很少，不适合维护一个复杂的状态机，而且因为是内网，一般也没啥问题。



第二，**不需要一对一沟通，建立连接，而是可以广播的应用**。咱们小时候人都很简单，大家在班级里面，谁成绩好，谁写作好，应该表扬谁惩罚谁，谁得几个小红花都是当着全班的面讲的，公平公正公开。长大了人心复杂了，薪水、奖金要背靠背，和员工一对一沟通。



UDP 的不面向连接的功能，可以使得可以承载广播或者多播的协议。**DHCP 就是一种广播的形式，就是基于 UDP 协议的**，而广播包的格式前面说过了。



对于多播，我们在讲 IP 地址的时候，讲过一个 **D 类地址，也即组播地址**，使用这个地址，可以将包组播给一批机器。当一台机器上的某个进程想监听某个组播地址的时候，需要**发送 IGMP 包**，所在网络的路由器就能收到这个包，知道有个机器上有个进程在监听这个组播地址。当路由器收到这个组播地址的时候，会将包转发给这台机器，这样就实现了跨路由器的组播。

在后面云中网络部分，有一个**协议 VXLAN**，也是需要用到组播，也是基于 UDP 协议的。



第三，**需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候**。记得曾国藩建立湘军的时候，专门招出生牛犊不怕虎的新兵，而不用那些“老油条”的八旗兵，就是因为八旗兵经历的事情多，遇到敌军不敢舍死忘生。



同理，UDP 简单、处理速度快，不像 TCP 那样，操这么多的心，各种重传啊，保证顺序啊，前面的不收到，后面的没法处理啊。不然等这些事情做完了，时延早就上去了。而 TCP 在网络不好出现丢包的时候，拥塞控制策略会主动的退缩，降低发送速度，这就相当于本来环境就差，还自断臂膀，用户本来就卡，这下更卡了。



当前很多应用都是要求低时延的，它们可不想用 TCP 如此复杂的机制，而是想根据自己的场景，实现自己的可靠和连接保证**。例如，如果应用自己觉得，有的包丢了就丢了，没必要重传了，就可以算了，有的比较重要，则应用自己重传，而不依赖于 TCP。**有的前面的包没到，后面的包到了，那就先给客户展示后面的嘛，干嘛非得等到齐了呢？如果网络不好，丢了包，那不能退缩啊，要尽快传啊，速度不能降下来啊，要挤占带宽，抢在客户失去耐心之前到达。



由于 UDP 十分简单，基本啥都没做，也就给了应用“城会玩”的机会。就像在和平年代，每个人应该有独立的思考和行为，应该可靠并且礼让；但是如果在战争年代，往往不太需要过于独立的思考，而需要士兵简单服从命令就可以了。



曾国藩说哪支部队需要诱敌牺牲，也就牺牲了，相当于包丢了就丢了。两军狭路相逢的时候，曾国藩说上，没有带宽也要上，这才给了曾国藩运筹帷幄，城会玩的机会。同理如果你实现的应用需要有自己的连接策略，可靠保证，时延要求，使用 UDP，然后再应用层实现这些是再好不过了。

### 基于 UDP 的“城会玩”的五个例子

列举几种“城会玩”的例子。



#### “城会玩”一：网页或者 APP 的访问

原来访问网页和手机 APP 都是基于 HTTP 协议的。HTTP 协议是基于 TCP 的，建立连接都需要多次交互，对于时延比较大的目前主流的移动互联网来讲，建立一次连接需要的时间会比较长，然而既然是移动中，TCP 可能还会断了重连，也是很耗时的。而且目前的 HTTP 协议，往往采取多个数据通道共享一个连接的情况，这样本来为了加快传输速度，但是 TCP 的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。

而 **QUIC**（全称 **Quick UDP Internet Connections**，**快速 UDP 互联网连接**）是 Google 提出的一种基于 UDP 改进的通信协议，其目的是降低网络通信的延迟，提供更好的用户互动体验。



QUIC 在应用层上，会自己实现快速连接建立、减少重传时延，自适应拥塞控制，是应用层“城会玩”的代表。这一节主要是讲 UDP，QUIC 我们放到应用层去讲。



#### “城会玩”二：流媒体的协议

现在直播比较火，直播协议多使用 RTMP，这个协议我们后面的章节也会讲，而这个 **RTMP 协议也是基于 TCP 的**。TCP 的严格顺序传输要保证前一个收到了，下一个才能确认，如果前一个收不到，下一个就算包已经收到了，在缓存里面，也需要等着。对于直播来讲，这显然是不合适的，因为老的视频帧丢了其实也就丢了，就算再传过来用户也不在意了，他们要看新的了，如果老是没来就等着，卡顿了，新的也看不了，那就会丢失客户，所以直播，实时性比较比较重要，宁可丢包，也不要卡顿的。



另外，对于丢包，其实对于视频播放来讲，有的包可以丢，有的包不能丢，因为视频的连续帧里面，有的帧重要，有的不重要，如果必须要丢包，隔几个帧丢一个，其实看视频的人不会感知，但是如果连续丢帧，就会感知了，因而在网络不好的情况下，应用希望选择性的丢帧。



还有就是当网络不好的时候，TCP 协议会主动降低发送速度，这对本来当时就卡的看视频来讲是要命的，应该应用层马上重传，而不是主动让步。因而，很多直播应用，都基于 UDP 实现了自己的视频传输协议。



#### “城会玩”三：实时游戏

游戏有一个特点，就是实时性比较高。快一秒你干掉别人，慢一秒你被别人爆头，所以很多职业玩家会买非常专业的鼠标和键盘，争分夺秒。



因而，**实时游戏中客户端和服务端要建立长连接，来保证实时传输。**但是游戏玩家很多，服务器却不多。由于维护 TCP 连接需要在内核维护一些数据结构，因而一台机器能够支撑的 TCP 连接数目是有限的，然后 UDP 由于是没有连接的，在异步 IO 机制引入之前，常常是应对海量客户端连接的策略。



另外还是 TCP 的强顺序问题，对战的游戏，对网络的要求很简单，玩家通过客户端发送给服务器鼠标和键盘行走的位置，服务器会处理每个用户发送过来的所有场景，处理完再返回给客户端，客户端解析响应，渲染最新的场景展示给玩家。



如果出现一个数据包丢失，所有事情都需要停下来等待这个数据包重发。客户端会出现等待接收数据，然而玩家并不关心过期的数据，激战中卡 1 秒，等能动了都已经死了。



游戏对实时要求较为严格的情况下，采用自定义的可靠 UDP 协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响。



#### “城会玩”四：IoT 物联网

一方面，物联网领域终端资源少，很可能只是个内存非常小的嵌入式系统，而维护 TCP 协议代价太大；另一方面，物联网对实时性要求也很高，而 TCP 还是因为上面的那些原因导致时延大。Google 旗下的 Nest 建立 Thread Group，推出了物联网通信协议 Thread，就是基于 UDP 协议的。



#### “城会玩”五：移动通信领域

在 4G 网络里，移动流量上网的数据面对的协议 GTP-U 是基于 UDP 的。因为移动网络协议比较复杂，而 GTP 协议本身就包含复杂的手机上线下线的通信协议。如果基于 TCP，TCP 的机制就显得非常多余，这部分协议会在后面的章节单独讲解。



### 小结

好了，这节就到这里了，我们来总结一下：



- 如果将 TCP 比作成熟的社会人，UDP 则是头脑简单的小朋友。TCP 复杂，UDP 简单；TCP 维护连接，UDP 谁都相信；TCP 会坚持知进退；UDP 愣头青一个，勇往直前；
- UDP 虽然简单，但它有简单的用法。它可以用在环境简单、需要多播、应用层自己控制传输的地方。例如 DHCP、VXLAN、QUIC 等。



最后，给你留两个思考题吧。

1. 都说 TCP 是面向连接的，在计算机看来，怎么样才算一个连接呢？
2. 你知道 TCP 的连接是如何建立，又是如何关闭的吗？

> chatGPT

1. 在计算机网络中，一个 TCP 连接被定义为两台计算机之间的通信路径。一个 TCP 连接由以下要素组成：

   - 源 IP 地址和端口：发送方计算机的 IP 地址和用于发送数据的端口号。
   - 目标 IP 地址和端口：接收方计算机的 IP 地址和用于接收数据的端口号。

   当两台计算机之间建立了一个 TCP 连接时，它们之间的通信路径就建立起来了。这个连接可以通过网络传输数据，直到连接被关闭。

2. TCP 连接的建立和关闭是通过 TCP 协议中的握手过程来完成的：

   - 连接建立：在连接建立过程中，通常使用三次握手。首先，客户端发送一个带有 SYN（同步）标志的数据包到服务器。服务器收到后，回复一个带有 SYN/ACK（同步/确认）标志的数据包给客户端。最后，客户端再回复一个带有 ACK（确认）标志的数据包给服务器。这样，连接就建立起来了，双方可以开始进行数据传输。
   - 连接关闭：在连接关闭过程中，通常使用四次挥手。当一方决定关闭连接时，它发送一个带有 FIN（结束）标志的数据包给对方。对方收到后，回复一个带有 ACK 标志的数据包作为确认。然后，对方也发送一个带有 FIN 标志的数据包给发起关闭的一方。最后，发起关闭的一方回复一个带有 ACK 标志的数据包作为确认。这样，连接就完全关闭了。

   通过握手过程，TCP 可以确保连接的可靠性和完整性，以及双方对连接的同步操作。



## 第11讲 | TCP协议（上）：因性恶而复杂，先恶后善反轻松

上一节，我们讲的 UDP，基本上包括了传输层所必须的端口字段。它就像我们小时候一样简单，相信“网之初，性本善，不丢包，不乱序”。



后来呢，我们都慢慢长大，了解了社会的残酷，变得复杂而成熟，就像 TCP 协议一样。它之所以这么复杂，那是因为它秉承的是“性恶论”。它天然认为网络环境是恶劣的，丢包、乱序、重传，拥塞都是常有的事情，一言不合就可能送达不了，因而要从算法层面来保证可靠性。



### TCP 包头格式

我们先来看 TCP 头的格式。从这个图上可以看出，它比 UDP 复杂得多。

<img src="趣谈网络协议.assets/642947c94d6682a042ad981bfba39fbf.jpg" alt="img" style="zoom: 25%;" />

首先，源端口号和目标端口号是不可少的，这一点和 UDP 是一样的。如果没有这两个端口号。数据就不知道应该发给哪个应用。



接下来是包的序号。为什么要给包编号呢？当然是为了解决乱序的问题。不编好号怎么确认哪个应该先来，哪个应该后到呢。编号是为了**解决乱序问题**。既然是社会老司机，做事当然要稳重，一件件来，面临再复杂的情况，也临危不乱。



还应该有的就是确认序号。发出去的包应该有确认，要不然我怎么知道对方有没有收到呢？如果没有收到就应该重新发送，直到送达。这个可以解决不丢包的问题。作为老司机，做事当然要靠谱，答应了就要做到，暂时做不到也要有个回复。



**TCP 是靠谱的协议，但是这不能说明它面临的网络环境好。从 IP 层面来讲，如果网络状况的确那么差，是没有任何可靠性保证的，而作为 IP 的上一层 TCP 也无能为力，唯一能做的就是更加努力，不断重传，通过各种算法保证**。也就是说，对于 TCP 来讲，IP 层你丢不丢包，我管不着，但是我在我的层面上，会努力保证可靠性。



接下来有一些状态位。例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。

还有一个重要的就是**窗口大小**。TCP 要做流量控制，通信双方各声明一个窗口，标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。



通过对 TCP 头的解析，我们知道要掌握 TCP 协议，重点应该关注以下几个问题：

- 顺序问题 ，稳重不乱；
- 丢包问题，承诺靠谱；
- 连接维护，有始有终；
- 流量控制，把握分寸；
- 拥塞控制，知进知退。

### TCP 的三次握手

所有的问题，首先都要先建立一个连接，所以我们先来看**连接维护问题**。

TCP 的连接建立，我们常常称为三次握手。

A：您好，我是 A。

B：您好 A，我是 B。

A：您好 B。

我们也常称为“请求 -> 应答 -> 应答之应答”的三个回合。这个看起来简单，其实里面还是有很多的学问，很多的细节。

首先，为什么要三次，而不是两次？按说两个人打招呼，一来一回就可以了啊？为了可靠，为什么不是四次？



**1、为了建立可靠的双向连接**

我们还是假设这个通路是非常不可靠的，A 要发起一个连接，当发了第一个请求杳无音信的时候，会有很多的可能性，比如第一个请求包丢了，再如没有丢，但是绕了弯路，超时了，还有 B 没有响应，不想和我连接。

A 不能确认结果，于是再发，再发。终于，有一个请求包到了 B，但是请求包到了 B 的这个事情，目前 A 还是不知道的，A 还有可能再发。

B 收到了请求包，就知道了 A 的存在，并且知道 A 要和它建立连接。如果 B 不乐意建立连接，则 A 会重试一阵后放弃，连接建立失败，没有问题；如果 B 是乐意建立连接的，则会发送应答包给 A。



当然对于 B 来说，这个应答包也是一入网络深似海，不知道能不能到达 A。这个时候 B 自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者 A 已经挂了都有可能。

而且这个时候 B 还能碰到一个诡异的现象就是，A 和 B 原来建立了连接，做了简单通信后，结束了连接。还记得吗？A 建立连接的时候，请求包重复发了几次，有的请求包绕了一大圈又回来了，B 会认为这也是一个正常的的请求的话，因此建立了连接，可以想象，这个连接不会进行下去，也没有个终结的时候，纯属单相思了。因而**两次握手肯定不行**。



B 发送的应答可能会发送多次，但是只要一次到达 A，A 就认为连接已经建立了，因为对于 A 来讲，他的消息有去有回。A 会给 B 发送应答之应答，而 B 也在等这个消息，才能确认连接的建立，只有等到了这个消息，对于 B 来讲，才算它的消息有去有回。

当然 A 发给 B 的应答之应答也会丢，也会绕路，甚至 B 挂了。按理来说，还应该有个应答之应答之应答，这样下去就没底了。所以四次握手是可以的，四十次都可以，关键四百次也不能保证就真的可靠了。只要双方的消息都有去有回，就基本可以了。



好在大部分情况下，A 和 B 建立了连接之后，A 会马上发送数据的，一旦 A 发送数据，则很多问题都得到了解决。例如 A 发给 B 的应答丢了，当 A 后续发送的数据到达的时候，B 可以认为这个连接已经建立，或者 B 压根就挂了，A 发送的数据，会报错，说 B 不可达，A 就知道 B 出事情了。



当然你可以说 A 比较坏，就是不发数据，建立连接后空着。**我们在程序设计的时候，可以要求开启 keepalive 机制，即使没有真实的数据包，也有探活包**。

另外，你作为服务端 B 的程序设计者，对于 A 这种长时间不发包的客户端，可以主动关闭，从而空出资源来给其他客户端使用。



**2、沟通TCP包的序号**

三次握手除了双方建立连接外，主要还是为了沟通一件事情，就是 **TCP 包的序号的问题**。



A 要告诉 B，我这面发起的包的序号起始是从哪个号开始的，B 同样也要告诉 A，B 发起的包的序号起始是从哪个号开始的。为什么序号不能都从 1 开始呢？因为这样往往会出现冲突。

例如，A 连上 B 之后，发送了 1、2、3 三个包，但是发送 3 的时候，中间丢了，或者绕路了，于是重新发送，后来 A 掉线了，重新连上 B 后，序号又从 1 开始，然后发送 2，但是压根没想发送 3，但是上次绕路的那个 3 又回来了，发给了 B，B 自然认为，这就是下一个包，于是发生了错误。



因而，每个连接都要有不同的序号。**这个序号的起始序号是随着时间变化的，可以看成一个 32 位的计数器，每 4 微秒加一**，如果计算一下，如果到重复，需要 4 个多小时，那个绕路的包早就死翘翘了，因为我们都知道 IP 包头里面有个 TTL，也即生存时间。

好了，双方终于建立了信任，建立了连接。前面也说过，为了维护这个连接，双方都要维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。



<img src="趣谈网络协议.assets/c067fe62f49e8152368c7be9d91adc08.jpg" alt="img" style="zoom:33%;" />



一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，之后处于 ESTABLISHED 状态，**因为它一发一收成功了**。服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。

关键看状态转换，有点像状态机。



### TCP 四次挥手

好了，说完了连接，接下来说一说“拜拜”，好说好散。这常被称为四次挥手。



A：B 啊，我不想玩了。

B：哦，你不想玩了啊，我知道了。

这个时候，还只是 A 不想玩了，也即 A 不会再发送数据，但是 B 能不能在 ACK 的时候，直接关闭呢？当然不可以了，很有可能 A 是发完了最后的数据就准备不玩了，但是 B 还没做完自己的事情，还是可以发送数据的，所以称为**半关闭**的状态。

这个时候 A 可以选择不再接收数据了，也可以选择最后再接收一段数据，等待 B 也主动关闭。



B：A 啊，好吧，我也不玩了，拜拜。

A：好的，拜拜。



这样整个连接就关闭了。但是这个过程有没有异常情况呢？当然有，上面是和平分手的场面。

A 开始说“不玩了”，B 说“知道了”，这个回合，是没什么问题的，因为在此之前，双方还处于合作的状态，如果 A 说“不玩了”，没有收到回复，则 A 会重新发送“不玩了”。但是这个回合结束之后，就有可能出现异常情况了，因为已经有一方率先撕破脸。

一种情况是，A 说完“不玩了”之后，直接跑路，是会有问题的，因为 B 还没有发起结束，而如果 A 跑路，B 就算发起结束，也得不到回答，B 就不知道该怎么办了。另一种情况是，A 说完“不玩了”，B 直接跑路，也是有问题的，因为 A 不知道 B 是还有事情要处理，还是过一会儿会发送结束。



那怎么解决这些问题呢？TCP 协议专门设计了几个状态来处理这些问题。我们来看断开连接的时候的**状态时序图**。

<img src="趣谈网络协议.assets/bf1254f85d527c77cc4088a35ac11d13.jpg" alt="img" style="zoom: 33%;" />

FIN_WAIT_1  CLOSE_WAIT

FIN_WAIT_ 2    LAST_ACK

TIME_WAIT 

断开的时候，我们可以看到，当 A 说“不玩了”，就进入 FIN_WAIT_1 的状态，B 收到“A 不玩”的消息后，发送知道了，就进入 CLOSE_WAIT 的状态。

A 收到“B 说知道了”，就进入 FIN_WAIT_2 的状态，如果这个时候 B 直接跑路，则 A 将永远在这个状态。TCP 协议里面并没有对这个状态的处理，

但是 **Linux 有，可以调整 tcp_fin_timeout 这个参数，设置一个超时时间**。



如果 B 没有跑路，发送了“B 也不玩了”的请求到达 A 时，A 发送“知道 B 也不玩了”的 ACK 后，从 FIN_WAIT_2 状态结束，按说 A 可以跑路了，但是最后的这个 ACK 万一 B 收不到呢？则 B 会重新发一个“B 不玩了”，这个时候 A 已经跑路了的话，B 就再也收不到 ACK 了，因而 **TCP 协议要求 A 最后等待一段时间 TIME_WAIT，这个时间要足够长，长到如果 B 没收到 ACK 的话，“B 说不玩了”会重发的，A 会重新发一个 ACK 并且足够时间到达 B**。

A 直接跑路还有一个问题是，A 的端口就直接空出来了，但是 B 不知道，B 原来发过的很多包很可能还在路上，如果 A 的端口被一个新的应用占用了，这个新的应用会收到上个连接中 B 发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来 B 发送的所有的包都死翘翘，再空出端口来。

（等待TIME_WAIT的原因是 ack可以重传+所有包都传完或失效避免影响下个端口连接）



等待的时间设为 2MSL，**MSL** 是 **Maximum Segment Lifetime**，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 域，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。协议规定 MSL 为 2 分钟，实际应用中常用的是 30 秒，1 分钟和 2 分钟等。



还有一个异常情况就是，B 超过了 2MSL 的时间，依然没有收到它发的 FIN 的 ACK，怎么办呢？按照 TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，A 就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我就都不认了，于是就直接发送 RST，B 就知道 A 早就跑了。





### TCP 状态机

将连接建立和连接断开的两个时序状态图综合起来，就是这个著名的 TCP 的状态机。学习的时候比较建议将这个状态机和时序状态机对照着看，不然容易晕。

<img src="趣谈网络协议.assets/fd45f9ad6ed575ea6bfdaafeb3bfb62a.jpg" alt="img" style="zoom: 33%;" />

在这个图中，加黑加粗的部分，是上面说到的主要流程，其中阿拉伯数字的序号，是连接过程中的顺序，而大写中文数字的序号，是连接断开过程中的顺序。加粗的实线是客户端 A 的状态变迁，加粗的虚线是服务端 B 的状态变迁。



### 小结

总结：

- TCP 包头很复杂，但是主要关注五个问题，顺序问题，丢包问题，**连接维护**，流量控制，拥塞控制；
- 连接的建立是经过三次握手，断开的时候四次挥手，一定要掌握的我画的那个状态图。

最后，给你留两个思考题。

1. TCP 的连接有这么多的状态，你知道如何在系统中查看某个连接的状态吗？
2. 这一节仅仅讲了连接维护问题，其实为了维护连接的状态，还有其他的数据结构来处理其他的四个问题，那你知道是什么吗？

> chatGPT

   1、在系统中查看某个 TCP 连接的状态，可以使用网络诊断工具，如 `netstat` 或 `ss` 命令。这些命令可以显示当前系统上的网络连接和套接字信息，包括 TCP 连接的状态。例如，使用 `netstat -an | grep <IP>:<Port>` 或 `ss -an | grep <IP>:<Port>` 可以查看指定 IP 地址和端口的 TCP 连接状态。

```
# netstat -an
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address           Foreign Address         State      
tcp        0      0 127.0.0.1:42222         0.0.0.0:*               LISTEN     
tcp        0      0 0.0.0.0:5555            0.0.0.0:*               LISTEN     
tcp        0      0 0.0.0.0:2049            0.0.0.0:*               LISTEN     
tcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN     
```



​    2、为了维护 TCP 连接的状态以及处理其他四个问题（顺序问题、丢包问题、流量控制和拥塞控制），TCP 使用了多种数据结构和算法。其中一些关键的数据结构和算法包括：

- 发送缓冲区和接收缓冲区：用于存储待发送和接收的数据。
- 滑动窗口机制：用于实现流量控制和拥塞控制，控制发送方发送数据的速率。
- 序列号和确认号：用于实现数据包的顺序问题和丢包问题的处理。
- 超时重传机制：用于处理丢包问题，当发送方未收到确认时，会重新发送数据。
- 拥塞控制算法：如慢启动、拥塞避免和快速重传等，用于控制网络拥塞情况下的数据传输速率。

这些数据结构和算法共同协作，确保 TCP 连接的可靠性、有序性和高效性。



## 第12讲 | TCP协议（下）：西行必定多妖孽，恒心智慧消磨难

​		我们前面说到玄奘西行，要出网关。既然出了网关，那就是在公网上传输数据，公网往往是不可靠的，因而需要很多的机制去保证传输的可靠性，这里面需要恒心，也即各种**重传的策略**，还需要有智慧，也就是说，这里面包含着**大量的算法**。



### 如何做个靠谱的人？

TCP 想成为一个成熟稳重的人，成为一个靠谱的人。那一个人怎么样才算靠谱呢？咱们工作中经常就有这样的场景，比如你交代给下属一个事情以后，下属到底能不能做到，做到什么程度，什么时候能够交付，往往就会有应答，有回复。这样，处理事情的过程中，一旦有异常，你也可以尽快知道，而不是交代完之后就石沉大海，过了一个月再问，他说，啊我不记得了。



对应到网络协议上，就是客户端每发送的一个包，服务器端都应该有个回复，如果服务器端超过一定的时间没有回复，客户端就会重新发送这个包，直到有**回复**。



这个发送应答的过程是什么样呢？可以是**上一个收到了应答，再发送下一个**。这种模式有点像两个人直接打电话，你一句，我一句。但是这种方式的缺点是效率比较低。如果一方在电话那头处理的时间比较长，这一头就要干等着，双方都没办法干其他事情。咱们在日常工作中也不是这样的，不能你交代你的下属办一件事情，就一直打着电话看着他做，而是应该他按照你的安排，先将事情记录下来，办完一件回复一件。在他办事情的过程中，你还可以同时交代新的事情，这样双方就并行了。



如果使⽤这种模式，其实需要你和你的下属就不能靠脑⼦了，⽽是要都准备⼀个本⼦，你每交代下属⼀个事情，双方的本子都要记录⼀下。



当你的下属做完⼀件事情，就回复你，做完了，你就在你的本⼦上将这个事情划去。同时你的本⼦上**每件事情都有时限，如果超过了时限下属还没有回复，你就要主动重新交代⼀下**：上次那件事情，你还没回复我，咋样啦？



既然多件事情可以一起处理，那就需要给每个事情编个号，防止弄错了。例如，程序员平时看任务的时候，都会看 JIRA 的 ID，而不是每次都要描述一下具体的事情。在大部分情况下，对于事情的处理是按照顺序来的，先来的先处理，这就给应答和汇报工作带来了方便。等开周会的时候，每个程序员都可以将 JIRA ID 的列表拉出来，说以上的都做完了，⽽不⽤⼀个个说。



### 如何实现一个靠谱的协议？

​		TCP 协议使用的也是同样的模式。为了保证顺序性，每一个包都有一个 ID。在建立连接的时候，会商定起始的 ID 是什么，然后按照 ID 一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的 ID，表示都收到了，这种模式称为**累计确认**或者**累计应答**（**cumulative acknowledgment**）。



​	为了记录所有发送的包和接收的包，TCP 也需要发送端和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的 ID 一个个排列，根据处理的情况分成四个部分。



第一部分：发送了并且已经确认的。这部分就是你交代下属的，并且也做完了的，应该划掉的。

第二部分：发送了并且尚未确认的。这部分是你交代下属的，但是还没做完的，需要等待做完的回复之后，才能划掉。

第三部分：没有发送，但是已经等待发送的。这部分是你还没有交代给下属，但是马上就要交代的。

第四部分：没有发送，并且暂时还不会发送的。这部分是你还没有交代给下属，而且暂时还不会交代给下属的。



这里面为什么要区分第三部分和第四部分呢？没交代的，一下子全交代了不就完了吗？

这就是我们上一节提到的十个词口诀里的“**流量控制，把握分寸**”。作为项目管理人员，你应该根据以往的工作情况和这个员工反馈的能力、抗压力等，先在心中估测一下，这个人一天能做多少工作。如果工作布置少了，就会不饱和；如果工作布置多了，他就会做不完；如果你使劲逼迫，人家可能就要辞职了。



到底一个员工能够同时处理多少事情呢？在 TCP 里，接收端会给发送端报一个窗口的大小，叫 **Advertised window**。这个窗口的大小应该等于上面的第二部分加上第三部分，就是已经交代了没做完的加上马上要交代的。超过这个窗口的，接收端做不过来，就不能发送了。



于是，发送端需要保持下面的数据结构。

<img src="趣谈网络协议.assets/dd67ba62279a3849c11ffc1deea25d44.jpg" alt="img" style="zoom:33%;" />

- LastByteAcked：第一部分和第二部分的分界线
- LastByteSent：第二部分和第三部分的分界线
- LastByteAcked + AdvertisedWindow：第三部分和第四部分的分界线



对于接收端来讲，它的缓存里记录的内容要简单一些。



第一部分：接受并且确认过的。也就是我领导交代给我，并且我做完的。

第二部分：还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量。

第三部分：还没接收，也没法接收的。也即超过工作量的部分，实在做不完。

对应的数据结构就像这样。

<img src="趣谈网络协议.assets/9d597af268016f67caa14178627188be.jpg" alt="img" style="zoom: 33%;" />



- MaxRcvBuffer：最大缓存的量；
- LastByteRead 之后是已经接收了，但是还没被应用层读取的；
- NextByteExpected 是第一部分和第二部分的分界线。



第二部分的窗口有多大呢？

NextByteExpected 和 LastByteRead 的差（接收已确认部分）其实是还没被应用层读取的部分占用掉的 MaxRcvBuffer 的量，我们定义为 A。

AdvertisedWindow 其实是 MaxRcvBuffer 减去 A。

也就是：AdvertisedWindow=MaxRcvBuffer-((NextByteExpected-1)-LastByteRead)。



那第二部分和第三部分的分界线在哪里呢？NextByteExpected 加 AdvertisedWindow 就是第二部分和第三部分的分界线，其实也就是 LastByteRead 加上 MaxRcvBuffer。



其中第二部分里面，由于受到的包可能不是顺序的，会出现空档，只有和第一部分连续的，可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了。



### 顺序问题与丢包问题

接下来我们结合一个例子来看。



还是刚才的图，在发送端来看，1、2、3 已经发送并确认；4、5、6、7、8、9 都是发送了还没确认；10、11、12 是还没发出的；13、14、15 是接收方没有空间，不准备发的。



在接收端来看，1、2、3、4、5 是已经完成 ACK，但是没读取的；6、7 是等待接收的；8、9 是已经接收，但是没有 ACK 的。



发送端和接收端当前的状态如下：

- 1、2、3 没有问题，双方达成了一致。
- 4、5 接收方说 ACK 了，但是发送方还没收到，有可能丢了，有可能在路上。
- 6、7、8、9 肯定都发了，但是 8、9 已经到了，但是 6、7 没到，**出现了乱序**，缓存着但是没办法 ACK。

根据这个例子，我们可以知道，顺序问题和丢包问题都有可能发生，所以我们先来看**确认与重发的机制**。



假设 4 的确认到了，不幸的是，5 的 ACK 丢了，6、7 的数据包丢了，这该怎么办呢？

一种方法就是**超时重试**，也即对每一个发送了，但是没有 ACK 的包，都有设一个定时器，超过了一定的时间，就重新尝试。但是这个超时的时间如何评估呢？**这个时间不宜过短，时间必须大于往返时间 RTT**，否则会引起不必要的重传。**也不宜过长**，这样超时时间变长，访问就变慢了。



估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断地变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为**自适应重传算法**（**Adaptive Retransmission Algorithm**）。



如果过一段时间，5、6、7 都超时了，就会重新发送。接收方发现 5 原来接收过，于是丢弃 5；6 收到了，发送 ACK，要求下一个是 7，7 不幸又丢了。当 7 再次超时的时候，有需要重传的时候，TCP 的策略是**超时间隔加倍**。**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍**。**两次超时，就说明网络环境差，不宜频繁反复发送。**



超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？

有一个可以**快速重传的机制**（接收方发现缺少中间包，就发送冗余ACK），当接收方收到一个序号大于下一个所期望的报文段时，就会检测到数据流中的一个间隔，于是它就会发送冗余的 ACK，仍然 ACK 的是期望接收的报文段。而当客户端收到三个冗余的 ACK 后，就会在定时器过期之前，重传丢失的报文段。



例如，接收方发现 6 收到了，8 也收到了，但是 7 还没来，那肯定是丢了，于是发送 6 的 ACK，要求下一个是 7。接下来，收到后续的包，仍然发送 6 的 ACK，要求下一个是 7。当客户端收到 3 个重复 ACK，就会发现 7 的确丢了，不等超时，马上重发。



还有一种方式称为 **Selective Acknowledgment**  （**SACK**）。这种方式需要在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发送给发送方。例如可以发送 ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是 7 丢了。





### 流量控制问题

我们再来看流量控制机制，在对于包的确认中，同时会携带一个窗口的大小。



我们先假设窗口不变的情况，窗口始终为 9。4 的确认来的时候，会右移一个，这个时候第 13 个包也可以发送了。

<img src="趣谈网络协议.assets/af16ecdfabf97f696d8133a20818fd87.jpg" alt="img" style="zoom: 33%;" />

这个时候，假设发送端发送过猛，会将第三部分的 10、11、12、13 全部发送完毕，之后就停止发送了，未发送可发送部分为 0。

<img src="趣谈网络协议.assets/e011cb0e56f43bae942f0b7ab7407b35.jpg" alt="img" style="zoom:33%;" />

当对于包 5 的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以发送了，例如第 14 个包才可以发送。

<img src="趣谈网络协议.assets/f5a4fcc035d1bb2d7e11c38391d768c2.jpg" alt="img" style="zoom:33%;" />

**如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为 0，则发送方将暂时停止发送**。



我们假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包 6 确认后，窗口大小就不能再是 9 了，就要缩小一个变为 8。

<img src="趣谈网络协议.assets/953e6706cfb5083e1f25b267505f5c9d.jpg" alt="img" style="zoom:33%;" />

这个新的窗口 8 通过 6 的确认消息到达发送端的时候，你会发现窗口没有平行右移，而是仅仅左面的边右移了，窗口的大小从 9 改成了 8。

<img src="趣谈网络协议.assets/0a9265c63d5e0fb08c442ea0a7cffa1f.jpg" alt="img" style="zoom:33%;" />

如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为 0。

<img src="趣谈网络协议.assets/c24c414c31bd5deb346f98417ecdb74a.jpg" alt="img" style="zoom:33%;" />

当这个窗口通过包 14 的确认到达发送端的时候，发送端的窗口也调整为 0，停止发送。

<img src="趣谈网络协议.assets/89fe7b73e40363182b13e3d9c9aa2acb.jpg" alt="img" style="zoom:33%;" />

**如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。**当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。



这就是我们常说的流量控制。



### 拥塞控制问题

最后，我们看一下拥塞控制的问题，也是通过窗口的大小来控制的，**前面的滑动窗口 rwnd 是怕发送方把接收方缓存塞满，而拥塞窗口 cwnd，是怕把网络塞满**。

这里有一个公式 LastByteSent - LastByteAcked (即未应答的包）<= min {cwnd, rwnd} ，是拥塞窗口和滑动窗口共同控制发送的速度。



那发送方怎么判断网络是不是慢呢？这其实是个挺难的事情，因为对于 TCP 协议来讲，他压根不知道整个网络路径都会经历什么，对他来讲就是一个黑盒。TCP 发送包常被比喻为往一个水管里面灌水，而 TCP 的拥塞控制就是在不堵塞，不丢包的情况下，尽量发挥带宽。



水管有粗细，网络有带宽，也即每秒钟能够发送多少数据；水管有长度，端到端有时延。在理想状态下，水管里面水的量 = 水管粗细 x 水管长度。对于到网络上，通道的容量 = 带宽 × 往返延迟。



如果我们设置发送窗口，使得发送但未确认的包为为通道的容量，就能够撑满整个管道。

<img src="趣谈网络协议.assets/c467d450d8000472e690ed378b8019c6.jpeg" alt="img" style="zoom:33%;" />

如图所示，假设往返时间为 8s，去 4s，回 4s，每秒发送一个包，每个包 1024byte。已经过去了 8s，则 8 个包都发出去了，其中前 4 个包已经到达接收端，但是 ACK 还没有返回，不能算发送成功。5-8 后四个包还在路上，还没被接收。这个时候，整个管道正好撑满，在发送端，已发送未确认的为 8 个包，正好等于带宽，也即每秒发送 1 个包，乘以来回时间 8s。



如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？



我们来想，原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费 1s，所以到达另一端需要耗费 4s，如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，**这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这是我们不想看到的**。



这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的在队列里面排着，这样包就不会丢失，但是缺点是会增加时延，这个缓存的包，4s 肯定到达不了接收端了，如果时延达到一定程度，就会超时重传，也是我们不想看到的。



于是 TCP 的拥塞控制主要来避免两种现象，**包丢失**和**超时重传**。一旦出现了这些现象就说明，发送速度太快了，要慢一点。但是一开始我怎么知道速度多快呢，我怎么知道应该把窗口调整到多大呢？



如果我们通过漏斗往瓶子里灌水，我们就知道，不能一桶水一下子倒进去，肯定会溅出来，要一开始慢慢的倒，然后发现总能够倒进去，就可以越倒越快。这叫作**慢启动**。



一条 TCP 连接开始，cwnd 设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd 加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认 cwnd 加一，两个确认 cwnd 加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认 cwnd 加一，四个确认 cwnd 加四，于是一次能够发送八个。可以看出这是**指数性的增长**。



涨到什么时候是个头呢？有一个值 ssthresh 为 65535 个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，可能快满了，再慢下来。



每收到一个确认后，cwnd 增加 1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加 1/8，八个确认一共 cwnd 增加 1，于是一次能够发送九个，变成了线性增长。



但是线性增长还是增长，还是越来越多，直到有一天，水满则溢，出现了拥塞，这时候一般就会一下子降低倒水的速度，等待溢出的水慢慢渗下去。



拥塞的一种表现形式是丢包，需要超时重传，这个时候，将 **sshresh** 设为 cwnd/2，将 cwnd 设为 1，重新开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。



前面我们讲过**快速重传算法**。当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd 减半为 cwnd/2，然后 sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。



就像前面说的一样，正是这种知进退，使得时延很重要的情况下，反而降低了速度。但是如果你仔细想一下，TCP 的拥塞控制主要来避免的两个现象都是有问题的。



**第一个问题**是丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。



**第二个问题**是 TCP 的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实 TCP 只要填满管道就可以了，不应该接着填，直到连缓存也填



为了优化这两个问题，后来有了 **TCP BBR 拥塞算法**。它企图找到一个平衡点，就是通过不断地加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。



<img src="趣谈网络协议.assets/a2b3a5df5eca52e302b75824e4bbbd4c.jpg" alt="img" style="zoom: 67%;" />

### 小结

好了，这一节我们就到这里，总结一下：

- 顺序问题、丢包问题、流量控制都是通过滑动窗口来解决的，这其实就相当于你领导和你的工作备忘录，布置过的工作要有编号，干完了有反馈，活不能派太多，也不能太少；
- 拥塞控制是通过拥塞窗口来解决的，相当于往管道里面倒水，快了容易溢出，慢了浪费带宽，要摸着石头过河，找到最优值。



最后留两个思考题：

1. TCP 的 BBR 听起来很牛，你知道他是如何达到这个最优点的嘛？
2. 学会了 UDP 和 TCP，你知道如何基于这两种协议写程序吗？这样的程序会有什么坑呢？

> chatGPT

1. TCP的BBR（Bottleneck Bandwidth and Round-trip propagation time）是一种拥塞控制算法，旨在通过动态调整发送速率来优化网络吞吐量和延迟。BBR通过测量网络的带宽和往返时间（RTT），以及对拥塞的敏感性，来决定发送速率。它使用了一种称为“带宽探测”的机制，通过发送特定的数据包并观察网络的反馈来估计网络的带宽。BBR还使用了一种称为“拥塞控制”的机制，根据网络的拥塞程度来调整发送速率。通过这些机制，BBR能够在网络中找到最佳的带宽和延迟点，从而实现更高的吞吐量和更低的延迟。
2. 基于UDP和TCP编写程序时，需要考虑以下几个方面的问题：

- UDP：UDP是一种无连接的协议，它提供了一种快速的、不可靠的数据传输方式。在编写UDP程序时，需要注意数据包的丢失、乱序和重复的可能性。此外，由于UDP不提供拥塞控制机制，发送方需要自行处理发送速率和拥塞情况，以避免网络拥塞。
- TCP：TCP是一种面向连接的协议，它提供了可靠的、有序的数据传输方式。在编写TCP程序时，需要注意建立连接、数据传输和断开连接的过程。TCP会自动处理数据包的丢失、乱序和重复，并提供拥塞控制机制来适应网络状况。但是，TCP也可能面临拥塞窗口调整、慢启动等问题，需要合理设置参数和处理这些情况。

在编写UDP和TCP程序时，还需要考虑网络延迟、带宽限制、数据包大小等因素。此外，还需要处理超时、错误处理、数据完整性验证等问题，以确保程序的稳定性和可靠性。



## 第13讲 | 套接字Socket：Talk is cheap, show me the code



前面讲完了 TCP 和 UDP 协议，还没有上手过，这一节咱们讲讲基于 TCP 和 UDP 协议的 Socket 编程。

在讲 TCP 和 UDP 协议的时候，我们分客户端和服务端，在写程序的时候，我们也同样这样分。

Socket 这个名字很有意思，可以作插口或者插槽讲。虽然我们是写软件程序，但是你可以想象为弄一根网线，一头插在客户端，一头插在服务端，然后进行通信。所以在通信之前，双方都要建立一个 Socket。

在建立 Socket 的时候，应该设置什么参数呢？Socket 编程进行的是端到端的通信，往往意识不到中间经过多少局域网，多少路由器，因而能够设置的参数，也只能是端到端协议之上网络层和传输层的。



在网络层，Socket 函数需要指定到底是 IPv4 还是 IPv6，分别对应设置为 AF_INET（address family） 和 AF_INET6。

另外，还要指定到底是 TCP 还是 UDP。还记得咱们前面讲过的，**TCP 协议是基于数据流的，所以设置为 SOCK_STREAM**，而 **UDP 是基于数据报的，因而设置为 SOCK_DGRAM**。



### 基于 TCP 协议的 Socket 程序函数调用过程

两端创建了 Socket 之后，接下来的过程中，TCP 和 UDP 稍有不同，我们先来看 TCP。



服务端：

TCP 的**服务端**要先监听一个端口，一般是**先调用 bind 函数**，给这个 Socket 赋予一个 IP 地址和端口。

为什么需要端口呢？要知道，你写的是一个应用程序，当一个网络包来的时候，内核要通过 TCP 头里面的这个端口，来找到你这个应用程序，把包给你。为什么要 IP 地址呢？有时候，一台机器会有多个网卡，也就会有多个 IP 地址，你可以选择监听所有的网卡，也可以选择监听一个网卡，这样，只有发给这个网卡的包，才会给你。



当服务端有了 IP 和端口号，就可以**调用 listen 函数进行监听**。在 TCP 的状态图里面，有一个 listen 状态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。



在内核中，为每个 Socket 维护两个队列。

一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于 established 状态；

一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于 syn_rcvd 的状态。

<img src="趣谈网络协议.assets/c067fe62f49e8152368c7be9d91adc08.jpg" alt="img" style="zoom:33%;" />



接下来，服务端**调用 accept 函数**，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。



客户端：

在服务端等待的时候，客户端可以**通过 connect 函数发起连接**。先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。**一旦握手成功，服务端的 accept 就会返回另一个 Socket**。



这是一个经常考的知识点，就是监听的 Socket 和真正用来传数据的 Socket 是两个，一个叫作**监听 Socket**，一个叫作**已连接 Socket**。

连接建立成功之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。

这个图就是基于 TCP 协议的 Socket 程序函数调用过程。

<img src="趣谈网络协议.assets/87c8ae36ae1b42653565008fc47aceea.jpg" alt="img" style="zoom: 33%;" />





说 TCP 的 Socket 就是一个文件流，是非常准确的。因为，Socket 在 Linux 中就是以文件的形式存在的。除此之外，还存在文件描述符。写入和读出，也是通过文件描述符。

在内核中，Socket 是一个文件，那对应就有文件描述符。**每一个进程都有一个数据结构 task_struct**，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的**文件描述符**。文件描述符是一个整数，是这个数组的下标。



这个数组中的内容是一个指针，指向内核中所有打开的文件的列表。既然是一个文件，就会有一个 inode，只不过 Socket 对应的 inode 不像真正的文件系统一样，保存在硬盘上的，而是在内存中的。在这个 inode 中，指向了 Socket 在内核中的 Socket 结构。

在这个结构里面，主要的是两个队列，一个是**发送队列**，一个是**接收队列**。在这两个队列里面保存的是一个**缓存 sk_buff**。这个缓存里面能够看到完整的包的结构。看到这个，是不是能和前面讲过的收发包的场景联系起来了？



整个数据结构如图。

<img src="趣谈网络协议.assets/604f4cb37576990b3f836cb5d7527b13.jpg" alt="img" style="zoom: 25%;" />



#### php代码例子

server：

```php
<?php
// 创建Socket
// AF_INET表示使用IPv4地址族，其中的"AF"代表"Address Family"，"INET"代表"Internet"。
// SOL_TCP表示使用TCP协议的协议级别。其中的"SOL"代表"Socket Option Level"，"TCP"代表"Transmission Control Protocol"，即传输控制协议。
$socket = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);
if ($socket === false) {
    echo "无法创建Socket: " . socket_strerror(socket_last_error()) . "\n";
    exit;
}

// 绑定Socket到IP地址和端口
$host = "127.0.0.1";
$port = 18080;
$result = socket_bind($socket, $host, $port);
if ($result === false) {
    echo "无法绑定Socket: " . socket_strerror(socket_last_error($socket)) . "\n";
    exit;
}

// 监听连接
$result = socket_listen($socket, 5);
if ($result === false) {
    echo "无法监听连接: " . socket_strerror(socket_last_error($socket)) . "\n";
    exit;
}

echo "服务器已启动，等待客户端连接...\n";

// 接受客户端连接 (另起一个连接)
$clientSocket = socket_accept($socket);
if ($clientSocket === false) {
    echo "无法接受客户端连接: " . socket_strerror(socket_last_error($socket)) . "\n";
    exit;
}

echo "客户端已连接\n";

// 接收客户端数据
$clientData = socket_read($clientSocket, 1024);
echo "接收到客户端数据: " . $clientData . "\n";

// 处理客户端请求
$response = "Hello, Client!";
socket_write($clientSocket, $response, strlen($response));

// 关闭客户端Socket连接
socket_close($clientSocket);

// 关闭服务器Socket
socket_close($socket);
?>
```



client：

```php
<?php
// 创建Socket
$socket = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);
if ($socket === false) {
    echo "无法创建Socket: " . socket_strerror(socket_last_error()) . "\n";
    exit;
}

// 连接到服务器
$host = "127.0.0.1";
$port = 18080;
$result = socket_connect($socket, $host, $port);
if ($result === false) {
    echo "无法连接到服务器: " . socket_strerror(socket_last_error($socket)) . "\n";
    exit;
}

// 发送数据
$message = "Hello, Server!";
socket_write($socket, $message, strlen($message));

// 接收服务器响应
$response = socket_read($socket, 1024);

// 关闭Socket连接
socket_close($socket);

// 处理服务器响应
echo "服务器响应: " . $response . "\n";
?>
```



### 基于 UDP 协议的 Socket 程序函数调用过程

对于 UDP 来讲，过程有些不一样。UDP 是没有连接的，所以不需要三次握手，也就不需要调用 listen 和 connect，但是，UDP 的交互仍然需要 IP 和端口号，因而也需要 bind。

**UDP 是没有维护连接状态的，因而不需要每对连接建立一组 Socket，而是只要有一个 Socket**，就能够和多个客户端通信。

也正是因为没有连接状态，每**次通信的时候，都调用 sendto 和 recvfrom**，都可以传入 IP 地址和端口。



这个图的内容就是基于 UDP 协议的 Socket 程序函数调用过程。

<img src="趣谈网络协议.assets/6bbe12c264f5e76a81523eb8787f3931.jpg" alt="img" style="zoom:33%;" />

#### php代码示例

接收方代码（receiver.php）：

```php
<?php
// 创建Socket
$socket = socket_create(AF_INET, SOCK_DGRAM, SOL_UDP);
if ($socket === false) {
    echo "无法创建Socket: " . socket_strerror(socket_last_error()) . "\n";
    exit;
}

// 绑定Socket到IP地址和端口
$host = "127.0.0.1";
$port = 8080;
$result = socket_bind($socket, $host, $port);
if ($result === false) {
    echo "无法绑定Socket: " . socket_strerror(socket_last_error($socket)) . "\n";
    exit;
}

echo "等待接收数据...\n";

// 接收数据
$result = socket_recvfrom($socket, $buffer, 1024, 0, $clientAddress, $clientPort);
if ($result === false) {
    echo "无法接收数据: " . socket_strerror(socket_last_error($socket)) . "\n";
    exit;
}

echo "接收到数据: " . $buffer . "\n";

// 关闭Socket连接
socket_close($socket);
?>
```

发送方代码（sender.php）：

```php
<?php
// 创建Socket
$socket = socket_create(AF_INET, SOCK_DGRAM, SOL_UDP);
if ($socket === false) {
    echo "无法创建Socket: " . socket_strerror(socket_last_error()) . "\n";
    exit;
}

// 目标地址和端口
$host = "127.0.0.1";
$port = 8080;

// 发送数据
$message = "Hello, Server!";
$result = socket_sendto($socket, $message, strlen($message), 0, $host, $port);
if ($result === false) {
    echo "无法发送数据: " . socket_strerror(socket_last_error($socket)) . "\n";
    exit;
}

echo "数据发送成功\n";

// 关闭Socket连接
socket_close($socket);
?>
```



### 服务器如何接更多的项目？

会了这几个基本的 Socket 函数之后，你就可以轻松地写一个网络交互的程序了。就像上面的过程一样，在建立连接后，进行一个 while 循环。客户端发了收，服务端收了发。



当然这只是万里长征的第一步，因为如果使用这种方法，基本上只能一对一沟通。如果你是一个服务器，同时只能服务一个客户，肯定是不行的。这就相当于老板成立一个公司，只有自己一个人，自己亲自上来服务客户，只能干完了一家再干下一家，这样赚不来多少钱。



那作为老板你就要想了，我最多能接多少项目呢？当然是越多越好。



我们先来算一下理论值，也就是**最大连接数**，系统会用一个**四元组来标识一个 TCP 连接**。

```
{本机IP, 本机端口, 对端IP, 对端端口}
```

服务器通常固定在某个本地端口上监听，等待客户端的连接请求。因此，服务端端 TCP 连接四元组中只有对端 IP, 也就是客户端的 IP 和对端的端口，也即客户端的端口是可变的，因此，最大 TCP 连接数 = 客户端 IP 数×客户端端口数。对 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数，约为 2 的 48 次方。



当然，服务端最大并发 TCP 连接数远不能达到理论上限。

首先主要是**文件描述符限制**，按照上面的原理，Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目；

另一个限制是**内存**，按上面的数据结构，每个 TCP 连接都要占用一定内存，操作系统是有限的。



所以，作为老板，在资源有限的情况下，要想接更多的项目，就需要降低每个项目消耗的资源数目。

#### 方式一：将项目外包给其他公司（多进程方式）

这就相当于你是一个代理，在那里监听来的请求。一旦建立了一个连接，就会有一个已连接 Socket，这时候你可以创建一个子进程，然后将基于已连接 Socket 的交互交给这个新的子进程来做。就像来了一个新的项目，但是项目不一定是你自己做，可以再注册一家子公司，招点人，然后把项目转包给这家子公司做，以后对接就交给这家子公司了，你又可以去接新的项目了。

这里有一个问题是，如何创建子公司，并如何将项目移交给子公司呢？

在 Linux 下，**创建子进程使用 fork 函数**。通过名字可以看出，这是在父进程的基础上完全拷贝一个子进程。**在 Linux 内核中，会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到了哪一行程序的进程**。显然，复制的时候在调用 fork，复制完毕之后，父进程和子进程都会记录当前刚刚执行完 fork。这两个进程刚复制完的时候，几乎一模一样，只是**根据 fork 的返回值来区分到底是父进程，还是子进程。如果返回值是 0，则是子进程；**如果返回值是其他的整数，就是父进程。



<img src="趣谈网络协议.assets/18070c00ff5d0082yy1fbc32b84e73d0.jpg" alt="img" style="zoom: 15%;" />

因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为 accept 创建的已连接 Socket 也是一个文件描述符，同样也会被子进程获得。



接下来，子进程就可以通过这个已连接 Socket 和客户端进行互通了，当通信完毕之后，就可以退出进程，

那父进程如何知道子进程干完了项目，要退出呢？**还记得 fork 返回的时候，如果是整数就是父进程吗？这个整数就是子进程的 ID，父进程可以通过这个 ID 查看子进程是否完成项目，是否需要退出**。



#### 方式二：将项目转包给独立的项目组（多线程方式）

上面这种方式你应该也能发现问题，如果每次接一个项目，都申请一个新公司，然后干完了，就注销掉这个公司，实在是太麻烦了。毕竟一个新公司要有新公司的资产，有新的办公家具，每次都买了再卖，不划算。



于是你应该想到了，我们可以使用**线程**。相比于进程来讲，这样要轻量级的多。如果创建进程相当于成立新公司，购买新办公家具，而创建线程，就相当于在同一个公司成立项目组。一个项目做完了，那这个项目组就可以解散，组成另外的项目组，办公家具可以共用。

在 Linux 下，通过 pthread_create 创建一个线程，也是调用 do_fork。不同的是，虽然新的线程在 task 列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，还是共享的，只不过多了一个引用而已。

<img src="趣谈网络协议.assets/a36537201678e08ac83e5410562d5f64.jpg" alt="img" style="zoom: 15%;" />

新的线程也可以通过已连接 Socket 处理请求，从而达到并发处理的目的。



上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程。一台机器无法创建很多进程或者线程。有个 **C10K**，它的意思是一台机器要维护 1 万个连接，就要创建 1 万个进程或者线程，那么操作系统是无法承受的。如果维持 1 亿用户在线需要 10 万台服务器，成本也太高了。

其实 C10K 问题就是，你接项目接的太多了，如果每个项目都成立单独的项目组，就要招聘 10 万人，你肯定养不起，那怎么办呢？





#### 方式三：一个项目组支撑多个项目（IO 多路复用，一个线程维护多个 Socket）



当然，一个项目组可以看多个项目了。这个时候，每个项目组都应该有个项目进度墙，将自己组看的项目列在那里，然后每天通过项目墙看每个项目的进度，一旦某个项目有了进展，就派人去盯一下。

由于 Socket 是文件描述符，因而某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中，这就是**项目进度墙**，然后调用 select 函数来监听文件描述符集合是否有变化。一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化。



#### 方式四：一个项目组支撑多个项目（IO 多路复用，从“派人盯着”到“有事通知”）

上面 select 函数还是有问题的，因为每次 Socket 所在的文件描述符集合中有 Socket 发生变化的时候，都需要通过轮询的方式，也就是需要将全部项目都过一遍的方式来查看进度，这大大影响了一个项目组能够支撑的最大的项目数量。因而使用 select，能够同时盯的项目数量由 FD_SETSIZE 限制。



如果改成事件通知的方式，情况就会好很多，项目组不需要通过轮询挨个盯着这些项目，而是当项目进度发生变化的时候，主动通知项目组，然后项目组再根据项目进展情况做相应的操作。



能完成这件事情的函数叫 epoll，它在内核中的实现不是通过轮询的方式，而是通过**注册 callback 函数**的方式，当某个文件描述符发送变化的时候，就会主动通知。



<img src="趣谈网络协议.assets/d6efc5c5ee8e48dae0323de380dcf6b1.jpg" alt="img" style="zoom:25%;" />

如图所示，假设进程打开了 Socket m, n, x 等多个文件描述符，现在需要通过 epoll 来监听是否这些 Socket 都有事件发生。其中 epoll_create 创建一个 epoll 对象，也是一个文件，也对应一个文件描述符，同样也对应着打开文件列表中的一项。在这项里面有一个红黑树，在红黑树里，要保存这个 epoll 要监听的所有 Socket。



当 epoll_ctl 添加一个 Socket 的时候，其实是加入这个红黑树，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的 Socket 的事件列表中。当一个 Socket 来了一个事件的时候，可以从这个列表中得到 epoll 对象，并调用 call  back 通知它。



这种通知方式使得监听的 Socket 数据增加的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了。上限就为系统定义的、进程打开的最大文件描述符个数。因而，**epoll 被称为解决 C10K 问题的利器**。



### 小结

总结一下：

- 你需要记住 TCP 和 UDP 的 Socket 的编程中，客户端和服务端都需要调用哪些函数；
- 写一个能够支撑大量连接的高并发的服务端不容易，需要多进程、多线程，而 epoll 机制能解决 C10K 问题。



最后，给你留两个思考题：

1. epoll 是 Linux 上的函数，那你知道 Windows 上对应的机制是什么吗？如果想实现一个跨平台的程序，你知道应该怎么办吗？
2. 自己写 Socket 还是挺复杂的，写个 HTTP 的应用可能简单一些。那你知道 HTTP 的工作机制吗？

> chatGPT

1、Windows上对应的机制是IOCP（Input/Output Completion Ports）。IOCP是Windows提供的一种高性能的异步I/O模型，用于处理大量的并发I/O操作。

如果想实现一个跨平台的程序，可以使用跨平台的网络库或框架，例如Boost.Asio、libuv或Poco等。这些库提供了对不同操作系统的网络编程接口的封装，使得开发者可以在不同平台上使用统一的API进行网络编程。

2、HTTP（Hypertext Transfer Protocol）是一种用于在客户端和服务器之间传输超文本的协议。它基于请求-响应模型，客户端发送HTTP请求到服务器，服务器处理请求并返回HTTP响应。

HTTP的工作机制可以简单概括为以下步骤：

1. 客户端发起HTTP请求，包括请求方法（GET、POST等）、URL、请求头和请求体等信息。
2. 服务器接收到请求后，解析请求，根据请求的URL和方法执行相应的处理逻辑。
3. 服务器生成HTTP响应，包括响应状态码、响应头和响应体等信息。
4. 服务器将HTTP响应发送回客户端。
5. 客户端接收到响应后，解析响应，根据响应的状态码和内容进行相应的处理。

HTTP协议使用TCP作为传输协议，默认使用80端口进行通信。它是一种无状态的协议，每个请求和响应都是独立的，服务器不会保留客户端的状态信息。

HTTP还支持一些常见的功能，如会话管理（使用Cookie和Session）、缓存控制、身份验证等，以满足不同的应用需求。





# 第二模块 底层网络知识详解：最常用的应用层

## 第14讲 | HTTP协议：看个新闻原来这么麻烦

前面讲述完**传输层**，接下来开始讲**应用层**的协议。从哪里开始讲呢，就从咱们最常用的 HTTP 协议开始。

HTTP 协议，几乎是每个人上网用的第一个协议，同时也是很容易被人忽略的协议。

既然说看新闻，咱们就先登录 [http://www.163.com](http://www.163.com/) 。

[http://www.163.com](http://www.163.com/) 是个 URL，叫作**统一资源定位符**。之所以叫统一，是因为它是有格式的。HTTP 称为协议，www.163.com 是一个域名，表示互联网上的一个位置。有的 URL 会有更详细的位置标识，例如 http://www.163.com/index.html 。正是因为这个东西是统一的，所以当你把这样一个字符串输入到浏览器的框里的时候，浏览器才知道如何进行统一处理。



### HTTP 请求的准备

浏览器会将 www.163.com 这个域名发送给 DNS 服务器，让它解析为 IP 地址。有关 DNS 的过程，其实非常复杂，这个在后面专门介绍 DNS 的时候，我会详细描述，这里我们先不管，反正它会被解析成为 IP 地址。那接下来是发送 HTTP 请求吗？



不是的，HTTP 是基于 TCP 协议的，当然是要先建立 TCP 连接了，怎么建立呢？还记得第 11 节讲过的三次握手吗？

目前使用的 HTTP 协议大部分都是 1.1。在 1.1 的协议里面，默认是开启了 Keep-Alive 的，这样建立的 TCP 连接，就可以在多次请求中复用。

学习了 TCP 之后，你应该知道，TCP 的三次握手和四次挥手，还是挺费劲的。如果好不容易建立了连接，然后就做了一点儿事情就结束了，有点儿浪费人力和物力。



### HTTP 请求的构建

建立了连接以后，浏览器就要发送 HTTP 的请求。

请求的格式就像这样。

<img src="趣谈网络协议.assets/85ebb0396cbaa45ce00b505229e523c1.jpeg" alt="img" style="zoom:35%;" />



HTTP 的报文大概分为三大部分。第一部分是**请求行**，第二部分是请求的**首部**，第三部分才是请求的**正文实体**。

#### 第一部分：请求行

在请求行中，URL 就是 [http://www.163.com](http://www.163.com/) ，版本为 HTTP 1.1。这里要说一下的，就是方法。方法有几种类型。



1、对于访问网页来讲，最常用的类型就是 **GET**。顾名思义，GET 就是去服务器获取一些资源。对于访问网页来讲，要获取的资源往往是一个页面。其实也有很多其他的格式，比如说返回一个 JSON 字符串，到底要返回什么，是由服务器端的实现决定的。

例如，在云计算中，如果我们的服务器端要提供一个基于 HTTP 协议的 API，获取所有云主机的列表，这就会使用 GET 方法得到，返回的可能是一个 JSON 字符串。字符串里面是一个列表，列表里面是一项的云主机的信息。



2、另外一种类型叫做 **POST**。它需要主动告诉服务端一些信息，而非获取。要告诉服务端什么呢？一般会放在正文里面。正文可以有各种各样的格式。常见的格式也是 JSON。

例如，我们下一节要讲的支付场景，客户端就需要把“我是谁？我要支付多少？我要买啥？”告诉服务器，这就需要通过 POST 方法。

再如，在云计算里，如果我们的服务器端，要提供一个基于 HTTP 协议的创建云主机的 API，也会用到 POST 方法。这个时候往往需要将“我要创建多大的云主机？多少 CPU 多少内存？多大硬盘？”这些信息放在 JSON 字符串里面，通过 POST 的方法告诉服务器端。



3、还有一种类型叫 **PUT**，就是向指定资源位置上传最新内容。但是，HTTP 的服务器往往是不允许上传文件的，所以 PUT 和 POST 就都变成了要传给服务器东西的方法。

在实际使用过程中，这两者还会有稍许的区别。POST 往往是用来创建一个资源的，而 PUT 往往是用来修改一个资源的。

例如，云主机已经创建好了，我想对这个云主机打一个标签，说明这个云主机是生产环境的，另外一个云主机是测试环境的。那怎么修改这个标签呢？往往就是用 PUT 方法。



4、再有一种常见的就是 **DELETE**。这个顾名思义就是用来删除资源的。例如，我们要删除一个云主机，就会调用 DELETE 方法。



#### 第二部分：首部字段（Header）

请求行下面就是我们的首部字段。首部是 key value，通过冒号分隔。这里面，往往保存了一些非常重要的字段。



例如，**Accept-Charset**，表示**客户端可以接受的字符集**。防止传过来的是另外的字符集，从而导致出现乱码。

再如，**Content-Type** 是指**正文的格式**。例如，我们进行 POST 的请求，如果正文是 JSON，那么我们就应该将这个值设置为 JSON。

这里需要重点说一下的就是**缓存**。为啥要使用缓存呢？那是因为一个非常大的页面有很多东西。



例如，我浏览一个商品的详情，里面有这个商品的价格、库存、展示图片、使用手册等等。商品的展示图片会保持较长时间不变，而库存会根据用户购买的情况经常改变。如果图片非常大，而库存数非常小，如果我们每次要更新数据的时候都要刷新整个页面，对于服务器的压力就会很大。



**对于这种高并发场景下的系统，在真正的业务逻辑之前，都需要有个接入层，将这些静态资源的请求拦在最外面**。

这个架构的图就像这样。

<img src="趣谈网络协议.assets/caec3ba1086557cbf694c621e7e01e1d.jpeg" alt="img" style="zoom:50%;" />

​		其中 DNS、CDN 我在后面的章节会讲。和这一节关系比较大的就是 Nginx 这一层，它如何处理 HTTP 协议呢？对于静态资源，有 Vanish 缓存层。当缓存过期的时候，才会访问真正的 Tomcat 应用集群。



在 HTTP 头里面，**Cache-control** 是用来**控制缓存**的。当客户端发送的请求中包含 max-age （最大缓存过期时间）指令时，如果判定缓存层中，资源的缓存时间数值比指定时间的数值小，那么客户端可以接受缓存的资源；当指定 max-age 值为 0，那么缓存层通常需要将请求转发给应用集群。



另外，**If-Modified-Since** 也是一个关于缓存的。也就是说，如果服务器的资源在某个时间之后更新了，那么客户端就应该下载最新的资源；如果没有更新，服务端会返回“304 Not Modified”的响应，那客户端就不用下载了，也会节省带宽。



到此为止，我们仅仅是拼凑起了 HTTP 请求的报文格式，接下来，浏览器会把它交给下一层传输层。怎么交给传输层呢？其实也无非是用 Socket 这些东西，只不过用的浏览器里，这些程序不需要你自己写，有人已经帮你写好了。



### HTTP 请求的发送

HTTP 协议是基于 TCP 协议的，所以它使用面向连接的方式发送请求，通过 stream 二进制流的方式传给对方。**当然，到了 TCP 层，它会把二进制流变成一个个报文段发送给服务器**。



在发送给每个报文段的时候，都需要对方有一个回应 ACK，来保证报文可靠地到达了对方。如果没有回应，那么 TCP 这一层会进行重新传输，直到可以到达。同一个包有可能被传了好多次，但是 HTTP 这一层不需要知道这一点，因为是 TCP 这一层在埋头苦干。



TCP 层发送每一个报文的时候，都需要加上自己的地址（即源地址）和它想要去的地方（即目标地址），将这两个信息放到 IP 头里面，交给 IP 层进行传输。

IP 层需要查看目标地址和自己是否是在同一个局域网。如果是，就发送 ARP 协议来请求这个目标地址对应的 MAC 地址，然后将源 MAC 和目标 MAC 放入 MAC 头，发送出去即可；如果不在同一个局域网，就需要发送到网关，还要需要发送 ARP 协议，来获取网关的 MAC 地址，然后将源 MAC 和网关 MAC 放入 MAC 头，发送出去。



网关收到包发现 MAC 符合，取出目标 IP 地址，根据路由协议找到下一跳的路由器，获取下一跳路由器的 MAC 地址，将包发给下一跳路由器。

这样路由器一跳一跳终于到达目标的局域网。这个时候，最后一跳的路由器能够发现，目标地址就在自己的某一个出口的局域网上。于是，在这个局域网上发送 ARP，获得这个目标地址的 MAC 地址，将包发出去。

目标的机器发现 MAC 地址符合，就将包收起来；发现 IP 地址符合，根据 IP 头中协议项，知道自己上一层是 TCP 协议，于是解析 TCP 的头，里面有序列号，需要看一看这个序列包是不是我要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。

TCP 头里面还有端口号，HTTP 的服务器正在监听这个端口号。于是，目标机器自然知道是 HTTP 服务器这个进程想要这个包，于是将包发给 HTTP 服务器。HTTP 服务器的进程看到，原来这个请求是要访问一个网页，于是就把这个网页发给客户端。





### HTTP 返回的构建

HTTP 的返回报文也是有一定格式的。这也是基于 HTTP 1.1 的。

<img src="趣谈网络协议.assets/6bc37ddcb4e7a61ca3275790820f2263.jpeg" alt="img" style="zoom: 33%;" />


状态码会反映 HTTP 请求的结果。“200”意味着大吉大利；而我们最不想见的，就是“404”，也就是“服务端无法响应这个请求”。然后，短语会大概说一下原因。

接下来是返回首部的 **key value**。

这里面，**Retry-After** 表示，告诉客户端应该在多长时间以后再次尝试一下。“503 错误”是说“服务暂时不再和这个值配合使用”。



在返回的头部里面也会有 **Content-Type**，表示返回的是 HTML，还是 JSON。

构造好了返回的 HTTP 报文，接下来就是把这个报文发送出去。还是交给 Socket 去发送，还是交给 TCP 层，让 TCP 层将返回的 HTML，也分成一个个小的段，并且保证每个段都可靠到达。

这些段加上 TCP 头后会交给 IP 层，然后把刚才的发送过程反向走一遍。虽然两次不一定走相同的路径，但是逻辑过程是一样的，一直到达客户端。

客户端发现 MAC 地址符合、IP 地址符合，于是就会交给 TCP 层。根据序列号看是不是自己要的报文段，如果是，则会根据 TCP 头中的端口号，发给相应的进程。这个进程就是浏览器，浏览器作为客户端也在监听某个端口。

当浏览器拿到了 HTTP 的报文。发现返回“200”，一切正常，于是就从正文中将 HTML 拿出来。HTML 是一个标准的网页格式。浏览器只要根据这个格式，展示出一个绚丽多彩的网页。



这就是一个正常的 HTTP 请求和返回的完整过程。



### HTTP 2.0

当然 HTTP 协议也在不断的进化过程中，在 HTTP1.1 基础上便有了 HTTP 2.0。



HTTP 1.1 在应用层以纯文本的形式进行通信。每次通信都要带完整的 HTTP 的头，而且不考虑 pipeline 模式的话，每次的过程总是像上面描述的那样一去一回。这样在实时性、并发性上都存在问题。

**请求头压缩：**

为了解决这些问题，HTTP 2.0 会对 HTTP 的头进行一定的压缩，将原来每次都要携带的大量 key  value 在两端建立一个索引表，对相同的头只发送索引表中的索引。



请求**分成流与数据分帧：**

另外，HTTP 2.0 协议将一个 TCP 的连接中，切分成多个流，每个流都有自己的 ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的。

HTTP 2.0 还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。常见的帧有 **Header 帧**，用于传输 Header 内容，并且会开启一个新的流。再就是 **Data 帧**，用来传输正文实体。多个 Data 帧属于同一个流。

通过这两种机制，HTTP 2.0 的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。

**这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据**。



我们来举一个例子。

假设我们的一个页面要发送三个独立的请求，一个获取 css，一个获取 js，一个获取图片 jpg。如果使用 HTTP 1.1 就是串行的，但是如果使用 HTTP 2.0，就可以在一个连接里，客户端和服务端都可以同时发送多个请求或回应，而且不用按照顺序一对一对应。

<img src="趣谈网络协议.assets/9a54f97931377dyy2fde0de93f4ecf1a.jpeg" alt="img" style="zoom:50%;" />

HTTP 2.0 其实是将三个请求变成三个流，将数据分成帧，乱序发送到一个 TCP 连接中。

<img src="趣谈网络协议.assets/3da001fac5701949b94e51caaee887d3.jpeg" alt="img" style="zoom: 50%;" />

​		HTTP 2.0 成功解决了 HTTP 1.1 的队首阻塞问题，同时，也不需要**通过 HTTP 1.x 的 pipeline 机制用多条 TCP 连接来实现并行请求与响应**；减少了 TCP 连接数对服务器性能的影响，同时将页面的多个数据 css、js、 jpg 等通过一个数据链接进行传输，能够加快页面组件的传输速度。



### QUIC 协议的“城会玩”

**HTTP 2.0 虽然大大增加了并发性**，但还是有问题的。因为 HTTP 2.0 也是基于 TCP 协议的，TCP 协议在处理包时是有严格顺序的。



当其中一个数据包遇到问题，TCP 连接需要等待这个包完成重传之后才能继续进行。虽然 HTTP 2.0 通过多个 stream，使得逻辑上一个 TCP 连接上的并行内容，进行多路数据的传输，然而这中间并没有关联的数据。一前一后，前面 stream 2 的帧没有收到，后面 stream 1 的帧也会因此阻塞。



于是，就又到了从 TCP 切换到 UDP，进行“城会玩”的时候了。这就是 Google 的 QUIC 协议，接下来我们来看它是如何“城会玩”的。



#### 机制一：自定义连接机制

我们都知道，一条 TCP 连接是由四元组标识的，分别是源 IP、源端口、目的 IP、目的端口。一旦一个元素发生变化时，就需要断开重连，重新连接。在移动互联情况下，当手机信号不稳定或者在 WIFI 和 移动网络切换时，都会导致重连，从而进行再次的三次握手，导致一定的时延。



这在 TCP 是没有办法的，但是基于 UDP，就可以在 QUIC 自己的逻辑里面维护连接的机制，不再以四元组标识，而是以一个 64 位的随机数作为 ID 来标识，而且 UDP 是无连接的，所以当 IP 或者端口变化的时候，只要 ID 不变，就不需要重新建立连接。



#### 机制二：自定义重传机制

前面我们讲过，TCP 为了保证可靠性，通过使用**序号**和**应答**机制，来解决顺序问题和丢包问题。



任何一个序号的包发过去，都要在一定的时间内得到应答，否则一旦超时，就会重发这个序号的包。那怎么样才算超时呢？还记得我们提过的**自适应重传算法**吗？这个超时是通过**采样往返时间 RTT** 不断调整的。



其实，在 TCP 里面超时的采样存在不准确的问题。例如，发送一个包，序号为 100，发现没有返回，于是再发送一个 100，过一阵返回一个 ACK101。这个时候客户端知道这个包肯定收到了，但是往返时间是多少呢？是 ACK 到达的时间减去后一个 100 发送的时间，还是减去前一个 100 发送的时间呢？事实是，第一种算法把时间算短了，第二种算法把时间算长了。



QUIC 也有个序列号，是递增的。任何一个序列号的包只发送一次，下次就要加一了。例如，发送一个包，序号是 100，发现没有返回；再次发送的时候，序号就是 101 了；如果返回的 ACK  100，就是对第一个包的响应。如果返回 ACK  101 就是对第二个包的响应，RTT 计算相对准确。



但是这里有一个问题，就是怎么知道包 100 和包 101 发送的是同样的内容呢？QUIC 定义了一个 offset 概念。

QUIC 既然是面向连接的，也就像 TCP 一样，是一个数据流，发送的数据在这个数据流里面有个偏移量 offset，可以通过 offset 查看数据发送到了哪里，这样只要这个 offset 的包没有来，就要重发；如果来了，按照 offset 拼接，还是能够拼成一个流。

<img src="趣谈网络协议.assets/805aa4261yyb30a2a0e5a2f06ce5162c.jpeg" alt="img" style="zoom: 50%;" />



#### 机制三：无阻塞的多路复用

有了自定义的连接和重传机制，我们就可以解决上面 HTTP  2.0 的多路复用问题。



同 HTTP 2.0 一样，同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求。但是，QUIC 是基于 UDP 的，一个连接上的多个 stream 之间没有依赖。这样，假如 stream2 丢了一个 UDP 包，后面跟着 stream3 的一个 UDP 包，虽然 stream2 的那个包需要重传，但是 stream3 的包无需等待，就可以发给用户。



#### 机制四：自定义流量控制

TCP 的流量控制是通过**滑动窗口协议**。

QUIC 的流量控制也是**通过 window_update**，来告诉对端它可以接受的字节数。但是 QUIC 的窗口是适应自己的多路复用机制的，不但在一个连接上控制窗口，还在一个连接中的每个 stream 控制窗口。



还记得吗？在 TCP 协议中，接收端的窗口的起始点是下一个要接收并且 ACK 的包，即便后来的包都到了，放在缓存里面，窗口也不能右移，因为 TCP 的 ACK 机制是基于序列号的累计应答，一旦 ACK 了一个序列号，就说明前面的都到了，所以只要前面的没到，后面的到了也不能 ACK，就会导致后面的到了，也有可能超时重传，浪费带宽。



QUIC 的 ACK 是基于 offset 的，每个 offset 的包来了，进了缓存，就可以应答，应答后就不会重发，中间的空档会等待到来或者重发即可，而窗口的起始位置为当前收到的最大 offset，从这个 offset 到当前的 stream 所能容纳的最大缓存，是真正的窗口大小。显然，这样更加准确。

<img src="趣谈网络协议.assets/a66563b46906e7708cc69a02d43afb22.jpg" alt="img" style="zoom: 67%;" />

另外，还有整个连接的窗口，需要对于所有的 stream 的窗口做一个统计。



### 小结

总结一下：

- HTTP 协议虽然很常用，也很复杂，重点记住 GET、POST、 PUT、DELETE 这几个方法，以及重要的首部字段；
- HTTP 2.0 通过**头压缩、分帧、二进制编码、多路复用**等技术提升性能；
- QUIC 协议通过基于 UDP 自定义的类似 TCP 的连接、重试、多路复用、流量控制技术，进一步提升性能。

接下来，给你留两个思考题吧。

1. QUIC 是一个精巧的协议，所以它肯定不止今天我提到的四种机制，你知道它还有哪些吗？
2. 这一节主要讲了如何基于 HTTP 浏览网页，如果要传输比较敏感的银行卡信息，该怎么办呢？

> chatGPT

对于第一个问题，QUIC（Quick UDP Internet Connections）是一种基于UDP的传输协议，旨在提供更快速和可靠的网络连接。除了提供可靠的数据传输和拥塞控制外，QUIC还引入了一些其他的机制，例如：

1. 多路复用（Multiplexing）：QUIC允许在单个连接上同时进行多个数据流的传输，避免了TCP中的队头阻塞问题，提高了并发性能。
2. 0-RTT连接建立（Zero Round Trip Time）：QUIC允许在第一次连接时发送数据，而无需等待握手完成，从而减少了延迟。
3. 快速握手（Fast Handshake）：QUIC使用基于密钥的握手协议，减少了握手过程的延迟和数据传输量。
4. 前向纠错（Forward Error Correction）：QUIC使用前向纠错技术，可以在数据包丢失时通过冗余数据进行恢复，提高了数据传输的可靠性。

这些机制使得QUIC在性能和可靠性方面相对于传统的TCP协议有所提升。

对于第二个问题，如果要传输比较敏感的银行卡信息或其他敏感数据，需要确保数据的安全性和保密性。以下是一些常见的做法：

1. 使用HTTPS：使用HTTPS协议进行数据传输，通过SSL/TLS加密保护数据的安全性。HTTPS使用公钥加密和私钥解密的方式，确保数据在传输过程中不被窃听或篡改。
2. 数据加密：在应用层对敏感数据进行加密，确保即使在传输过程中被截获，也无法被解密和使用。
3. 安全传输协议：使用安全的传输协议，如SFTP（SSH File Transfer Protocol）或FTPS（FTP over SSL/TLS），确保数据在传输过程中的安全性。
4. 数据保护和合规性：遵循相关的数据保护法规和合规性要求，如PCI DSS（Payment Card Industry Data Security Standard），确保敏感数据的安全性和合规性。



## 第15讲 | HTTPS协议：点外卖的过程原来这么复杂

用 HTTP 协议，看个新闻还没有问题，但是换到更加严肃的场景中，就存在很多的安全风险。例如，你要下单做一次支付，如果还是使用普通的 HTTP 协议，那你很可能会被黑客盯上。



你发送一个请求，说我要点个外卖，但是这个网络包被截获了，于是在服务器回复你之前，黑客先假装自己就是外卖网站，然后给你回复一个假的消息说：“好啊好啊，来来来，银行卡号、密码拿来。”如果这时候你真把银行卡密码发给它，那你就真的上套了。

那怎么解决这个问题呢？当然一般的思路就是**加密**。加密分为两种方式一种是**对称加密**，一种是**非对称加密**。



在对称加密算法中，加密和解密使用的密钥是相同的。也就是说，加密和解密使用的是同一个密钥。因此，对称加密算法要保证安全性的话，密钥要做好保密。只能让使用的人知道，不能对外公开。



在非对称加密算法中，加密使用的密钥和解密使用的密钥是不相同的。一把是作为公开的公钥，另一把是作为谁都不能给的私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。



因为对称加密算法相比非对称加密算法来说，效率要高得多，性能也好，所以交互的场景下多用对称加密。



### 对称加密

假设你和外卖网站约定了一个密钥，你发送请求的时候用这个密钥进行加密，外卖网站用同样的密钥进行解密。这样就算中间的黑客截获了你的请求，但是它没有密钥，还是破解不了。



这看起来很完美，但是中间有个问题，你们两个怎么来约定这个密钥呢？如果这个密钥在互联网上传输，也是很有可能让黑客截获的。黑客一旦截获这个秘钥，它可以佯作不知，静静地等着你们两个交互。这时候你们之间互通的任何消息，它都能截获并且查看，就等你把银行卡账号和密码发出来。



我们在谍战剧里面经常看到这样的场景，就是特工破译的密码会有个密码本，截获无线电台，通过密码本就能将原文破解出来。怎么把密码本给对方呢？只能通过**线下传输**。



比如，你和外卖网站偷偷约定时间地点，它给你一个纸条，上面写着你们两个的密钥，然后说以后就用这个密钥在互联网上定外卖了。当然你们接头的时候，也会先约定一个口号，什么“天王盖地虎”之类的，口号对上了，才能把纸条给它。但是，“天王盖地虎”同样也是对称加密密钥，同样存在如何把“天王盖地虎”约定成口号的问题。而且在谍战剧中一对一接头可能还可以，在互联网应用中，客户太多，这样是不行的。



### 非对称加密

所以，只要是对称加密，就会永远在这个死循环里出不来，这个时候，就需要非对称加密介入进来。



非对称加密的私钥放在外卖网站这里，不会在互联网上传输，这样就能保证这个密钥的私密性。但是，对应私钥的公钥，是可以在互联网上随意传播的，只要外卖网站把这个公钥给你，你们就可以愉快地互通了。



比如说你用公钥加密，说“我要定外卖”，黑客在中间就算截获了这个报文，因为它没有私钥也是解不开的，所以这个报文可以顺利到达外卖网站，外卖网站用私钥把这个报文解出来，然后回复，“那给我银行卡和支付密码吧”。



存在问题：

1、先别太乐观，这里还是有问题的。**回复的这句话，是外卖网站拿私钥加密的，互联网上人人都可以把它打开，当然包括黑客。**那外卖网站可以拿公钥加密吗？当然不能，因为它自己的私钥只有它自己知道，谁也解不开。

2、另外，这个过程还有一个问题，黑客也可以模拟发送“我要定外卖”这个过程的，因为它也有外卖网站的公钥。



为了解决这个问题，**看来一对公钥私钥是不够的，客户端也需要有自己的公钥和私钥**，并且客户端要把自己的公钥，给外卖网站。

==》其实是有两对公私钥，发送时用对方的公钥加密，这样只有有私钥的对方可以解密消息。



这样，客户端给外卖网站发送的时候，用外卖网站的公钥加密。而外卖网站给客户端发送消息的时候，使用客户端的公钥。这样就算有黑客企图模拟客户端获取一些信息，或者半路截获回复信息，但是由于它没有私钥，这些信息它还是打不开。



### 数字证书

不对称加密也会有同样的问题，如何将不对称加密的公钥给对方呢？一种是放在一个公网的地址上，让对方下载；另一种就是在建立连接的时候，传给对方。



这两种方法有相同的问题，那就是，作为一个普通网民，你怎么鉴别别人给你的公钥是对的。会不会有人冒充外卖网站，发给你一个它的公钥。接下来，你和它所有的互通，看起来都是没有任何问题的。毕竟每个人都可以创建自己的公钥和私钥（用openssl）。

> RSA（Rivest-Shamir-Adleman）是一种非对称加密算法，其中包含公钥和私钥两个密钥。



例如，我自己搭建了一个网站 cliu8site，可以通过这个命令先创建私钥。

```
# openssl genrsa -out cliu8siteprivate.key 1024


# cat cliu8siteprivate.key 
-----BEGIN RSA PRIVATE KEY-----
MIICXQIBAAKBgQCriFjZB+XyRWzyYnJmw2j0cwSRU9cem6ZeNWVLHKz90rzS0jvm
C2PaA/SipUjku/MV1cWPdVAJD5xUomAUWwJKQuGfM0L2JbiyxZ1jkIy+G2ZuOmVC
QbhscxxxxxxxxxxxxxxxxxdHxHyoUlbkoYOutibXEXFFaFy1+Fz82wPHlRUCQD2o
BDlh7Q8I0I1oUtDmszWgR+lUgk48UYbGJvAxLcqqTsSOhchPFQPB5MYmyYyIsgb8
d5AJSlwnqNPvaceVTyECQQDH5ILFyiDBwIwBmmyu8jNJBcB4FbfBLWx+NC8oZ3HJ
cqqFzlwDaORJ6oAwFthU9I6Joht6hOjjmvotHTUYaRKK
-----END RSA PRIVATE KEY-----
```



然后，再根据这个私钥，创建对应的公钥。

```bash
# openssl rsa -in cliu8siteprivate.key -pubout -out cliu8sitepublic.pem

==》
# cat cliu8sitepublic.pem
-----BEGIN PUBLIC KEY-----
MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCriFjZB+XyRWzyYnJmw2j0cwSR
U9cem6ZeNWVLxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxAJD5xUomAUWwJKQuGf
M0L2JbiyxZ1jkIy+G2ZuOmVCQbhsc1vApUFJD33l0VJpuoJDfSB5A4gV3wyI5oiQ
lfIZTMou4NmGPxULzwIDAQAB
-----END PUBLIC KEY-----
```



> 补充 
>
> PEM（Privacy-Enhanced Mail）是一种用于存储和传输加密数据的文件格式。在加密领域中，PEM格式通常用于存储公钥和证书。
>
> PEM公钥是以PEM格式编码的公钥文件。它通常使用Base64编码，并包含了公钥的文本表示形式。PEM公钥文件以`.pem`或`.pub`为扩展名。
>
> PEM公钥文件的内容通常包括以下部分：
>
> 1. 标头（Header）：标识文件类型和加密算法。
> 2. 元数据（Metadata）：包含公钥的相关信息，如算法参数、密钥长度等。
> 3. 公钥数据（Public Key Data）：以Base64编码的公钥数据。



这个时候就需要权威部门的介入了，就像每个人都可以打印自己的简历，说自己是谁，但是有公安局盖章的，就只有户口本，这个才能证明你是你。这个由权威部门颁发的称为**证书**（**Certificate**）。



证书里面有什么呢？当然应该有**公钥**，这是最重要的；还有证书的**所有者**，就像户口本上有你的姓名和身份证号，说明这个户口本是你的；另外还有证书的**发布机构**和证书的**有效期**，这个有点像身份证上的机构是哪个区公安局，有效期到多少年。

<img src="趣谈网络协议.assets/image-20240823141858771.png" alt="image-20240823141858771" style="zoom: 50%;" />



这个证书是怎么生成的呢？会不会有人假冒权威机构颁发证书呢？就像有假身份证、假户口本一样。生成证书需要发起一个证书请求，然后将这个请求发给一个权威机构去认证，这个权威机构我们称为 **CA**（ **Certificate Authority**）。

**证书请求**可以通过这个命令生成。

```bash
# openssl req -key cliu8siteprivate.key -new -out cliu8sitecertificate.req
==》
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:CN
State or Province Name (full name) []:GD
Locality Name (eg, city) [Default City]:GZ
Organization Name (eg, company) [Default Company Ltd]:COM   
Organizational Unit Name (eg, section) []:
Common Name (eg, your name or your server's hostname) []:
Email Address []:
```

将这个请求发给权威机构，权威机构会给这个证书卡一个章，我们称为**签名算法。**问题又来了，那怎么签名才能保证是真的权威机构签名的呢？当然只有用只掌握在权威机构手里的东西签名了才行，这就是 CA 的私钥。



签名算法大概是这样工作的：一般是对信息做一个 Hash 计算，得到一个 Hash 值，这个过程是不可逆的，也就是说无法通过 Hash 值得出原来的信息内容。在把信息发送出去时，把这个 Hash 值加密后，作为一个签名和信息一起发出去。

权威机构给证书签名的命令是这样的。

```
openssl x509 -req -in cliu8sitecertificate.req -CA cacertificate.pem -CAkey caprivate.key -out cliu8sitecertificate.pem
```

> 需要知道CA的pem



这个命令会返回 Signature ok，而 cliu8sitecertificate.pem 就是签过名的证书。CA 用自己的私钥给外卖网站的公钥签名，就相当于给外卖网站背书，形成了外卖网站的证书。

我们来查看这个证书的内容。

```
openssl x509 -in cliu8sitecertificate.pem -noout -text 
```



这里面有个 Issuer，也即证书是谁颁发的；Subject，就是证书颁发给谁；Validity 是证书期限；Public-key 是公钥内容；Signature Algorithm 是签名算法。



这下好了，**你不会从外卖网站上得到一个公钥，而是会得到一个证书，这个证书有个发布机构 CA，你只要得到这个发布机构 CA 的公钥，去解密外卖网站证书的签名**，如果解密成功了，Hash 也对的上，就说明这个外卖网站的公钥没有啥问题。




你有没有发现，又有新问题了。要想验证证书，需要 CA 的公钥，问题是，你怎么确定 CA 的公钥就是对的呢？

所以，CA 的公钥也需要更牛的 CA 给它签名，然后形成 CA 的证书。要想知道某个 CA 的证书是否可靠，要看 CA 的上级证书的公钥，能不能解开这个 CA 的签名。就像你不相信区公安局，可以打电话问市公安局，让市公安局确认区公安局的合法性。这样层层上去，直到全球皆知的几个著名大 CA，称为 **root CA**，做最后的背书。通过这种**层层授信背书**的方式，从而保证了非对称加密模式的正常运转。



除此之外，还有一种证书，称为 **Self-Signed Certificate**，就是自己给自己签名。这个给人一种“我就是我，你爱信不信”的感觉。这里我就不多说了。



### HTTPS 的工作模式

我们可以知道，非对称加密在性能上不如对称加密，那是否能将两者结合起来呢？例如，公钥私钥主要用于传输对称加密的秘钥，而真正的双方大数据量的通信都是通过对称加密进行的。



当然是可以的。这就是 HTTPS 协议的总体思路。



<img src="趣谈网络协议.assets/df1685dd308cef1db97e91493f911ab4.jpg" alt="img" style="zoom: 33%;" />

当你登录一个外卖网站的时候，由于是 HTTPS，客户端会发送 **Client Hello** 消息到服务器，以明文传输 TLS 版本信息、加密套件候选列表、压缩算法候选列表等信息。另外，还会有一个随机数，在协商对称密钥的时候使用。

这就类似在说：“您好，我想定外卖，但你要保密我吃的是什么。这是我的加密套路，再给你个随机数，你留着。”

然后，外卖网站返回 **Server Hello** 消息, 告诉客户端，服务器选择使用的协议版本、加密套件、压缩算法等，还有一个随机数，用于后续的密钥协商。

这就类似在说：“您好，保密没问题，你的加密套路还挺多，咱们就按套路 2 来吧，我这里也有个随机数，你也留着。”

然后，外卖网站会给你一个服务器端的证书，然后说：“**Server Hello Done**，我这里就这些信息了。”



你当然不相信这个证书，于是你从自己信任的 CA 仓库中，拿 CA 的证书里面的公钥去解密外卖网站的证书。如果能够成功，则说明外卖网站是可信的。这个过程中，你可能会不断往上追溯 CA、CA 的 CA、CA 的 CA 的 CA，反正直到一个授信的 CA，就可以了。



证书验证完毕之后，觉得这个外卖网站可信，于是**客户端计算产生随机数字 Pre-master**，发送 **Client Key Exchange**，用证书中的公钥加密，再发送给服务器，服务器可以通过私钥解密出来。



到目前为止，无论是客户端还是服务器，都有了三个随机数，分别是：自己的、对端的，以及刚生成的 Pre-Master 随机数。**通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。**



有了对称密钥，客户端就可以说：“Change Cipher Spec，咱们以后都采用协商的通信密钥和加密算法进行加密通信了。”

然后发送一个 Encrypted Handshake Message，将已经商定好的参数等，采用协商密钥进行加密，发送给服务器用于数据与握手验证。



同样，服务器也可以发送 Change Cipher Spec，说：“没问题，咱们以后都采用协商的通信密钥和加密算法进行加密通信了”，并且也发送 Encrypted Handshake Message 的消息试试。当双方握手结束之后，就可以通过对称密钥进行加密传输了。



这个过程除了加密解密之外，其他的过程和 HTTP 是一样的，过程也非常复杂。

上面的过程只包含了 HTTPS 的单向认证，也即客户端验证服务端的证书，是大部分的场景，也可以在更加严格安全要求的情况下，启用双向认证，双方互相验证证书。



### 重放与篡改

其实，这里还有一些没有解决的问题，例如重放和篡改的问题。



没错，有了加密和解密，黑客截获了包也打不开了，但是它可以发送 N 次。这个往往通过 Timestamp 和 Nonce 随机数联合起来，然后做一个不可逆的签名来保证。

Nonce 随机数保证唯一，或者 Timestamp 和 Nonce 合起来保证唯一，同样的，请求只接受一次，于是服务器多次收到相同的 Timestamp 和 Nonce，则视为无效即可。

如果有人想篡改 Timestamp 和 Nonce，还有签名保证不可篡改性，如果改了用签名算法解出来，就对不上了，可以丢弃了。



### 小结

总结一下。

- 加密分对称加密和非对称加密。对称加密效率高，但是解决不了密钥传输问题；非对称加密可以解决这个问题，但是效率不高。
-  非对称加密需要通过证书和权威机构来验证公钥的合法性。
- HTTPS 是综合了对称加密和非对称加密算法的 HTTP 协议。既保证传输安全，也保证传输效率。

最后，给你留两个思考题：

1. HTTPS 协议比较复杂，沟通过程太繁复，这样会导致效率问题，那你知道有哪些手段可以解决这些问题吗？
2. HTTP 和 HTTPS 协议的正文部分传输个 JSON 什么的还好，如果播放视频，就有问题了，那这个时候，应该使用什么协议呢？



> chatGPT

对于第一个问题，有几种手段可以解决HTTPS协议的复杂性和效率问题：

1. HTTP/2：HTTP/2是一种新的协议，它在传输效率和性能方面比HTTP/1.1有显著的改进。它引入了多路复用、头部压缩、服务器推送等特性，可以减少连接建立的次数，提高并发性能。
2. TLS会话复用：TLS会话复用允许客户端和服务器在多个HTTPS请求之间重用已建立的TLS连接。这样可以减少握手过程的开销，提高连接的效率。
3. HTTP长连接：通过使用HTTP长连接，可以在一个TCP连接上发送多个HTTP请求和响应，减少了连接建立和关闭的开销。
4. CDN加速：使用内容分发网络（CDN）可以将静态资源缓存到离用户更近的边缘节点，提供更快的响应速度和更好的用户体验。

对于第二个问题，如果需要传输视频或其他大型媒体文件，HTTP或HTTPS可能不是最佳选择，因为它们是基于文本的协议，不适合高带宽和大文件的传输。

在这种情况下，可以考虑使用流媒体协议，如RTMP（Real-Time Messaging Protocol）或HLS（HTTP Live Streaming）。这些协议专门设计用于流式传输音频和视频内容，并具有更好的适应性和性能。

RTMP是一种实时流媒体传输协议，常用于视频直播和互动应用。它使用TCP作为传输协议，可以提供低延迟和高质量的流媒体传输。

HLS是一种基于HTTP的流媒体传输协议，适用于点播和实时流媒体。它将视频文件切分为小的TS（Transport Stream）分段，并通过HTTP传输。HLS具有广泛的兼容性，并且可以根据网络条件自适应调整视频质量。



## 第16讲 | 流媒体协议：如何在直播里看到美女帅哥？

最近直播比较火，很多人都喜欢看直播，那一个直播系统里面都有哪些组成部分，都使用了什么协议呢？



无论是直播还是点播，其实都是对于视频数据的传输。一提到视频，大家都爱看，但是一提到视频技术，大家都头疼，因为名词实在是太多了。



### 三个名词系列

我这里列三个名词系列，你先大致有个印象。

- **名词系列一**：AVI、MPEG、RMVB、MP4、MOV、FLV、WebM、WMV、ASF、MKV。例如 RMVB 和 MP4，看着是不是很熟悉？
- **名词系列二**：H.261、 H.262、H.263、H.264、H.265。这个是不是就没怎么听过了？别着急，你先记住，要重点关注 H.264。
- **名词系列**三：MPEG-1、MPEG-2、MPEG-4、MPEG-7。MPEG 好像听说过，但是后面的数字是怎么回事？是不是又熟悉又陌生？

想问你个问题，视频是什么？我说，其实就是快速播放一连串连续的图片。

每一张图片，我们称为一**帧**。只要每秒钟帧的数据足够多，也即播放得足够快。比如每秒 30 帧，以人的眼睛的敏感程度，是看不出这是一张张独立的图片的，这就是我们常说的**帧率**（**FPS**）。

每一张图片，都是由**像素**组成的，假设为 1024*768（这个像素数不算多）。每个像素由 RGB 组成，每个 8 位，共 24 位。

我们来算一下，每秒钟的视频有多大？

30 帧 × 1024 × 768 × 24 = 566,231,040Bits = 70,778,880Bytes

如果一分钟呢？4,246,732,800Bytes，已经是 4 个 G 了。

是不是不算不知道，一算吓一跳？这个数据量实在是太大，根本没办法存储和传输。如果这样存储，你的硬盘很快就满了；如果这样传输，那多少带宽也不够用啊！



怎么办呢？人们想到了**编码**，就是看如何用尽量少的 Bit 数保存视频，使播放的时候画面看起来仍然很精美。**编码是一个压缩的过程。**



### 视频和图片的压缩过程有什么特点？

之所以能够对视频流中的图片进行压缩，因为视频和图片有这样一些特点。



1. **空间冗余**：图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，不是突变的，没必要每个像素都完整地保存，可以隔几个保存一个，中间的用算法计算出来。
2. **时间冗余**：视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根据已有的图片进行预测和推断。
3. **视觉冗余**：人的视觉系统对某些细节不敏感，因此不会每一个细节都注意到，可以允许丢失一些数据。
4. **编码冗余**：不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多，类似[霍夫曼编码（Huffman Coding）](https://zh.wikipedia.org/wiki/霍夫曼编码)的思路。

总之，用于编码的算法非常复杂，而且多种多样，但是编码过程其实都是类似的。

<img src="趣谈网络协议.assets/46be417bde30b0a22f25928c30a3049e.jpg" alt="img" style="zoom: 50%;" />

### 视频编码的两大流派

能不能形成一定的标准呢？要不然开发视频播放的人得累死了。当然能，我这里就给你介绍，视频编码的两大流派。



- 流派一：ITU（International Telecommunications Union）的 VCEG（Video Coding Experts Group），这个称为**国际电信联盟下的 VCEG**。既然是电信，可想而知，他们最初做视频编码，主要侧重传输。名词系列二，就是这个组织制定的标准。
- 流派二：ISO（International Standards Organization）的 MPEG（Moving Picture Experts Group），这个是 **ISO 旗下的 MPEG**，本来是做视频存储的。例如，编码后保存在 VCD 和 DVD 中。当然后来也慢慢侧重视频传输了。名词系列三，就是这个组织制定的标准。

后来，ITU-T（国际电信联盟电信标准化部门，ITU Telecommunication Standardization Sector）与 MPEG 联合制定了 H.264/MPEG-4 AVC，这才是我们这一节要重点关注的。



经过编码之后，生动活泼的一帧一帧的图像，就变成了一串串让人看不懂的二进制，这个二进制可以放在一个文件里面，按照一定的格式保存起来，这就是名词系列一。

其实这些就是视频保存成文件的格式。例如，前几个字节是什么意义，后几个字节是什么意义，然后是数据，数据中保存的就是编码好的结果。



### 如何在直播里看到帅哥美女？

当然，这个二进制也可以通过某种网络协议进行封装，放在互联网上传输，这个时候就可以进行网络直播了。



网络协议将**编码**好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的服务端来接收这些网络包，从而得到里面的视频流，这个过程称为**接流**。

服务端接到视频流之后，可以对视频流进行一定的处理，例如**转码**，也即从一个编码格式，转成另一种格式。因为观众使用的客户端千差万别，要保证他们都能看到直播。

**流处理**完毕之后，就可以等待观众的客户端来请求这些视频流。观众的客户端请求的过程称为**拉流**。

如果有非常多的观众，同时看一个视频直播，那都从一个服务器上**拉流**，压力太大了，因而需要一个视频的**分发**网络，将视频预先加载到就近的边缘节点，这样大部分观众看的视频，是从边缘节点拉取的，就能降低服务器的压力。

当观众的客户端将视频流拉下来之后，就需要进行**解码**，也即通过上述过程的逆过程，将一串串看不懂的二进制，再转变成一帧帧生动的图片，在客户端**播放**出来，这样你就能看到美女帅哥啦。



整个直播过程，可以用这个的图来描述。

<img src="趣谈网络协议.assets/a90e05f4496baf25df15e0871a5e205c.jpg" alt="img" style="zoom:50%;" />

接下来，我们依次来看一下每个过程。

#### 编码：如何将丰富多彩的图片变成二进制流？

虽然我们说视频是一张张图片的序列，但是如果每张图片都完整，就太大了，因而会将视频序列分成三种帧。

- **I 帧**，Intra-frame，也称关键帧。里面是完整的图片，只需要本帧数据，就可以完成解码。
- **P 帧**，Predicted frame，前向预测编码帧。P 帧表示的是这一帧跟之前的一个关键帧（或 P 帧）的差别，解码时需要用之前缓存的画面，叠加上和本帧定义的差别，生成最终画面。
- **B 帧**，Bi-directional frame，双向预测内插编码帧。B 帧记录的是本帧与前后帧的差别。要解码 B 帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的数据与本帧数据的叠加，取得最终的画面。

可以看出，I 帧最完整，B 帧压缩率最高，而压缩后帧的序列，应该是在 IBBP 的间隔出现的。这就是**通过时序进行编码**。

<img src="趣谈网络协议.assets/10abca08bddaac3214cd69bb9a7b8a4f.jpg" alt="img" style="zoom:50%;" />

在一帧中，分成多个片，每个片中分成多个宏块，每个宏块分成多个子块，这样将一张大的图分解成一个个小块，可以方便进行**空间上的编码**。

尽管时空非常立体地组成了一个序列，但是总归还是要压缩成一个二进制流。这个流是有结构的，是一个个的**网络提取层单元**（**NALU**，**Network Abstraction Layer Unit**）。变成这种格式就是为了传输，因为网络上的传输，默认的是一个个的包，因而这里也就分成了一个个的单元。

<img src="趣谈网络协议.assets/4df30b99a606504cb0bbbc611c27d8c1.jpg" alt="img" style="zoom:50%;" />



每一个 NALU 首先是一个起始标识符，用于标识 NALU 之间的间隔；然后是 NALU 的头，里面主要配置了 NALU 的类型；最终 Payload 里面是 NALU 承载的数据。

在 NALU 头里面，主要的内容是类型 **NAL Type**。

- 0x07 表示 SPS，是序列参数集， 包括一个图像序列的所有信息，如图像尺寸、视频格式等。
- 0x08 表示 PPS，是图像参数集，包括一个图像的所有分片的所有相关信息，包括图像类型、序列号等。

在传输视频流之前，必须要传输这两类参数，不然无法解码。为了保证容错性，每一个 I 帧前面，都会传一遍这两个参数集合。



如果 NALU Header 里面的表示类型是 SPS 或者 PPS，则 Payload 中就是真正的参数集的内容。

如果类型是帧，则 Payload 中才是正的视频数据，当然也是一帧一帧存放的，前面说了，一帧的内容还是挺多的，因而每一个 NALU 里面保存的是一片。对于每一片，到底是 I 帧，还是 P 帧，还是 B 帧，在片结构里面也有个 Header，这里面有个类型，然后是片的内容。

这样，整个格式就出来了，**一个视频，可以拆分成一系列的帧，每一帧拆分成一系列的片，每一片都放在一个 NALU 里面，NALU 之间都是通过特殊的起始标识符分隔，在每一个 I 帧的第一片前面，要插入单独保存 SPS 和 PPS 的 NALU，最终形成一个长长的 NALU 序列**。



#### 推流：如何把数据流打包传输到对端？

那这个格式是不是就能够直接在网上传输到对端，开始直播了呢？其实还不是，还需要将这个二进制的流打包成网络包进行发送，这里我们使用 **RTMP 协议**。这就进入了第二个过程，**推流**。



RTMP 是基于 TCP 的，因而肯定需要双方建立一个 TCP 的连接。在有 TCP 的连接的基础上，还需要建立一个 RTMP 的连接，也即在程序里面，你需要调用 RTMP 类库的 Connect 函数，显示创建一个连接。



> RTMP 为什么需要建立一个单独的连接呢？

因为它们需要商量一些事情，保证以后的传输能正常进行。主要就是两个事情，一个是**版本号**，如果客户端、服务器的版本号不一致，则不能工作。另一个就是**时间戳**，视频播放中，时间是很重要的，后面的数据流互通的时候，经常要带上时间戳的差值，因而一开始双方就要知道对方的时间戳。

未来沟通这些事情，需要发送六条消息：客户端发送 C0、C1、  C2，服务器发送 S0、  S1、  S2。

首先，客户端发送 C0 表示自己的版本号，不必等对方的回复，然后发送 C1 表示自己的时间戳。

服务器只有在收到 C0 的时候，才能返回 S0，表明自己的版本号，如果版本不匹配，可以断开连接。



服务器发送完 S0 后，也不用等什么，就直接发送自己的时间戳 S1。客户端收到 S1 的时候，发一个知道了对方时间戳的 ACK  C2。同理服务器收到 C1 的时候，发一个知道了对方时间戳的 ACK  S2。



于是，握手完成。

<img src="趣谈网络协议.assets/ba03ba5f2b2515df3669c469301e5784.jpg" alt="img" style="zoom:50%;" />

握手之后，双方需要互相传递一些控制信息，例如 Chunk 块的大小、窗口大小等。

真正传输数据的时候，还是需要创建一个流 Stream，然后通过这个 Stream 来推流 publish。

推流的过程，就是将 NALU 放在 Message 里面发送，这个也称为 **RTMP Packet 包**。Message 的格式就像这样。

<img src="趣谈网络协议.assets/206yy043f9fdfa79d984156fb2fea4b3.jpg" alt="img" style="zoom: 50%;" />



发送的时候，去掉 NALU 的起始标识符。因为这部分对于 RTMP 协议来讲没有用。接下来，将 SPS 和 PPS 参数集封装成一个 RTMP 包发送，然后发送一个个片的 NALU。

RTMP 在收发数据的时候并不是以 Message 为单位的，而是把 Message 拆分成 Chunk 发送，而且必须在一个 Chunk 发送完成之后，才能开始发送下一个 Chunk。每个 Chunk 中都带有 Message  ID，表示属于哪个 Message，接收端也会按照这个 ID 将 Chunk 组装成 Message。

前面连接的时候，设置的 Chunk 块大小就是指这个 Chunk。将大的消息变为小的块再发送，可以在低带宽的情况下，减少网络拥塞。



这有一个分块的例子，你可以看一下。

假设一个视频的消息长度为 307，但是 Chunk 大小约定为 128，于是会拆分为三个 Chunk。

第一个 Chunk 的 Type＝0，表示 Chunk 头是完整的；头里面 Timestamp 为 1000，总长度 Length 为 307，类型为 9，是个视频，Stream  ID 为 12346，正文部分承担 128 个字节的 Data。

第二个 Chunk 也要发送 128 个字节，Chunk 头由于和第一个 Chunk 一样，因此采用 Chunk Type＝3，表示头一样就不再发送了。

第三个 Chunk 要发送的 Data 的长度为 307-128-128=51 个字节，还是采用 Type＝3。

<img src="趣谈网络协议.assets/186f198d54300f772dcddcb6ec476a06.jpg" alt="img" style="zoom: 50%;" />

就这样数据就源源不断到达流媒体服务器，整个过程就像这样。

<img src="趣谈网络协议.assets/0b4642e6c5130aeac225b9db1126fc64.jpg" alt="img" style="zoom: 50%;" />

这个时候，大量观看直播的观众就可以通过 RTMP 协议从流媒体服务器上拉取，但是这么多的用户量，都去同一个地方拉取，服务器压力会很大，而且用户分布在全国甚至全球，如果都去统一的一个地方下载，也会时延比较长，需要有分发网络。



分发网络分为**中心**和**边缘**两层。边缘层服务器部署在全国各地及横跨各大运营商里，和用户距离很近。中心层是流媒体服务集群，负责内容的转发。智能负载均衡系统，根据用户的地理位置信息，就近选择边缘服务器，为用户提供推 / 拉流服务。中心层也负责转码服务，例如，把 RTMP 协议的码流转换为 HLS 码流。

<img src="趣谈网络协议.assets/01b67e494f4705e71243f89b9cd1a556.jpg" alt="img" style="zoom: 33%;" />

这套机制在后面的 DNS、HTTPDNS、CDN 的章节会更有详细的描述。

#### 拉流：观众的客户端如何看到视频？

接下来，我们再来看观众的客户端通过 RTMP 拉流的过程。

<img src="趣谈网络协议.assets/2cdaf16cc2ee71512a4bdf5995549fdb.jpg" alt="img" style="zoom:33%;" />

先读到的是 H.264 的解码参数，例如 SPS 和 PPS，然后对收到的 NALU 组成的一个个帧，进行解码，交给播发器播放，一个绚丽多彩的视频画面就出来了。



### 小结

好了，今天的内容就到这里了，我们来总结一下：



-  视频名词比较多，编码两大流派达成了一致，都是通过时间、空间的各种算法来压缩数据；
- 压缩好的数据，为了传输组成一系列 NALU，按照帧和片依次排列；
- 排列好的 NALU，在网络传输的时候，要按照 RTMP 包的格式进行包装，RTMP 的包会拆分成 Chunk 进行传输；
- 推送到流媒体集群的视频流经过转码和分发，可以被客户端通过 RTMP 协议拉取，然后组合为 NALU，解码成视频格式进行播放。

最后，给你留两个思考题：

1. 你觉得基于 RTMP 的视频流传输的机制存在什么问题？如何进行优化？
2. 在线看视频之前，大家都是把电影下载下来看的，电影这么大，你知道如何快速下载吗？

> chatGPT

思考题 1: 基于 RTMP 的视频流传输的机制存在什么问题？如何进行优化？

基于 RTMP（Real-Time Messaging Protocol）的视频流传输机制存在一些问题，包括：

1. 延迟问题：RTMP 在传输视频流时可能会引入一定的延迟，这对于实时性要求较高的应用（如直播）可能会造成不利影响。
2. 带宽占用：RTMP 使用的是基于 TCP 的传输协议，它对带宽的利用率相对较低，可能导致网络拥塞和带宽浪费。
3. 安全性问题：RTMP 的传输是明文的，没有加密保护，可能存在数据安全性的风险。

为了优化基于 RTMP 的视频流传输，可以考虑以下方法：

1. 使用更低延迟的传输协议：可以考虑使用基于 UDP 的传输协议，如 WebRTC，以减少传输延迟。
2. 优化带宽利用率：可以采用压缩算法、流量控制和带宽自适应等技术，以提高带宽利用率和减少网络拥塞。
3. 引入加密机制：为了保护数据的安全性，可以使用加密算法对视频流进行加密，确保传输过程中的数据安全。
4. 使用内容分发网络（CDN）：通过在全球范围内部署服务器节点，将视频内容缓存到离用户更近的位置，以提供更快速的视频传输和更好的用户体验。



思考题 2: 如何快速下载大型电影？

要快速下载大型电影，可以考虑以下方法：

1. 使用高速互联网连接：确保你的网络连接速度足够快，可以选择使用宽带或光纤等高速互联网连接。
2. 使用下载管理器：使用专业的下载管理器软件，如Internet Download Manager（IDM）或Free Download Manager（FDM），它们可以提供更稳定和高效的下载功能。
3. 使用多线程下载：一些下载管理器支持多线程下载，可以同时使用多个连接下载文件，提高下载速度。
4. 使用下载加速器：下载加速器软件可以通过优化网络连接和使用多个下载源等技术，提高下载速度。
5. 选择合适的下载源：选择可靠的下载源，如官方网站、BitTorrent 等，以确保下载速度和文件完整性。
6. 避免高峰时段下载：在网络使用较少的时间段下载，避免高峰时段的网络拥塞。
7. 使用分段下载：一些大型文件可能被分成多个部分，可以使用分段下载的功能，同时下载多个部分，以加快下载速度。


## 第17讲 | P2P协议

如果你想下载一个电影，一般会通过什么方式呢？

当然，最简单的方式就是通过 **HTTP** 进行下载。但是相信你有过这样的体验，通过浏览器下载的时候，只要文件稍微大点，下载的速度就奇慢无比。

还有种下载文件的方式，就是通过 **FTP**，也即**文件传输协议**。FTP 采用两个 TCP 连接来传输一个文件。

- **控制连接**：服务器以被动的方式，打开众所周知用于 FTP 的端口 21，客户端则主动发起连接。该连接将命令从客户端传给服务器，并传回服务器的应答。常用的命令有：list——获取文件目录；reter——取一个文件；store——存一个文件。
- **数据连接**：每当一个文件在客户端与服务器之间传输时，就创建一个数据连接。



### FTP 的两种工作模式

每传输一个文件，都要建立一个全新的数据连接。FTP 有两种工作模式，分别是**主动模式**（**PORT**）和**被动模式**（**PASV**），这些都是站在 FTP 服务器的角度来说的。

- **主动模式**下，客户端随机打开一个大于 1024 的端口 N，向服务器的命令端口 21 发起连接，同时开放 N+1 端口监听，并向服务器发出 “port N+1” 命令，由服务器从自己的数据端口 20，主动连接到客户端指定的数据端口 N+1。
- **被动模式**下，当开启一个 FTP 连接时，客户端打开两个任意的本地端口 N（大于 1024）和 N+1。第一个端口连接服务器的 21 端口，提交 PASV 命令。然后，服务器会开启一个任意的端口 P（大于 1024），返回“227 entering passive mode”消息，里面有 FTP 服务器开放的用来进行数据传输的端口。客户端收到消息取得端口号之后，会通过 N+1 号端口连接服务器的端口 P，然后在两个端口之间进行数据传输。



### P2P 是什么？

但是无论是 HTTP 的方式，还是 FTP 的方式，都有一个比较大的缺点，就是**难以解决单一服务器的带宽压力**， 因为它们使用的都是传统的客户端服务器的方式。

后来，一种创新的、称为 P2P 的方式流行起来。**P2P** 就是 **peer-to-peer**。资源开始并不集中地存储在某些设备上，而是分散地存储在多台设备上。这些设备我们姑且称为 peer。



想要下载一个文件的时候，你只要得到那些已经存在了文件的 peer，并和这些 peer 之间，建立点对点的连接，而不需要到中心服务器上，就可以就近下载文件。一旦下载了文件，你也就成为 peer 中的一员，你旁边的那些机器，也可能会选择从你这里下载文件，所以当你使用 P2P 软件的时候，例如 BitTorrent，往往能够看到，既有下载流量，也有上传的流量，也即你自己也加入了这个 P2P 的网络，自己从别人那里下载，同时也提供给其他人下载。可以想象，这种方式，参与的人越多，下载速度越快，一切完美。



#### 种子（.torrent）文件

但是有一个问题，当你想下载一个文件的时候，怎么知道哪些 peer 有这个文件呢？

这就用到**种子**啦，也即咱们比较熟悉的**.torrent 文件**。.torrent 文件由两部分组成，分别是：**announce**（**tracker URL**）和**文件信息**。



文件信息里面有这些内容。

- **info 区**：这里指定的是该种子有几个文件、文件有多长、目录结构，以及目录和文件的名字。
- **Name 字段**：指定顶层目录名字。
- **每个段的大小**：BitTorrent（简称 BT）协议把一个文件分成很多个小段，然后分段下载。
- **段哈希值**：将整个种子中，每个段的 SHA-1 哈希值拼在一起。



下载时，BT 客户端首先解析.torrent 文件，得到 tracker 地址，然后连接 **tracker 服务器**。tracker 服务器回应下载者的请求，将其他下载者（包括发布者）的 IP 提供给下载者。下载者再连接其他下载者，根据.torrent 文件，两者分别对方告知自己已经有的块，然后交换对方没有的数据。此时不需要其他服务器参与，并分散了单个线路上的数据流量，因此减轻了服务器的负担。

下载者每得到一个块，需要算出下载块的 Hash 验证码，并与.torrent 文件中的对比。如果一样，则说明块正确，不一样则需要重新下载这个块。这种规定是为了解决下载内容的准确性问题。

从这个过程也可以看出，这种方式特别依赖 tracker。tracker 需要收集下载者信息的服务器，并将此信息提供给其他下载者，使下载者们相互连接起来，传输数据。虽然下载的过程是非中心化的，但是加入这个 P2P 网络的时候，都需要借助 tracker 中心服务器，这个服务器是用来登记有哪些用户在请求哪些资源。

所以，**这种工作方式有一个弊端，一旦 tracker 服务器出现故障或者线路遭到屏蔽，BT 工具就无法正常工作了**。



### 去中心化网络（DHT）

那能不能彻底非中心化呢？

于是，后来就有了一种叫作 **DHT**（**Distributed Hash Table**）的去中心化网络。每个加入这个 DHT 网络的人，都要负责存储这个网络里的资源信息和其他成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。

有一种著名的 DHT 协议，叫 **Kademlia 协议**。这个和区块链的概念一样，很抽象，我来详细讲一下这个协议。

任何一个 BitTorrent 启动之后，它都有两个角色。一个是 **peer**，监听一个 TCP 端口，用来上传和下载文件，这个角色表明，我这里有某个文件。另一个角色 **DHT node**，监听一个 UDP 的端口，通过这个角色，这个节点加入了一个 DHT 的网络。

<img src="趣谈网络协议.assets/80ecacb45587d201cbb9a08c31476d27.jpg" alt="img" style="zoom:50%;" />

在 DHT 网络里面，每一个 DHT node 都有一个 ID。这个 ID 是一个很长的串。每个 DHT node 都有责任掌握一些知识，也就是**文件索引**，也即它应该知道某些文件是保存在哪些节点上。它只需要有这些知识就可以了，而它自己本身不一定就是保存这个文件的节点。

#### 哈希值

当然，每个 DHT node 不会有全局的知识，也即不知道所有的文件保存在哪里，它只需要知道一部分。那应该知道哪一部分呢？这就需要用哈希算法计算出来。

每个文件可以计算出一个哈希值，而 **DHT node 的 ID 是和哈希值相同长度的串**。

DHT 算法是这样规定的：如果一个文件计算出一个哈希值，则和这个哈希值一样的那个 DHT node，就有责任知道从哪里下载这个文件，即便它自己没保存这个文件。



当然不一定这么巧，总能找到和哈希值一模一样的，有可能一模一样的 DHT node 也下线了，所以 DHT 算法还规定：除了一模一样的那个 DHT node 应该知道，ID 和这个哈希值非常接近的 N 个 DHT node 也应该知道。



什么叫和哈希值接近呢？例如只修改了最后一位，就很接近；修改了倒数 2 位，也不远；修改了倒数 3 位，也可以接受。总之，凑齐了规定的 N 这个数就行。



刚才那个图里，文件 1 通过哈希运算，得到匹配 ID 的 DHT node 为 node C，当然还会有其他的，我这里没有画出来。所以，node C 有责任知道文件 1 的存放地址，虽然 node C 本身没有存放文件 1。

同理，文件 2 通过哈希运算，得到匹配 ID 的 DHT node 为 node E，但是 node D 和 E 的 ID 值很近，所以 node D 也知道。当然，文件 2 本身没有必要一定在 node D 和 E 里，但是碰巧这里就在 E 那有一份。

接下来一个新的节点 node new 上线了。如果想下载文件 1，它首先要加入 DHT 网络，如何加入呢？

在这种模式下，种子.torrent 文件里面就不再是 tracker 的地址了，而是一个 list 的 node 的地址，而所有这些 node 都是已经在 DHT 网络里面的。当然随着时间的推移，很可能有退出的，有下线的，但是我们假设，不会所有的都联系不上，总有一个能联系上。



node new 只要在种子里面找到一个 DHT node，就加入了网络。



node new 会计算文件 1 的哈希值，并根据这个哈希值了解到，和这个哈希值匹配，或者很接近的 node 上知道如何下载这个文件，例如计算出来的哈希值就是 node C。

但是 node new 不知道怎么联系上 node C，因为种子里面的 node 列表里面很可能没有 node C，但是它可以问，DHT 网络特别像一个社交网络，node new 只有去它能联系上的 node 问，你们知道不知道 node C 的联系方式呀？

在 DHT 网络中，每个 node 都保存了一定的联系方式，但是肯定没有 node 的所有联系方式。DHT 网络中，节点之间通过互相通信，也会交流联系方式，也会删除联系方式。和人们的方式一样，你有你的朋友圈，你的朋友有它的朋友圈，你们互相加微信，就互相认识了，过一段时间不联系，就删除朋友关系。

有个理论是，社交网络中，任何两个人直接的距离不超过六度，也即你想联系比尔盖茨，也就六个人就能够联系到了。

所以，node new 想联系 node C，就去万能的朋友圈去问，并且求转发，朋友再问朋友，很快就能找到。如果找不到 C，也能找到和 C 的 ID 很像的节点，它们也知道如何下载文件 1。

在 node C 上，告诉 node new，下载文件 1，要去 B、D、 F，于是 node new 选择和 node B 进行 peer 连接，开始下载，它一旦开始下载，自己本地也有文件 1 了，于是 node new 告诉 node C 以及和 node C 的 ID 很像的那些节点，我也有文件 1 了，可以加入那个文件拥有者列表了。



但是你会发现 node new 上没有文件索引，但是根据哈希算法，一定会有某些文件的哈希值是和 node new 的 ID 匹配上的。在 DHT 网络中，会有节点告诉它，你既然加入了咱们这个网络，你也有责任知道某些文件的下载地址。



好了，一切都分布式了。



这里面遗留几个细节的问题。

- DHT node ID 以及文件哈希是个什么东西？

节点 ID 是一个随机选择的 160bits（20 字节）空间，文件的哈希也使用这样的 160bits 空间。

- 所谓 ID 相似，具体到什么程度算相似？



在 Kademlia 网络中，距离是通过异或（XOR）计算的。我们就不以 160bits 举例了。我们以 5 位来举例。

01010 与 01000 的距离，就是两个 ID 之间的异或值，为 00010，也即为 2。 01010 与 00010 的距离为 01000，也即为 8,。01010 与 00011 的距离为 01001，也即 8+1=9 。以此类推，高位不同的，表示距离更远一些；低位不同的，表示距离更近一些，总的距离为所有的不同的位的距离之和。

这个距离不能比喻为地理位置，因为在 Kademlia 网络中，位置近不算近，ID 近才算近，所以我把这个距离比喻为社交距离，也即在朋友圈中的距离，或者社交网络中的距离。这个和你住的位置没有关系，和人的经历关系比较大。

还是以 5 位 ID 来举例，就像在领英中，排第一位的表示最近一份工作在哪里，第二位的表示上一份工作在哪里，然后第三位的是上上份工作，第四位的是研究生在哪里读，第五位的表示大学在哪里读。



如果你是一个猎头，在上面找候选人，当然最近的那份工作是最重要的。而对于工作经历越丰富的候选人，大学在哪里读的反而越不重要。



#### DHT 网络中的朋友圈是怎么维护的？

就像人一样，虽然我们常联系人的只有少数，但是朋友圈里肯定是远近都有。DHT 网络的朋友圈也是一样，远近都有，并且**按距离分层**。



假设某个节点的 ID 为 01010，如果一个节点的 ID，前面所有位数都与它相同，只有最后 1 位不同。这样的节点只有 1 个，为 01011。与基础节点的异或值为 00001，即距离为 1；对于 01010 而言，这样的节点归为“k-bucket 1”。



如果一个节点的 ID，前面所有位数都相同，从倒数第 2 位开始不同，这样的节点只有 2 个，即 01000 和 01001，与基础节点的异或值为 00010 和 00011，即距离范围为 2 和 3；对于 01010 而言，这样的节点归为“k-bucket 2”。



如果一个节点的 ID，前面所有位数相同，从倒数第 i 位开始不同，这样的节点只有 2^(i-1) 个，与基础节点的距离范围为[2^(i-1), 2^i)；对于 01010 而言，这样的节点归为“k-bucket i”。



最终到从倒数 160 位就开始都不同。



你会发现，差距越大，陌生人越多，但是朋友圈不能都放下，所以每一层都只放 K 个，这是参数可以配置。



### DHT 网络是如何查找朋友的？

假设，node A 的 ID 为 00110，要找 node B ID 为 10000，异或距离为 10110，距离范围在[2^4, 2^5)，所以这个目标节点可能在“k-bucket 5”中，这就说明 B 的 ID 与 A 的 ID 从第 5 位开始不同，所以 B 可能在“k-bucket 5”中。



然后，A 看看自己的 k-bucket 5 有没有 B。如果有，太好了，找到你了；如果没有，在 k-bucket 5 里随便找一个 C。因为是二进制，C、B 都和 A 的第 5 位不同，那么 C 的 ID 第 5 位肯定与 B 相同，即它与 B 的距离会小于 2^4，相当于比 A、B 之间的距离缩短了一半以上。



再请求 C，在它自己的通讯录里，按同样的查找方式找一下 B。如果 C 知道 B，就告诉 A；如果 C 也不知道 B，那 C 按同样的搜索方法，可以在自己的通讯录里找到一个离 B 更近的 D 朋友（D、B 之间距离小于 2^3），把 D 推荐给 A，A 请求 D 进行下一步查找。



Kademlia 的这种查询机制，是通过折半查找的方式来收缩范围，对于总的节点数目为 N，最多只需要查询 log2(N) 次，就能够找到。



例如，图中这个最差的情况。

![img](趣谈网络协议.assets/dc6d713751d09ea5dd0d79c65433aeb4.jpg)

A 和 B 每一位都不一样，所以相差 31，A 找到的朋友 C，不巧正好在中间。和 A 的距离是 16，和 B 距离为 15，于是 C 去自己朋友圈找的时候，不巧找到 D，正好又在中间，距离 C 为 8，距离 B 为 7。于是 D 去自己朋友圈找的时候，不巧找到 E，正好又在中间，距离 D 为 4，距离 B 为 3，E 在朋友圈找到 F，距离 E 为 2，距离 B 为 1，最终在 F 的朋友圈距离 1 的地方找到 B。当然这是最最不巧的情况，每次找到的朋友都不远不近，正好在中间。



如果碰巧了，在 A 的朋友圈里面有 G，距离 B 只有 3，然后在 G 的朋友圈里面一下子就找到了 B，两次就找到了。



在 DHT 网络中，朋友之间怎么沟通呢？



Kademlia 算法中，每个节点只有 4 个指令。

- PING：测试一个节点是否在线，还活着没，相当于打个电话，看还能打通不。
- STORE：要求一个节点存储一份数据，既然加入了组织，有义务保存一份数据。
- FIND_NODE：根据节点 ID 查找一个节点，就是给一个 160 位的 ID，通过上面朋友圈的方式找到那个节点。
- FIND_VALUE：根据 KEY 查找一个数据，实则上跟 FIND_NODE 非常类似。KEY 就是文件对应的 160 位的 ID，就是要找到保存了文件的节点。



DHT 网络中，朋友圈如何更新呢？

- 每个 bucket 里的节点，都按最后一次接触的时间倒序排列，这就相当于，朋友圈里面最近联系过的人往往是最熟的。
- 每次执行四个指令中的任意一个都会触发更新。
- 当一个节点与自己接触时，检查它是否已经在 k-bucket 中，也就是说是否已经在朋友圈。如果在，那么将它挪到 k-bucket 列表的最底，也就是最新的位置，刚联系过，就置顶一下，方便以后多联系；如果不在，新的联系人要不要加到通讯录里面呢？假设通讯录已满的情况，PING 一下列表最上面，也即最旧的一个节点。如果 PING 通了，将旧节点挪到列表最底，并丢弃新节点，老朋友还是留一下；如果 PING 不通，删除旧节点，并将新节点加入列表，这人联系不上了，删了吧。



这个机制保证了任意节点加入和离开都不影响整体网络。



## 小结

总结一下：

- 下载一个文件可以使用 HTTP 或 FTP，这两种都是集中下载的方式，而 P2P 则换了一种思路，采取非中心化下载的方式；
- P2P 也是有两种，一种是依赖于 tracker 的，也即元数据集中，文件数据分散；另一种是基于分布式的哈希算法，元数据和文件数据全部分散。



接下来，给你留两个思考题：

1. 除了这种去中心化分布式哈希的算法，你还能想到其他的应用场景吗？
2. 在前面所有的章节中，要下载一个文件，都需要使用域名。但是网络通信是使用 IP 的，那你知道怎么实现两者的映射机制吗？

> chatGPT

思考题 1: 除了去中心化分布式哈希算法，你还能想到其他的应用场景吗？

除了在文件共享领域中的应用，去中心化分布式哈希算法还可以应用于以下场景：

1. 分布式存储系统：可以使用去中心化分布式哈希算法来实现分布式存储系统，将数据分散存储在多个节点上，提高数据的可靠性和可扩展性。
2. 区块链技术：区块链是一种去中心化的分布式账本技术，可以使用分布式哈希算法来确保区块链的完整性和安全性。
3. 内容分发网络（CDN）：CDN 可以使用去中心化分布式哈希算法来实现内容的分发和缓存，提高内容的访问速度和可用性。
4. 分布式计算：在分布式计算环境中，可以使用去中心化分布式哈希算法来分配任务和管理计算资源。

思考题 2: 在前面所有的章节中，要下载一个文件，都需要使用域名。但是网络通信是使用 IP 的，那你知道怎么实现两者的映射机制吗？

域名和 IP 的映射关系是通过域名系统（DNS）来实现的。DNS 是一个分布式的命名系统，它将域名映射到相应的 IP 地址。





# 第二模块 底层网络知识详解：陌生的数据中心

第18讲 | DNS协议：网络世界的地址簿

## 第19讲 | HttpDNS：网络世界的地址簿也会指错路

第20讲 | CDN：你去小卖部取过快递么？

第21讲 | 数据中心：我是开发商，自己拿地盖别墅

第22讲 | VPN：朝中有人好做官

第23讲 | 移动网络：去巴塞罗那，手机也上不了脸书



# 第三模块 热门技术中的应用：云计算中的网络

第24讲 | 云中网络：自己拿地成本高，购买公寓更灵活

第25讲 | 软件定义网络：共享基础设施的小区物业管理办法

第26讲 | 云中的网络安全：虽然不是土豪，也需要基本安全和保障

第27讲 | 云中的网络QoS：邻居疯狂下电影，我该怎么办？

第28讲 | 云中网络的隔离GRE、VXLAN：虽然住一个小区，也要保护隐私



# 第三模块 热门技术中的应用：容器技术中的网络

第29讲 | 容器网络：来去自由的日子，不买公寓去合租

第30讲 | 容器网络之Flannel：每人一亩三分地

第31讲 | 容器网络之Calico：为高效说出善意的谎言



# 第三模块 热门技术中的应用：微服务相关协议

第32讲 | RPC协议综述：远在天边，近在眼前应学14分钟



第33讲 | 基于XML的SOAP协议：不要说NBA，请说美国职业篮球联赛应学9分钟



第34讲 | 基于JSON的RESTful接口协议：我不关心过程，请给我结果应学11分钟



第35讲 | 二进制类RPC协议：还是叫NBA吧，总说全称多费劲应学12分钟



第36讲 | 跨语言类RPC协议：交流之前，双方先来个专业术语表应学13分钟



# 第四模块 网络协议知识串讲


第37讲 | 知识串讲：用双十一的故事串起碎片的网络协议（上）应学9分钟



第38讲 | 知识串讲：用双十一的故事串起碎片的网络协议（中）应学9分钟



第39讲 | 知识串讲：用双十一的故事串起碎片的网络协议（下）应学14分钟



第40讲 | 搭建一个网络实验环境：授人以鱼不如授人以渔应学9分钟



# 答疑与加餐